{"./":{"url":"./","title":"Introduction","keywords":"","body":"Summary Android Android系统架构 Activity && Service生命周期 Activity四种启动模式 ListView原理及优化 Android中Handler机制 Android广播机制 View绘制过程 Canvas使用 事件分发机制 Binder 性能优化 推送机制 进程保活 Activity、View及Window之间关系 EventBus OkHttp Intent 版本问题 面试题 计算机基础 算法 基本算法 树 Hash 最小生成树算法 最短路径算法 KMP算法 查找算法 排序算法 跳跃表 面试题 操作系统 计算机体系结构 操作系统基础 并发 内存管理 磁盘与文件 Linux系统 中断 设备管理 I/O 面试题 计算机网络 网络分层 底层网络协议 TCP IP HTTP HTTPS 面试题 数据库 事务 索引 SQL 连接 MySQL 并发控制 Redis Innodb 面试题 密码学 Java OOP 序列化 面试题 运算符 异常 范型 Object StringBuilder 代理 集合 集合 HashMap Concurrenthashmap BlockQueue 并发 线程 Volatile Synchronized AQS CountDownLatch Threadlocal 线程中断 GC Java 虚拟机垃圾收集 Java 虚拟机对象生命周期 Java 虚拟机 类加载 类加载器 Java分派机制 虚拟机架构 内存模型 String 常量池 框架 Netty Mybatis 面试题 缓存 代理 Spring IOC 设计模式 AOP 系统架构 基本概念 高并发 流量控制 系统设计 短链接系统 分布式 分布式 Session 分布式缓存 分布式锁 分布式事务 消息队列 Zookeeper Kafka 远程调用 Dubbo 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/":{"url":"android/","title":"Android","keywords":"","body":"安卓 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/arch.html":{"url":"android/arch.html","title":"Android系统架构","keywords":"","body":"Android系统架构 应用程序(Applications) Android会同一系列核心应用程序包一起发布，该应用程序包包括email客户端，SMS短消息程序，日历，地图，浏览器，联系人管理程序等。所有的应用程序都是使用JAVA语言编写的。通常开发人员就处在这一层。 应用程序框架(Application Frameworks) 提供应用程序开发的各种API进行快速开发，也即隐藏在每个应用后面的是一系列的服务和系统，大部分使用Java编写，所谓官方源码很多也就是看这里，其中包括： 丰富而又可扩展的视图（Views）：可以用来构建应用程序， 它包括列表（lists），网格（grids），文本框（text boxes），按钮（buttons）， 甚至可嵌入的web浏览器。 内容提供器（Content Providers）：使得应用程序可以访问另一个应用程序的数据（如联系人数据库）， 或者共享它们自己的数据 资源管理器（Resource Manager）：提供 非代码资源的访问，如本地字符串，图形，和布局文件（ layout files ）。 通知管理器 （Notification Manager）：使得应用程序可以在状态栏中显示自定义的提示信息。 活动管理器（ Activity Manager）：用来管理应用程序生命周期并提供常用的导航回退功能。 系统运行库与Android运行环境(Libraris & Android Runtime) 系统运行库 Android 包含一些C/C++库，这些库能被Android系统中不同的组件使用。它们通过 Android 应用程序框架为开发者提供服务。以下是一些核心库： Bionic系统 C 库 - 一个从 BSD 继承来的标准 C 系统函数库（ libc ）， 它是专门为基于 embedded linux 的设备定制的。 媒体库 - 基于 PacketVideo OpenCORE；该库支持多种常用的音频、视频格式回放和录制，同时支持静态图像文件。编码格式包括MPEG4, H.264, MP3, AAC, AMR, JPG, PNG 。 Surface Manager - 对显示子系统的管理，并且为多个应用程序提 供了2D和3D图层的无缝融合。这部分代码 Webkit,LibWebCore - 一个最新的web浏览器引擎用，支持Android浏览器和一个可嵌入的web视图。鼎鼎大名的 Apple Safari背后的引擎就是Webkit SGL - 底层的2D图形引擎 3D libraries - 基于OpenGL ES 1.0 APIs实现；该库可以使用硬件 3D加速（如果可用）或者使用高度优化的3D软加速。 FreeType -位图（bitmap）和矢量（vector）字体显示。 SQLite - 一个对于所有应用程序可用，功能强劲的轻型关系型数据库引擎。 Android运行环境 该核心库提供了JAVA编程语言核心库的大多数功能。每一个Android应用程序都在它自己的进程中运 行，都拥有一个独立的Dalvik虚拟 机实例。Dalvik被设计成一个设备可以同时高效地运行多个虚拟系统。 Dalvik虚拟机执行（.dex）的Dalvik可执行文件，该格式文件针对小内存使用做了 优化。同时虚拟机是基于寄存器的，所有的类都经由JAVA编译器编译，然后通过SDK中 的 \"dx\" 工具转化成.dex格式由虚拟机执行。 HAL--硬件抽象层 其实Android并非讲所有的设备驱动都放在linux内核里面，而是实现在userspace空间，这么做的主要原因是GPL协议，Linux是遵循该协议来发布的，也就意味着对linux内核的任何修改，都必须发布其源代码。而现在这么做就可以避开而无需发布其源代码，毕竟它是用来赚钱的。而在linux内核中为这些userspace驱动代码开一个后门，就可以让本来userspace驱动不可以直接控制的硬件可以被访问。而只需要公布这个后门代码即可。一般情况下如果要将Android移植到其他硬件去运行，只需要实现这部分代码即可。包括：显示器驱动，声音，相机，GPS,GSM等等 Linux内核(Linux Kernel) Android的核心系统服务依赖于Linux 2.6 内核，如安全性，内存管理，进程管理， 网络协议栈和驱动模型。 Linux 内核也同时作为硬件和软件栈之间的抽象层。其外还对其做了部分修改，主要涉及两部分修改： Binder (IPC)：提供有效的进程间通信，虽然linux内核本身已经提供了这些功能，但Android系统很多服务都需要用到该功能，为了某种原因其实现了自己的一套。 电源管理：主要是为了省电，毕竟是手持设备嘛，低耗电才是我们的追求。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/lifecicle.html":{"url":"android/lifecicle.html","title":"Activity && Service生命周期","keywords":"","body":"Activity && Service生命周期 Activity生命周期 在上面的图中存在不同状态之间的过渡，但是，这些状态中只有三种可以是静态，也就是说 Activity 只能在三种状态之一下存在很长时间。 继续：在这种状态下，Activity处于前台，且用户可以与其交互（又称为运行态，在调用 onResume() 方法调用后）。 暂停：在这种状态下，Activity被在前台中处于半透明状态或者未覆盖整个屏幕的另一个Activity—部分阻挡。 暂停的Activity不会接收用户输入并且无法执行任何代码。 停止：在这种状态下，Activity被完全隐藏并且对用户不可见；它被视为处于后台。 停止时，Activity实例及其诸如成员变量等所有状态信息将保留，但它无法执行任何代码。 其他状态（“创建”和“开始”）是瞬态，系统会通过调用下一个生命周期回调方法从这些状态快速移到下一个状态。 也就是说，在系统调用 onCreate() 之后，它会快速调用 onStart()，紧接着快速调用 onResume()。 创建和销毁 创建一个新实例 大多数应用包含若干个不同的Activity，用户可通过这些Activity执行不同的操作。无论Activity是用户单击您的应用图标时创建的主Activity还是您的应用在响应用户操作时开始的其他Activity，系统都会通过调用其 onCreate() 方法创建 Activity 的每个新实例。 一旦 onCreate() 完成执行操作，系统会相继调用 onStart() 和 onResume() 方法，您的Activity从不会驻留在“已创建”或“已开始”状态。在技术上，Activity会在 onStart() 被调用时变得可见，但紧接着是 onResume()，且Activity保持“运行”状态，直到有事情发生使其发生变化，比如当接听来电时，用户导航至另一个Activity，或设备屏幕关闭。 销毁Activity 当Activity的第一个生命周期回调是 onCreate() 时，它最终的回调是 onDestroy()。系统会对您的Activity调用此方法，作为Activity实例完全从系统内存删除的最终信号。 在所有情况下，系统在调用 onPause() 和 onStop() 之后都会调用 onDestroy() ，只有一个例外：当您从 onCreate() 方法内调用 finish() 时。在有些情况下，比如当您的Activity作为临时决策工具运行以启动另一个Activity时，您可从 onCreate() 内调用 finish() 来销毁Activity。 在这种情况下，系统会立刻调用 onDestroy()，而不调用任何其他生命周期方法。 暂停和继续 在正常使用应用的过程中，前台 Activity 有时会被其他导致 Activity 暂停 的可视组件阻挡。 例如，当半透明Activity打开时（比如对话框样式中的Activity），上一个Activity会暂停。只要 Activity 仍然部分可见但目前又未处于焦点之中，它会一直暂停。但是，一旦Activity完全被阻挡并且不可见，它便停止。 当 Activity 进入暂停状态时，系统会对调用 onPause() 方法，通过该方法，您可以停止不应在暂停时继续的进行之中的操作（比如视频）或保留任何应该永久保存的信息，以防用户坚持离开应用。如果用户从暂停状态返回到您的 Activity ，系统会重新开始该Activity并调用 onResume() 方法。 暂停Activity 当系统为 Activity 调用 onPause() 时，它从技术角度看意味着 Activity 仍然处于部分可见状态，但往往说明用户即将离开Activity并且它很快就要进入“停止”状态。 您通常应使用 onPause() 回调： 停止动画或其他可能消耗 CPU 的进行之中的操作。 提交未保存的更改，但仅当用户离开时希望永久性保存此类更改（比如电子邮件草稿）。 释放系统资源，比如广播接收器、传感器手柄（比如 GPS） 或当您的Activity暂停且用户不需要它们时仍然可能影响电池寿命的任何其他资源。 避免在 onPause() 期间执行 CPU 密集型工作，比如向数据库写入信息，因为这会拖慢向下一 Activity 过渡的过程（应改为在 onStop() 期间执行高负载操作。 继续Activity 当用户从“暂停”状态继续您的Activity时，系统会调用 onResume() 方法。 请注意，每当 Activity 进入前台时系统便会调用此方法，包括它初次创建之时。 同样地，应实现 onResume() 初始化在 onPause() 期间释放的组件并且执行每当 Activity 进入“继续”状态时必须进行的任何其他初始化操作（比如开始动画和初始化只在 Activity 具有用户焦点时使用的组件）。 停止并重新开始 几种 Activity 停止和重新开始的关键场景： 用户打开“最近应用”窗口并从您的应用切换到另一个应用。当前位于前台的您的应用中的 Activity 将停止。 如果用户从主屏幕启动器图标或“最近应用”窗口返回到您的应用， Activity 会重新开始。 用户在您的应用中执行开始新 Activity 的操作。当第二个 Activity 创建好后，当前 Activity 便停止。如果用户之后按了返回按钮，第一个 Activity 会重新开始。 用户在其手机上使用您的应用的同时接听来电。 不同于识别部分 UI 阻挡的暂停状态，停止状态保证 UI 不再可见，且用户的焦点在另外的Activity（或完全独立的应用）中。 停止Activity 当您的Activity收到 onStop() 方法的调用时，它不再可见，并且应释放几乎所有用户不使用时不需要的资源。 一旦您的 Activity 停止，如果需要恢复系统内存，系统可能会销毁该实例。 在极端情况下，系统可能会仅终止应用进程，而不会调用Activity的最终 onDestroy() 回调，因此您使用 onStop() 释放可能泄露内存的资源非常重要。 尽管 onPause() 方法在 onStop()之前调用，您应使用 onStop() 执行更大、占用更多 CPU 的关闭操作，比如向数据库写入信息。 当您的Activity停止时， Activity 对象将驻留在内存中并在 Activity 继续时被再次调用。 您无需重新初始化在任何导致进入“继续”状态的回调方法过程中创建的组件。 系统还会在布局中跟踪每个 View 的当前状态，如果用户在 EditText 小工具中输入文本，该内容会保留，因此您无需保存即可恢复它。 即使系统在 Activity 停止时销毁了 Activity ，它仍会保留 Bundle（键值对的二进制大对象）中的 View 对象（比如 EditText 中的文本），并在用户导航回 Activity 的相同实例时恢复它们 开始/重新开始Activity 当您的Activity从停止状态返回前台时，它会接收对 onRestart() 的调用。系统还会在每次您的Activity变为可见时调用 onStart() 方法（无论是正重新开始还是初次创建）。 但是，只会在Activity从停止状态继续时调用 onRestart() 方法，因此您可以使用它执行只有在Activity之前停止但未销毁的情况下可能必须执行的特殊恢复工作。您应经常使用 onStart() 回调方法作为 onStop() 方法的对应部分，因为系统会在它创建您的Activity以及从停止状态重新开始Activity时调用onStart()。 重新创建 在有些情况下，您的 Activity 会因正常应用行为而销毁，比如当用户按 返回按钮 或您的 Activity 通过调用finish()示意自己的销毁。 如果 Activity 当前被停止或长期未使用，或者前台Activity需要更多资源以致系统必须关闭后台进程恢复内存，系统也可能会销毁Activity。 当您的Activity因用户按了 返回 或Activity自行完成而被销毁时，系统的 Activity 实例概念将永久消失。 但是，如果系统因系统局限性（而非正常应用行为）而销毁Activity，尽管 Activity 实际实例已不在，系统会记住其存在，这样，如果用户导航回实例，系统会使用描述 Activity 被销毁时状态的一组已保存数据创建 Activity 的新实例。 系统用于恢复先前状态的已保存数据被称为“实例状态”，并且是 Bundle 对象中存储的键值对集合。 默认情况下，系统会使用 Bundle 实例状态保存您的 Activity 布局（比如，输入到 EditText 对象中的文本值）中有关每个 View 对象的信息。 这样，如果您的Activity实例被销毁并重新创建，布局状态便恢复为其先前的状态，且您无需代码。 但是，您的Activity可能具有您要恢复的更多状态信息，比如跟踪用户在 Activity 中进度的成员变量。 为了 Android 系统恢复Activity中视图的状态，每个视图必须具有 android:id 属性提供的唯一 ID。 要保存有关 Activity 状态的其他数据，您必须替代 onSaveInstanceState() 回调方法。当用户要离开 Activity 并在 Activity 意外销毁时向其传递将保存的 Bundle 对象时，系统会调用此方法。 如果系统必须稍后重新创建Activity实例，它会将相同的 Bundle 对象同时传递给 onRestoreInstanceState() 和 onCreate() 方法。 保存Activity状态 当您的Activity开始停止时，系统会调用 onSaveInstanceState() 以便您的Activity可以保存带有键值对集合的状态信息。 此方法的默认实现保存有关Activity视图层次的状态信息（只保存部分 View ），例如 EditText 小工具中的文本或ListView 的滚动位置。要保存Activity的更多状态信息，您必须实现 onSaveInstanceState() 并将键值对添加至 Bundle 对象。 如果当系统配置改变时，不希望重建Activity，可以给Activity指定configChanges属性。当被配置的系统配置发生改变时会调用onConfigurationChanged()方法，而不会调用onSaveInstanceState()。 onSaveInstanceState() 的调用时机是不明确的，但是如果调用就一定会在 onStop()之前。 恢复Activity状态 当您的Activity在先前销毁之后重新创建时，您可以从系统向Activity传递的 Bundle 恢复已保存的状态。onCreate() 和 onRestoreInstanceState() 回调方法均接收包含实例状态信息的相同 Bundle。 因为无论系统正在创建Activity的新实例还是重新创建先前的实例，都会调用 onCreate() 方法，因此您必须在尝试读取它之前检查状态 Bundle 是否为 null。 如果为 null，则系统将创建Activity的新实例，而不是恢复已销毁的先前实例。 Service生命周期 Start Service：通过context.startService()启动，这种service可以无限制的运行，除非调用stopSelf()或者其他组件调用context.stopService()。 Bind Service：通过context.bindService()启动，客户可以通过IBinder接口和service通信，客户可以通过context.unBindService()取消绑定。一个service可以和多个客户绑定，当所有客户都解除绑定后，service将终止运行。 一个通过context.startService()方法启动的service，其他组件也可以通过context.bindService()与它绑定，在这种情况下，不能使用stopSelf()或者context.stopService()停止service，只能当所有客户解除绑定在调用context.stopService()才会终止。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/launchmod.html":{"url":"android/launchmod.html","title":"Activity四种启动模式","keywords":"","body":"Activity四种启动模式 Standard 标准模式。每次启动Activity都会创建新的实例。谁启动了这个Activity，那么这个Activity就运行在谁的Task中。不能使用非Activity类型的context启动这种模式的Activity，因为这种context并没有Task，这个时候就可以加一个FLAG_ACTIVITY_NEW_TASK标记位，这个时候启动Activity实际上是以singleTask模式启动。 SingleTop 栈顶复用模式。如果当前栈顶是要启动的Activity，那么直接引用，如果不是，则新建。在直接引用的时候会调用onNewIntent()方法。 适合接收通知启动的内容显示页面，或者从外界可能多次跳转到一个界面。 SingleTask 栈内复用模式。这种模式下，只要Activity只要在一个栈内存在，那么就不会创建新的实例，会调用onNewIntent()方法。 如果要调用的Activity在同一应用中：调用singleTask模式的Activity会清空在它之上的所有Activity。 若其他应用启动该Activity：如果不存在，则建立新的Task。如果已经存在后台，那么启动后，后台的Task会一起被切换到前台。 适合作为程序入口点，例如浏览器的主界面。不管从多少个应用启动浏览器，只会启动主界面一次，其余情况都会走onNewIntent，并且会清空主界面上面的其他页面。 SingleInstance 单实例模式。这时一种加强的singleTask，它除了具有singleTask的所有特性外，还加强了一点--该模式的Activity只能单独的位于一个Task中。 不同Task之间，默认不能传递数据(startActivityForResult())，如果一定要传递，只能使用Intent绑定。 适合需要与程序分离开的页面。例如闹铃提醒，将闹铃提醒与闹铃设置分离。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/listview.html":{"url":"android/listview.html","title":"ListView原理及优化","keywords":"","body":"ListView原理及优化 原理 ListView的实现离不开Adapter。可以这么理解：ListView中给出了数据来的时候，View如何实现的具体方式，相当于MVC中的V；而Adapter提供了相当于MVC中的C，指挥了ListView的数据加载等行为。 提一个问题：假设ListView中有10W个条项，那内存中会缓存10W个吗？答案当然是否定的。那么是如何实现的呢？下面这张图可以清晰地解释其中的原理: 可以看到当一个View移出可视区域的时候，设为View1，它会被标记Recycle，然后可能： 新进入的View2与View1类型相同，那么在getView方法传入的convertView就不是null而就是View1。换句话说，View1被重用了 新进入的View2与View1类型不同，那么getView传入的convertView就是null，这是需要new一个View。当内存紧张时，View1就会被GC ListView的优化(以异步加载Bitmap优化为例) 首先概括的说ListView优化分为三级缓存: 内存缓存 文件缓存 网络读取 简要概括就是在getView中，如果加载过一个图片，放入Map类型的一个MemoryCache中(示例代码使用的是Collections.synchronizedMap(new LinkedHashMap(10, 1.5f, true))来维护一个试用LRU的堆)。如果这里获取不到，根据View被Recycle之前放入的TAG中记录的uri从文件系统中读取文件缓存。如果本地都找不到，再去网络中异步加载。 这里有几个注意的优化点： 从文件系统中加载图片也没有内存中加载那么快，甚至可能内存中加载也不够快。因此在ListView中应设立busy标志位，当ListView滚动时busy设为true，停止各个view的图片加载。否则可能会让UI不够流畅用户体验度降低。 文件加载图片放在子线程实现，否则快速滑动屏幕会卡 开启网络访问等耗时操作需要开启新线程，应使用线程池避免资源浪费，最起码也要用AsyncTask。 Bitmap从网络下载下来最好先放到文件系统中缓存。这样一是方便下一次加载根据本地uri直接找到，二是如果Bitmap过大，从本地缓存可以方便的使用Option.inSampleSize配合Bitmap.decodeFile(ui, options)或Bitmap.createScaledBitmap来进行内存压缩 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/handler.html":{"url":"android/handler.html","title":"Android中Handler机制","keywords":"","body":"Android中Handler机制 1.Looper.prepare 首先从ThreadLocal中获取一个Looper，如果没有则向ThreadLocal中添加一个new Looper，同时新建一个MessageQueue。 主线程的Looper在ActivityThread创建。 ThreadLocal ThreadLocal是Java提供的用于保存同一进程中不同线程数据的一种机制。每个线程中都保有一个ThreadLocalMap的成员变量，ThreadLocalMap内部采用WeakReference数组保存，数组的key即为ThreadLocal内部的Hash值。 2.Looper.loop 循环调用MessageQueue.next获取消息，该函数在MessageQueue中没有消息的时候会阻塞，这里采用了epoll的I/O多路复用机制。当获取到一个消息的时候会返回。 3.Mseeage.target.dispatchMessage 在loop中获取到消息后，会调用Message内部的Handler引用并分派事件。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/broadcast.html":{"url":"android/broadcast.html","title":"Android广播机制","keywords":"","body":"Android广播机制 广播(Broadcast)机制用于进程/线程间通信，广播分为广播发送和广播接收两个过程，其中广播接收者BroadcastReceiver便是Android四大组件之一。 BroadcastReceiver分为两类： 静态广播接收者：通过AndroidManifest.xml的标签来申明的BroadcastReceiver。 动态广播接收者：通过AMS.registerReceiver()方式注册的BroadcastReceiver，动态注册更为灵活，可在不需要时通过unregisterReceiver()取消注册。 从广播发送方式可分为三类： 普通广播：通过Context.sendBroadcast()发送，可并行处理 有序广播：通过Context.sendOrderedBroadcast()发送，串行处理 Sticky广播：通过Context.sendStickyBroadcast()发送，发出的广播会一直滞留（等待），以便有人注册这则广播消息后能尽快的收到这条广播。 Android 中的 Broadcast 实际底层使用Binder机制。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/draw.html":{"url":"android/draw.html","title":"View绘制过程","keywords":"","body":"View绘制过程 整个View树的绘图流程是在ViewRootImpl类的performTraversals()方法（这个方法巨长）开始的，该函数做的执行过程主要是根据之前设置的状态，判断是否重新计算视图大小(measure)、是否重新放置视图的位置(layout)、以及是否重绘 (draw)。 Measure 通过上面可以看出measure过程主要就是从顶层父View向子View递归调用view.measure方法（measure中又回调onMeasure方法）的过程。具体measure核心主要有如下几点： MeasureSpec（View的内部类）测量规格为int型，值由高2位规格模式specMode和低30位具体尺寸specSize组成。其中specMode只有三种值： MeasureSpec.EXACTLY //确定模式，父View希望子View的大小是确定的，由specSize决定； MeasureSpec.AT_MOST //最多模式，父View希望子View的大小最多是specSize指定的值； MeasureSpec.UNSPECIFIED //未指定模式，父View完全依据子View的设计值来决定； View的 measure 方法是final的，不允许重载，View子类只能重载onMeasure来完成自己的测量逻辑。 最顶层DecorView测量时的MeasureSpec是由ViewRootImpl中getRootMeasureSpec方法确定的，LayoutParams宽高参数均为MATCH_PARENT，specMode是EXACTLY，specSize为物理屏幕大小。 ViewGroup类提供了measureChild，measureChild和measureChildWithMargins方法，简化了父子View的尺寸计算。 只要是ViewGroup的子类就必须要求LayoutParams继承子MarginLayoutParams，否则无法使用layout_margin参数。 View的布局大小由父View和子View共同决定。 使用View的getMeasuredWidth()和getMeasuredHeight()方法来获取View测量的宽高，必须保证这两个方法在onMeasure流程之后被调用才能返回有效值。 Layout layout方法接收四个参数，这四个参数分别代表相对Parent的左、上、右、下坐标。而且还可以看见左上都为0，右下分别为上面刚刚测量的width和height。 整个layout过程比较容易理解，从上面分析可以看出layout也是从顶层父View向子View的递归调用view.layout方法的过程，即父View根据上一步measure子View所得到的布局大小和布局参数，将子View放在合适的位置上。具体layout核心主要有以下几点： View.layout方法可被重载，ViewGroup.layout为final的不可重载，ViewGroup.onLayout为abstract的，子类必须重载实现自己的位置逻辑。 measure操作完成后得到的是对每个View经测量过的measuredWidth和measuredHeight，layout操作完成之后得到的是对每个View进行位置分配后的mLeft、mTop、mRight、mBottom，这些值都是相对于父View来说的。 凡是layout_XXX的布局属性基本都针对的是包含子View的ViewGroup的，当对一个没有父容器的View设置相关layout_XXX属性是没有任何意义的。 使用View的getWidth()和getHeight()方法来获取View测量的宽高，必须保证这两个方法在onLayout流程之后被调用才能返回有效值。 Draw ViewRootImpl中的代码会创建一个Canvas对象，然后调用View的draw()方法来执行具体的绘制工作。 可以看见，绘制过程就是把View对象绘制到屏幕上，整个draw过程需要注意如下细节： 如果该View是一个ViewGroup，则需要递归绘制其所包含的所有子View。 View默认不会绘制任何内容，真正的绘制都需要自己在子类中实现。 View的绘制是借助onDraw方法传入的Canvas类来进行的。 区分View动画和ViewGroup布局动画，前者指的是View自身的动画，可以通过setAnimation添加，后者是专门针对ViewGroup显示内部子视图时设置的动画，可以在xml布局文件中对ViewGroup设置layoutAnimation属性。 在获取画布剪切区（每个View的draw中传入的Canvas）时会自动处理掉padding，子View获取Canvas不用关注这些逻辑，只用关心如何绘制即可。 默认情况下子View的ViewGroup.drawChild绘制顺序和子View被添加的顺序一致，但是你也可以重载ViewGroup.getChildDrawingOrder()方法提供不同顺序。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/canvas.html":{"url":"android/canvas.html","title":"Canvas使用","keywords":"","body":"Canvas使用 save：用来保存 Canvas 的状态。save 之后，可以调用 Canvas 的平移、放缩、旋转、错切、裁剪等操作。 restore：用来恢复Canvas之前保存的状态。防止 save 后对 Canvas 执行的操作对后续的绘制有影响。 save 和 restore 要配对使用( restore 可以比 save 少，但不能多)，如果 restore 调用次数比 save 多，会引发 Error 。save 和 restore 之间，往往夹杂的是对 Canvas 的特殊操作。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/event.html":{"url":"android/event.html","title":"事件分发机制","keywords":"","body":"事件分发机制 事件的分发机制由三个重要方法来共同完成：dispatchTouchEvent、onInterceptTouchEvent和onTouchEvent 事件分发：public boolean dispatchTouchEvent(MotionEvent ev)：用来进行事件的分发。如果事件能够传递给当前View，那么此方法一定会被调用，返回结果受当前View的onTouchEvent和下级View的DispatchTouchEvent方法的影响，表示是否消耗当前事件。 事件拦截：public boolean onInterceptTouchEvent(MotionEvent event)：在上述方法内部调用，用来判断是否拦截某个事件，如果当前View拦截了某个事件，那么在同一个事件序列当中，此方法不会被再次调用，返回结果表示是否拦截当前事件。 事件响应：public boolean onTouchEvent(MotionEvent event)：在dispatchTouchEvent方法中调用，用来处理点击事件，返回结果表示是否消耗当前事件，如果不消耗，则在同一个事件序列中，当前View无法再次接收到事件。 三者的关系可以总结为如下伪代码： public boolean dispatchTouchEvent(MotionEvent ev) { boolean consume = false; if (onInterceptTouchEvent(ev)) { consume = onTouchEvent(ev); } else { consume = child.dispatchTouchEvent(ev); } return consume; } 同一个事件序列是从手指触摸屏幕的那一刻起，到手指离开屏幕那一刻结束，这个过程中所产生的一系列事件。这个事件序列以down事件开始，中间含有数量不定的move事件，最终以up事件结束。 一个事件序列只能被一个View拦截且消耗，不过通过事件代理TouchDelegate，可以将onTouchEvent强行传递给其他View处理。 某个View一旦决定拦截，那么这一事件序列就都只能由它来处理。 某个View一旦开始处理事件，如果不消耗ACTION_DOWN事件（onTouchEvent返回了false），那么事件会重新交给它的父元素处理，即父元素的onTouchEvent会被调用。 如果View不消耗除ACTION_DOWN以外的事件，那么这个点击事件会消失，此时父元素的onTouchEvent并不会调用，并且当前View可以持续收到后续的事件（Android系统通过一个标记来解决），最终这些消失的事件会传递到Activity。 ViewGroup默认不拦截任何事件。Android源码中ViewGroup的onInterceptTouchEvent方法默认返回false。 View没有onIntercepteTouchEvent方法，一旦有点击事件传递给它，那么它的onTouchEvent方法就会被调用。 View的onTouchEvent默认都不会消耗事件（返回false），除非它是可点击的（clickable和longClickable有一个为true）。View的longClickable默认都为false，clickable要分情况看，比如Button默认为true，TextView默认为false。 View的enable属性不影响onTouchEvent的默认返回值。哪怕一个View是disable状态，只要它的clickable或者longClickable有一个为true，那么它的onTouchEvent就返回true。 onClick会发生的前提是当前View是可点击的，并且它受到down和up的事件。 事件传递是由外向内的，即事件总是先传递给父元素，然后再由父元素分发给子View，通过requestDisallowInterceptTouchEvent方法就可以在子元素中干扰父元素的事件分发过程，但ACTION_DOWN事件除外。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/binder.html":{"url":"android/binder.html","title":"Binder","keywords":"","body":"Binder 简介 Binder使用Client－Server通信方式。Binder框架定义了四个角色：Server,Client,ServiceManager以及Binder驱动。其中Server,Client,ServiceManager运行于用户空间，驱动运行于内核空间。Binder驱动程序提供设备文件/dev/binder与用户空间交互，Client、Server和Service Manager通过open和ioctl文件操作函数与Binder驱动程序进行通信。 Binder原理简述 Server创建了Binder实体，为其取一个字符形式，可读易记的名字。 将这个Binder连同名字以数据包的形式通过Binder驱动发送给ServiceManager，通知ServiceManager注册一个名字为XX的Binder，它位于Server中。 驱动为这个穿过进程边界的Binder创建位于内核中的实体结点以及ServiceManager对实体的引用，将名字以及新建的引用打包给ServiceManager。 ServiceManager收数据包后，从中取出名字和引用填入一张查找表中。但是一个Server若向ServiceManager注册自己Binder就必须通过这个引用和ServiceManager的Binder通信。 Server向ServiceManager注册了Binder实体及其名字后，Client就可以通过名字获得该Binder的引用了。Clent也利用保留的引用向ServiceManager请求访问某个Binder：我申请名字叫XX的Binder的引用。 ServiceManager收到这个连接请求，从请求数据包里获得Binder的名字，在查找表里找到该名字对应的条目，从条目中取出Binder引用，将该引用作为回复发送给发起请求的Client。 当然，不是所有的Binder都需要注册给ServiceManager广而告之的。Server端可以通过已经建立的Binder连接将创建的Binder实体传给Client，当然这条已经建立的Binder连接必须是通过实名Binder实现。由于这个Binder没有向ServiceManager注册名字，所以是 匿名Binder。Client将会收到这个匿名Binder的引用，通过这个引用向位于Server中的实体发送请求。匿名Binder为通信双方建立一条私密通道，只要Server没有把匿名Binder发给别的进程，别的进程就无法通过穷举或猜测等任何方式获得该Binder的引用，向该Binder发送请求。 Binder的数据拷贝 Linux内核实际上没有从一个用户空间到另一个用户空间直接拷贝的函数，需要先用copy_from_user()拷贝到内核空间，再用copy_to_user()拷贝到另一个用户空间。为了实现用户空间到用户空间的拷贝，mmap()分配的内存除了映射进了接收方进程里，还映射进了内核空间。所以调用copy_from_user()将数据拷贝进内核空间也相当于拷贝进了接收方的用户空间，这就是Binder只需一次拷贝的\"秘密\"。 最底层的是Android的ashmen(Anonymous shared memory)机制，它负责辅助实现内存的分配，以及跨进程所需要的内存共享。AIDL(android interface definition language)对Binder的使用进行了封装，可以让开发者方便的进行方法的远程调用，后面会详细介绍。Intent是最高一层的抽象，方便开发者进行常用的跨进程调用。 使用共享内存通信的一个显而易见的好处是效率高，因为 进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次内存数据：一次从输入文件到共享内存区，另一次从共享内存到输出文件。实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域，而是保持共享区域，直到通信完成为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除内存映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/optimize.html":{"url":"android/optimize.html","title":"性能优化","keywords":"","body":"性能优化 ANR ANR全称Application Not Responding，意思就是程序未响应。 出现场景 主线程被IO操作（从4.0之后网络IO不允许在主线程中）阻塞。 主线程中存在耗时的计算 主线程中错误的操作，比如Thread.wait或者Thread.sleep等 Android系统会监控程序的响应状况，一旦出现下面两种情况，则弹出ANR对话框 应用在5秒内未响应用户的输入事件（如按键或者触摸） BroadcastReceiver未在10秒内完成相关的处理 如何避免 基本的思路就是将IO操作在工作线程来处理，减少其他耗时操作和错误操作 使用AsyncTask处理耗时IO操作。 使用Thread或者HandlerThread时，调用Process.setThreadPriority(Process.THREAD_PRIORITY_BACKGROUND)设置优先级，否则仍然会降低程序响应，因为默认Thread的优先级和主线程相同。 使用Handler处理工作线程结果，而不是使用Thread.wait()或者Thread.sleep()来阻塞主线程。 Activity的onCreate和onResume回调中尽量避免耗时的代码 BroadcastReceiver中onReceive代码也要尽量减少耗时，建议使用IntentService处理。 如何改善 通常100到200毫秒就会让人察觉程序反应慢，为了更加提升响应，可以使用下面的几种方法 如果程序正在后台处理用户的输入，建议使用让用户得知进度，比如使用ProgressBar控件。 程序启动时可以选择加上欢迎界面，避免让用户察觉卡顿。 使用Systrace和TraceView找出影响响应的问题。 如果开发机器上出现问题，我们可以通过查看/data/anr/traces.txt即可，最新的ANR信息在最开始部分。 OOM 在实践操作当中，可以从四个方面着手减小内存使用，首先是减小对象的内存占用，其次是内存对象的重复利用，然后是避免对象的内存泄露，最后是内存使用策略优化。 减小对象的内存占用 使用更加轻量级的数据结构：例如，我们可以考虑使用ArrayMap/SparseArray而不是HashMap等传统数据结构，相比起Android系统专门为移动操作系统编写的ArrayMap容器，在大多数情况下，HashMap都显示效率低下，更占内存。另外，SparseArray更加高效在于，避免了对key与value的自动装箱，并且避免了装箱后的解箱。 避免使用Enum：在Android中应该尽量使用int来代替Enum，因为使用Enum会导致编译后的dex文件大小增大，并且使用Enum时，其运行时还会产生额外的内存占用。 减小Bitmap对象的内存占用： inBitmap：如果设置了这个字段，Bitmap在加载数据时可以复用这个字段所指向的bitmap的内存空间。但是，内存能够复用也是有条件的。比如，在Android 4.4(API level 19)之前，只有新旧两个Bitmap的尺寸一样才能复用内存空间。Android 4.4开始只要旧 Bitmap 的尺寸大于等于新的 Bitmap 就可以复用了。 inSampleSize：缩放比例，在把图片载入内存之前，我们需要先计算出一个合适的缩放比例，避免不必要的大图载入。 decode format：解码格式，选择ARGB_8888 RBG_565 ARGB_4444 ALPHA_8，存在很大差异。 ARGB_4444：每个像素占四位，即A=4，R=4，G=4，B=4，那么一个像素点占4+4+4+4=16位 ARGB_8888：每个像素占四位，即A=8，R=8，G=8，B=8，那么一个像素点占8+8+8+8=32位 RGB_565：每个像素占四位，即R=5，G=6，B=5，没有透明度，那么一个像素点占5+6+5=16位 ALPHA_8：每个像素占四位，只有透明度，没有颜色。 使用更小的图片：在设计给到资源图片的时候，我们需要特别留意这张图片是否存在可以压缩的空间，是否可以使用一张更小的图片。尽量使用更小的图片不仅仅可以减少内存的使用，还可以避免出现大量的InflationException。假设有一张很大的图片被XML文件直接引用，很有可能在初始化视图的时候就会因为内存不足而发生InflationException，这个问题的根本原因其实是发生了OOM。 内存对象的重复使用 大多数对象的复用，最终实施的方案都是利用对象池技术，要么是在编写代码的时候显式的在程序里面去创建对象池，然后处理好复用的实现逻辑，要么就是利用系统框架既有的某些复用特性达到减少对象的重复创建，从而减少内存的分配与回收。 复用系统自带资源：Android系统本身内置了很多的资源，例如字符串/颜色/图片/动画/样式以及简单布局等等，这些资源都可以在应用程序中直接引用。这样做不仅仅可以减少应用程序的自身负重，减小APK的大小，另外还可以一定程度上减少内存的开销，复用性更好。但是也有必要留意Android系统的版本差异性，对那些不同系统版本上表现存在很大差异，不符合需求的情况，还是需要应用程序自身内置进去。 ListView ViewHodler Bitmap对象的复用：在ListView与GridView等显示大量图片的控件里面需要使用LRU的机制来缓存处理好的Bitmap。 inBitmap：使用inBitmap属性可以告知Bitmap解码器去尝试使用已经存在的内存区域，新解码的bitmap会尝试去使用之前那张bitmap在heap中所占据的pixel data内存区域，而不是去问内存重新申请一块区域来存放bitmap。 使用inBitmap，在4.4之前，只能重用相同大小的bitmap的内存区域，而4.4之后你可以重用任何bitmap的内存区域，只要这块内存比将要分配内存的bitmap大就可以。这里最好的方法就是使用LRUCache来缓存bitmap，后面来了新的bitmap，可以从cache中按照api版本找到最适合重用的bitmap，来重用它的内存区域。 新申请的bitmap与旧的bitmap必须有相同的解码格式 避免在onDraw方法里面执行对象的创建：类似onDraw等频繁调用的方法，一定需要注意避免在这里做创建对象的操作，因为他会迅速增加内存的使用，而且很容易引起频繁的gc，甚至是内存抖动。 StringBuilder：在有些时候，代码中会需要使用到大量的字符串拼接的操作，这种时候有必要考虑使用StringBuilder来替代频繁的“+”。 避免内存泄漏 内部类引用导致Activity的泄漏：最典型的场景是Handler导致的Activity泄漏，如果Handler中有延迟的任务或者是等待执行的任务队列过长，都有可能因为Handler继续执行而导致Activity发生泄漏。 Activity Context被传递到其他实例中，这可能导致自身被引用而发生泄漏。 考虑使用Application Context而不是Activity Context 注意临时Bitmap对象的及时回收 注意监听器的注销 注意缓存容器中的对象泄漏：不使用的对象要将引用置空。 注意Cursor对象是否及时关闭 内存优化策略 综合考虑设备内存阈值与其他因素设计合适的缓存大小 onLowMemory()：Android系统提供了一些回调来通知当前应用的内存使用情况，通常来说，当所有的background应用都被kill掉的时候，forground应用会收到onLowMemory()的回调。在这种情况下，需要尽快释放当前应用的非必须的内存资源，从而确保系统能够继续稳定运行。 onTrimMemory()：Android系统从4.0开始还提供了onTrimMemory()的回调，当系统内存达到某些条件的时候，所有正在运行的应用都会收到这个回调，同时在这个回调里面会传递以下的参数，代表不同的内存使用情况，收到onTrimMemory()回调的时候，需要根据传递的参数类型进行判断，合理的选择释放自身的一些内存占用，一方面可以提高系统的整体运行流畅度，另外也可以避免自己被系统判断为优先需要杀掉的应用 资源文件需要选择合适的文件夹进行存放：例如我们只在hdpi的目录下放置了一张100100的图片，那么根据换算关系，xxhdpi的手机去引用那张图片就会被拉伸到200200。需要注意到在这种情况下，内存占用是会显著提高的。对于不希望被拉伸的图片，需要放到assets或者nodpi的目录下。 谨慎使用static对象 优化布局层次，减少内存消耗 使用FlatBuffer等工具序列化数据 谨慎使用依赖注入框架 使用ProGuard来剔除不需要的代码 卡顿优化 导致Android界面滑动卡顿主要有两个原因： UI线程（main）有耗时操作 视图渲染时间过长，导致卡顿 众所周知，界面的流畅度主要依赖FPS这个值，这个值是通过（1s/渲染1帧所花费的时间）计算所得，FPS值越大视频越流畅，所以就需要渲染1帧的时间能尽量缩短。正常流畅度的FPS值在60左右，即渲染一帧的时间不应大于16 ms。 如果想让应用流畅运行 ： 不要阻塞UI线程； 不要在UI线程之外操作UI； 减少UI嵌套层级 针对界面切换卡顿，一般出现在组件初始化的地方。屏幕滑动卡顿，ui嵌套层级，还有图片加载，图片的话，滑动不加载，监听scrollListener。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/push.html":{"url":"android/push.html","title":"推送机制","keywords":"","body":"推送机制 轮询 客户端隔一段时间就去服务器上获取一下信息，看是否有更新的信息出现，这就是轮询。我们可以通过AlarmManager来管理时间，当然时间的设置策略也是十分重要的，由于每次轮询都需要建立和释放TCP连接，所以在移动网络情况下耗电量相当大。 移动网络状态转换 针对不同应用的需求，有的可以每5分钟查询一次或者每10分钟查询一次，但是这种策略的电量和流量消耗十分严重。我们可以使用退避法（暂时这么说），比如第一次我们每隔2分钟查询一次数据，如果没有数据，就将查询间隔加倍。 同时进程的保活也十分重要，这部分的知识参照进程保活。 长连接 客户端主动和服务器建立TCP长连接之后，客户端定期向服务器发送心跳包，有消息的时候，服务器直接通过这个已经建立好的TCP连接通知客户端。 长连接就是 建立连接之后，不主动断开。双方互相发送数据，发完了也不主动断开连接，之后有需要发送的数据就继续通过这个连接发送。 影响TCP连接寿命的因素 NAT超时 因为 IPv4 的 IP 量有限，运营商分配给手机终端的 IP 是运营商内网的 IP，手机要连接 Internet，就需要通过运营商的网关做一个网络地址转换（Network Address Translation，NAT）。简单的说运营商的网关需要维护一个外网 IP、端口到内网 IP、端口的对应关系，以确保内网的手机可以跟 Internet 的服务器通讯。 NAT 功能由图中的 GGSN 模块实现。 大部分移动无线网络运营商都在链路一段时间没有数据通讯时，会淘汰 NAT 表中的对应项，造成链路中断。 DHCP租期 目前测试发现安卓系统对DHCP的处理有Bug，DHCP租期到了不会主动续约并且会继续使用过期IP，这个问题会造成TCP长连接偶然的断连。 网络状态变化 手机网络和WIFI网络切换、网络断开和连上等情况有网络状态的变化，也会使长连接变为无效连接，需要监听响应的网络状态变化事件，重新建立Push长连接。 心跳包 TCP长连接本质上不需要心跳包来维持，其主要是为了防止上面提到的NAT超时，既然一些NAT设备判断是否淘汰NAT映射的依据是一定时间没有数据，那么客户端就主动发一个数据，这样就能维持TCP长连接。 当然，如果仅仅是为了防止NAT超时，可以让服务器来发送心跳包给客户端，不过这样做有个弊病就是，万一连接断了，服务器就再也联系不上客户端了。所以心跳包必须由客户端发送，客户端发现连接断了，还可以尝试重连服务器。 时间间隔 发送心跳包势必要先唤醒设备，然后才能发送，如果唤醒设备过于频繁，或者直接导致设备无法休眠，会大量消耗电量，而且移动网络下进行网络通信，比在wifi下耗电得多。所以这个心跳包的时间间隔应该尽量的长，最理想的情况就是根本没有NAT超时，比如刚才我说的两台在同一个wifi下的电脑，完全不需要心跳包。这也就是网上常说的长连接，慢心跳。 现实是残酷的，根据网上的一些说法，中移动2/3G下，NAT超时时间为5分钟，中国电信3G则大于28分钟，理想的情况下，客户端应当以略小于NAT超时时间的间隔来发送心跳包。 心跳包和轮询的区别 轮询是为了获取数据，而心跳是为了保活TCP连接。 轮询得越频繁，获取数据就越及时，心跳的频繁与否和数据是否及时没有直接关系。 轮询比心跳能耗更高，因为一次轮询需要经过TCP三次握手，四次挥手，单次心跳不需要建立和拆除TCP连接。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/keep-live.html":{"url":"android/keep-live.html","title":"进程保活","keywords":"","body":"进程保活 进程生命周期 Android 系统将尽量长时间地保持应用进程，但为了新建进程或运行更重要的进程，最终需要清除旧进程来回收内存。 为了确定保留或终止哪些进程，系统会根据进程中正在运行的组件以及这些组件的状态，将每个进程放入“重要性层次结构”中。 必要时，系统会首先消除重要性最低的进程，然后是重要性略逊的进程，依此类推，以回收系统资源。 重要性层次结构一共有 5 级。以下列表按照重要程度列出了各类进程（第一个进程最重要，将是最后一个被终止的进程）： 前台进程：用户当前操作所必需的进程。如果一个进程满足以下任一条件，即视为前台进程： 托管用户正在交互的 Activity（已调用 Activity 的 onResume() 方法） 托管某个 Service，后者绑定到用户正在交互的 Activity 托管正在“前台”运行的 Service（服务已调用 startForeground()） 托管正执行一个生命周期回调的 Service（onCreate()、onStart() 或 onDestroy()） 托管正执行其 onReceive() 方法的 BroadcastReceiver 通常，在任意给定时间前台进程都为数不多。只有在内在不足以支持它们同时继续运行这一万不得已的情况下，系统才会终止它们。 此时，设备往往已达到内存分页状态，因此需要终止一些前台进程来确保用户界面正常响应。 可见进程：没有任何前台组件、但仍会影响用户在屏幕上所见内容的进程。 如果一个进程满足以下任一条件，即视为可见进程： 托管不在前台、但仍对用户可见的 Activity（已调用其 onPause() 方法）。例如，如果前台 Activity 启动了一个对话框，允许在其后显示上一 Activity，则有可能会发生这种情况 托管绑定到可见（或前台）Activity 的 Service 可见进程被视为是极其重要的进程，除非为了维持所有前台进程同时运行而必须终止，否则系统不会终止这些进程。 服务进程：正在运行已使用 startService() 方法启动的服务且不属于上述两个更高类别进程的进程。尽管服务进程与用户所见内容没有直接关联，但是它们通常在执行一些用户关心的操作（例如，在后台播放音乐或从网络下载数据）。因此，除非内存不足以维持所有前台进程和可见进程同时运行，否则系统会让服务进程保持运行状态。 后台进程：包含目前对用户不可见的 Activity 的进程（已调用 Activity 的 onStop() 方法）。这些进程对用户体验没有直接影响，系统可能随时终止它们，以回收内存供前台进程、可见进程或服务进程使用。 通常会有很多后台进程在运行，因此它们会保存在 LRU （最近最少使用）列表中，以确保包含用户最近查看的 Activity 的进程最后一个被终止。如果某个 Activity 正确实现了生命周期方法，并保存了其当前状态，则终止其进程不会对用户体验产生明显影响，因为当用户导航回该 Activity 时，Activity 会恢复其所有可见状态。 空进程：不含任何活动应用组件的进程。保留这种进程的的唯一目的是用作缓存，以缩短下次在其中运行组件所需的启动时间。 为使总体系统资源在进程缓存和底层内核缓存之间保持平衡，系统往往会终止这些进程。 根据进程中当前活动组件的重要程度，Android 会将进程评定为它可能达到的最高级别。例如，如果某进程托管着服务和可见 Activity，则会将此进程评定为可见进程，而不是服务进程。 此外，一个进程的级别可能会因其他进程对它的依赖而有所提高，即 服务于另一进程的进程其级别永远不会低于其所服务的进程。 例如，如果进程 A 中的内容提供程序为进程 B 中的客户端提供服务，或者如果进程 A 中的服务绑定到进程 B 中的组件，则进程 A 始终被视为至少与进程 B 同样重要。 由于运行服务的进程其级别高于托管后台 Activity 的进程，因此 启动长时间运行操作的 Activity 最好为该操作启动服务，而不是简单地创建工作线程，当操作有可能比 Activity 更加持久时尤要如此。例如，正在将图片上传到网站的 Activity 应该启动服务来执行上传，这样一来，即使用户退出 Activity，仍可在后台继续执行上传操作。使用服务可以保证，无论 Activity 发生什么情况，该操作至少具备“服务进程”优先级。 同理，广播接收器也应使用服务，而不是简单地将耗时冗长的操作放入线程中。 保活的基本概念 当前Android进程保活手段主要分为 黑、白、灰 三种，其大致的实现思路如下： 黑色保活：不同的app进程，用广播相互唤醒（包括利用系统提供的广播进行唤醒） 白色保活：启动前台Service 灰色保活：利用系统的漏洞启动前台Service 还有一种就是控制Service.onStartCommand的返回值，使用 START_STICKY可以在一定程度上保活。 黑色保活 所谓黑色保活，就是利用不同的app进程使用广播来进行相互唤醒。举个3个比较常见的场景： 场景1：开机，网络切换、拍照、拍视频时候，利用系统产生的广播唤醒app。 场景2：接入第三方SDK也会唤醒相应的app进程，如微信sdk会唤醒微信，支付宝sdk会唤醒支付宝。由此发散开去，就会直接触发了下面的场景3。 场景3：假如你手机里装了支付宝、淘宝、天猫、UC等阿里系的app，那么你打开任意一个阿里系的app后，有可能就顺便把其他阿里系的app给唤醒了。 白色保活 白色保活手段非常简单，就是调用系统api启动一个前台的Service进程，这样会在系统的通知栏生成一个Notification，用来让用户知道有这样一个app在运行着，哪怕当前的app退到了后台。如网易云音乐。 灰色保活 它是利用系统的漏洞来启动一个前台的Service进程，与普通的启动方式区别在于，它不会在系统通知栏处出现一个Notification，看起来就如同运行着一个后台Service进程一样。这样做带来的好处就是，用户无法察觉到你运行着一个前台进程（因为看不到Notification）,但你的进程优先级又是高于普通后台进程的。 API ，启动前台Service时直接传入new Notification()； API >= 18，同时启动两个id相同的前台Service，然后再将后启动的Service做stop处理； public class GrayService extends Service { private final static int GRAY_SERVICE_ID = 1001; @Override public int onStartCommand(Intent intent, int flags, int startId) { if (Build.VERSION.SDK_INT = 18 的平台上用的灰色保活手段 */ public static class GrayInnerService extends Service { @Override public int onStartCommand(Intent intent, int flags, int startId) { startForeground(GRAY_SERVICE_ID, new Notification()); stopForeground(true); stopSelf(); return super.onStartCommand(intent, flags, startId); } } } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/activity-view-window.html":{"url":"android/activity-view-window.html","title":"Activity、View及Window之间关系","keywords":"","body":"Activity、View及Window之间关系 View View（包括ViewGroup）使用的是组合模式，将View组成成树形结构，以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。View主要是用于绘制我们想要的结果，是一个最基本的UI组件。 Window 简单地说，Window表示一个窗口，一般来说，Window大小取值为屏幕大小。但是这不是绝对的，如对话框、Toast等就不是整个屏幕大小。你可以指定Window的大小。Window包含一个View tree和窗口的layout参数。 感觉Window的理解比较抽象，Window相当于一个容器，里面“盛放”着很多View，这些View是以树状结构组织起来的。 如果还是无法理解的话，就把Window当成是显示器，显示器有大有小（对应Window有大有小），View是显示器里面具体显示的内容。 Window对象存在的必要性 Window能做的事情，View对象基本都能做：像什么触摸事件啊、显示的坐标及大小啊、管理各个子View啊等等。View已经这么强大了，为什么还多此一举，加个Window对象。可能有人会说因为WindowManager管理的就是Window对象呀，那我想问，既然这样，Android系统直接让WindowManager去管理View不就好了？让View接替Window的工作，把Window所做的事情都封装到View里面不好嘛？。或许又有人说，View负责绘制显示内容，Window负责管理View，各自的工作职责不同。可是我想说，Window所做的大部分工作，View里面都有同样（或类似）的处理。 关于Window存在的必要，我查了国内外各种资料，最后有了我个人的理解。在后面小节里面，我会结合我个人的理解来解释。在解释之前，我们需要了解Window绘制过程。 Window绘制过程 在理解Window绘制过程之前，首先，我们需要知道Surface，在Window中持有一个Surface，那么什么是Surface呢？ Surface其实就是一个持有像素点矩阵的对象，这个像素点矩阵是组成显示在屏幕的图像的一部分。我们看到显示的每个Window（包括对话框、全屏的Activity、状态栏等）都有他自己绘制的Surface。而最终的显示可能存在Window之间遮挡的问题，此时就是通过Surface Flinger对象渲染最终的显示，使他们以正确的Z-order显示出来。一般Surface拥有一个或多个缓存（一般2个），通过双缓存来刷新，这样就可以一边绘制一边加新缓存。 WindowManager为每个Window创建Surface对象，然后应用就可以通过这个Surface来绘制任何它想要绘制的东西。而对于WindowManager来说，这只不过是一块矩形区域而已。 前面我们说过，View是Window里面用于交互的UI元素。Window只attach一个View Tree，当Window需要重绘（如，当View调用invalidate）时，最终转为Window的Surface，Surface被锁住（locked）并返回Canvas对象，此时View拿到Canvas对象来绘制自己。当所有View绘制完成后，Surface解锁（unlock），并且post到绘制缓存用于绘制，通过Surface Flinger来组织各个Window，显示最终的整个屏幕。 总结 现在我们知道了Window绘制过程，其实，站在系统的角度来考虑，一个Window对象代表一块显示区域，系统不关心Window里面具体的绘制内容，也不管你Window怎么去绘制，反正只给你提供可以在这块区域上绘制图形的Surface对象，你Window对象怎么画是你的事情！ 换句话说，站在系统的角度上看，系统是“不知道”有View对象这个说法的！作为系统，我有自己的骄傲，不去管你Window如何搬砖、如何砌墙，只给你地皮。而这时，Window为了绘制出用户想要的组件（按钮、文字、输入框等等），系统又不给我！没事，那我自己定义，于是就定义了View机制，给每个View提供Canvas，让不同的View自己绘制具有自己特色的组件。同时，为了更好的管理View，通过定义ViewGroup，等等。 Activity 对于开发人员来说，一个Activity就“相当于”一个界面（通过setContentView指定具体的View）。我们可以直接在Activity里处理事件，如onKeyEvent,onTouchEvent等。 并可以通过Activity维护应用程序的生命周期。 Activity和Window 前面我们知道，Window已经是系统管理的窗口界面。那么为什么还需要Activity呢？我们把Activity所做的事情，全部封装到Window不就好了？ 其实，本质上讲，我们要显示一个窗口出来，的确可以不需要Activity。悬浮窗口中不就是没有使用Activity来显示一个悬浮窗吗？既然如此，Window（以及View）能处理点击事件以及封装各种逻辑，那为啥还需要Activity呢？ Android中的应用中，里面对各个窗口的管理相当复杂（任务栈、状态等等），Android系统当然可以不用Activity，让用户自己直接操作Window来开发自己的应用。但是如果让用户自己去管理这些Window，先不说工作量，光让用户自己去实现任务栈这点，有几个人能写的出来。为了让大家能简单、快速的开发应用，Android通过定义Activity，让Activity帮我们管理好，我们只需简单的去重写几个回调函数，无需直接与Window对象接触。各种事件也只需重写Activity里面的回调即可。无需关注其他细节，默认都帮我们写好了，针对需要定制的部分我们重写（设计模式为：模板方法模式）。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/eventbus.html":{"url":"android/eventbus.html","title":"EventBus","keywords":"","body":"EventBus EventBus消息接收者注册流程 EventBus Post流程 postToSubscription()在这个方法中，实现了从发布者到调用者的调用过程。在这里有很重要的几个分支： Main：在主线程中执行。 如果当前线程(post线程)是主线程，则直接invoke； 如果当前线程(post线程)不是主线程，则将消息放入一个HandlerPosterPendingPostQueue的消息队列中，然后通过主线程的Handler发送消息，最好在Handler.HandleMessage中调用EventBus.invokeSubscriber，来让订阅方法在主线程中执行。 BackGround：在后台线程执行。 如果当前线程(post线程)不是主线程，则直接invoke； 如果当前线程(post线程)是主线程，则将消息放入BackgroundPoster.PendingPostQueue的消息队列中，由于该Poster实现了接口Runable，于是将该Poster放入线程池中执行，在线程中调用EventBus.invokeSubscriber。 Async：异步执行。将消息放入AsyncPoster中，然后将该Poster放入线程池并调用EventBus.invokeSubscriber。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/okhttp.html":{"url":"android/okhttp.html","title":"OkHttp","keywords":"","body":"OkHttp 具体内容在 Pocket 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/intent.html":{"url":"android/intent.html","title":"Intent","keywords":"","body":"Intent Intent 是一个消息传递对象，您可以使用它从其他应用组件请求操作。尽管 Intent 可以通过多种方式促进组件之间的通信，但其基本用例主要包括以下三个： 启动Activity：startActivity() 启动服务：bindService() 传递广播：sendBroadcast() Intent 类型 Intent 分为两种类型： 显式 Intent：按名称（完全限定类名）指定要启动的组件。 隐式 Intent：不会指定特定的组件，而是声明要执行的常规操作，从而允许其他应用中的组件来处理它。 创建显式 Intent 启动 Activity 或服务时，系统将立即启动 Intent 对象中指定的应用组件。 隐式 Intent 如何通过系统传递以启动其他 Activity 的图解 创建隐式 Intent 时，Android 系统通过将 Intent 的内容与在设备上其他应用的清单文件中声明的 Intent 过滤器进行比较，从而找到要启动的相应组件。Intent如果 Intent 与 Intent 过滤器匹配，则系统将启动该组件，并将其传递给对象。如果多个 Intent 过滤器兼容，则系统会显示一个对话框，支持用户选取要使用的应用。 为了确保应用的安全性，启动 Service 时，请始终使用显式 Intent，且不要为服务声明 Intent 过滤器。从 Android 5.0（API 级别 21）开始，如果使用隐式 Intent 调用 bindService()，系统会抛出异常。 构建 Intent 组件名称(ComponentName)：这是可选项，但也是构建显式 Intent 的一项重要信息，这意味着 Intent 应当仅传递给由组件名称定义的应用组件。Intent 的这一字段是 ComponentName 对象，您可以使用目标组件的完全限定类名指定此对象，其中包括应用的软件包名称。 操作(Action)：指定要执行的通用操作（例如，“查看”或“选取”）的字符串。 数据(Data)：引用待操作数据和/或该数据 MIME 类型的 URI（Uri 对象）。提供的数据类型通常由 Intent 的操作决定。 要仅设置数据 URI，请调用 setData()。要仅设置 MIME 类型，请调用 setType()。如有必要，您可以使用 setDataAndType() 同时显式设置二者。 警告：若要同时设置 URI 和 MIME 类型，请勿调用 setData() 和 setType()，因为它们会互相抵消彼此的值。请始终使用 setDataAndType() 同时设置 URI 和 MIME 类型。 类别(Category)：一个包含应处理 Intent 组件类型的附加信息的字符串。您可以将任意数量的类别描述放入一个 Intent 中，但大多数 Intent 均不需要类别。 Extra：携带完成请求操作所需的附加信息的键值对。正如某些操作使用特定类型的数据 URI 一样，有些操作也使用特定的附加数据。例如，使用 ACTION_SEND 创建用于发送电子邮件的 Intent 时，可以使用 EXTRA_EMAIL 键指定“目标”收件人，并使用 EXTRA_SUBJECT 键指定“主题”。 标志(Flags)：在 Intent 类中定义的、充当 Intent 元数据的标志。标志可以指示 Android 系统如何启动 Activity（例如，Activity 应属于哪个Task ）。 Intent 解析 当系统收到隐式 Intent 以启动 Activity 时，它根据以下三个方面将该 Intent 与 Intent 过滤器进行比较，搜索该 Intent 的最佳 Activity： Intent 操作 Intent 数据（URI 和数据类型） Intent 类别 系统通过将 Intent 与所有这三个元素进行比较，根据过滤器测试隐式 Intent。隐式 Intent 若要传递给组件，必须通过所有这三项测试。如果 Intent 甚至无法匹配其中任何一项测试，则 Android 系统不会将其传递给组件。但是，由于一个组件可能有多个 Intent 过滤器，因此未能通过某一组件过滤器的 Intent 可能会通过另一过滤器。（在Demo中实验了几次，发现 Action 和 Data 必须至少设置一个，否则不能匹配到） 操作（Action）匹配 要指定接受的 Intent 操作， Intent 过滤器既可以不声明任何 action 元素，也可以声明多个此类元素。例如： ... 要通过此过滤器，您在 Intent 中指定的操作必须与过滤器中列出的 某一操作匹配。 如果该过滤器未列出任何操作，则 Intent 没有任何匹配项，因此所有 Intent 均无法通过测试。但是，如果 Intent 未指定操作，则会通过测试（只要过滤器至少包含一个操作）。 类别（Category）匹配 要指定接受的 Intent 类别， Intent 过滤器既可以不声明任何 category 元素，也可以声明多个此类元素。例如： ... 若要 Intent 通过类别测试，则 Intent 中的每个类别均必须与过滤器中的类别匹配。反之则未必然，Intent 过滤器声明的类别可以超出 Intent 中指定的数量，且 Intent 仍会通过测试。因此，不含类别的 Intent 应当始终会通过此测试，无论过滤器中声明何种类别均是如此。 Android 会自动将 CATEGORY_DEFAULT 类别应用于传递给 startActivity() 和 startActivityForResult() 的所有隐式 Intent。因此，如需 Activity 接收隐式 Intent，则必须将 \"android.intent.category.DEFAULT\" 的类别包括在其 Intent 过滤器中。 数据（Data）匹配 要指定接受的 Intent 数据， Intent 过滤器既可以不声明任何 data 元素，也可以声明多个此类元素。例如： ... 每个 元素均可指定 URI 结构和数据类型（MIME 介质类型）。URI 的每个部分均包含单独的 scheme、host、port 和 path 属性： scheme://host:port/path 例如： content://com.example.project:200/folder/subfolder/etc 在此 URI 中，架构是 content，主机是 com.example.project，端口是 200，路径是 folder/subfolder/etc。上述每个属性均为可选，但存在线性依赖关系： 如果未指定架构，则会忽略主机。 如果未指定主机，则会忽略端口。 如果未指定架构和主机，则会忽略路径。 将 Intent 中的 URI 与过滤器中的 URI 规范进行比较时，它仅与过滤器中包含的部分 URI 进行比较。例如： 如果过滤器仅指定架构，则具有该架构的所有 URI 均与该过滤器匹配。 如果过滤器指定架构和权限、但未指定路径，则具有相同架构和权限的所有 URI 都会通过过滤器，无论其路径如何均是如此。 如果过滤器指定架构、权限和路径，则仅具有相同架构、权限和路径 的 URI 才会通过过滤器。 路径规范可以包含星号通配符 ( * )，因此仅需部分匹配路径名即可。 数据匹配会将 Intent 中的 URI 和 MIME 类型与过滤器中指定的 URI 和 MIME 类型进行比较。规则如下： 仅当过滤器未指定任何 URI 或 MIME 类型时，不含 URI 和 MIME 类型的 Intent 才会通过测试。 对于包含 URI、但不含 MIME 类型（既未显式声明，也无法通过 URI 推断得出）的 Intent，仅当其 URI 与过滤器的 URI 格式匹配、且过滤器同样未指定 MIME 类型时，才会通过测试。 仅当过滤器列出相同的 MIME 类型且未指定 URI 格式时，包含 MIME 类型、但不含 URI 的 Intent 才会通过测试。 仅当 MIME 类型与过滤器中列出的类型匹配时，包含 URI 和 MIME 类型（通过显式声明，或可以通过 URI 推断得出）的 Intent 才会通过测试的 MIME 类型部分。如果 Intent 的 URI 与过滤器中的 URI 匹配，或者如果 Intent 具有 content: 或 file: URI 且过滤器未指定 URI，则 Intent 会通过测试的 URI 部分。换而言之，如果过滤器仅列出 MIME 类型，则假定组件支持 content: 和 file: 数据。 最后一条规则，反映了期望组件能够从文件中或 内容提供者 处获得本地数据。因此，其过滤器可以仅列出数据类型，而不必显式命名 content: 和 file: 架构。这是一个典型的案例。例如，下文中的 data 元素向 Android 指出，组件可从 内容提供者 处获得并显示图像数据。 ... Intent 匹配 您的应用可以采用类似的方式使用 Intent 匹配。PackageManager 提供了一整套 query...() 方法来返回所有能够接受特定 Intent 的组件。此外，它还提供了一系列类似的 resolve...() 方法来确定响应 Intent 的最佳组件。例如，queryIntentActivities()将返回能够执行那些作为参数传递的 Intent 的所有 Activity 列表，而 queryIntentServices() 则可返回类似的服务列表。这两种方法均不会激活组件，而只是列出能够响应的组件。对于广播接收器，有一种类似的方法： queryBroadcastReceivers()。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/version.html":{"url":"android/version.html","title":"版本问题","keywords":"","body":"版本问题 CompileSdkVersion compileSdkVersion 告诉 Gradle 用哪个 Android SDK 版本编译你的应用。使用任何新添加的 API 就需要使用对应 Level 的 Android SDK。 需要强调的是修改 compileSdkVersion 不会改变运行时的行为。当你修改了 compileSdkVersion 的时候，可能会出现新的编译警告、编译错误，但新的 compileSdkVersion 不会被包含到 APK 中：它纯粹只是在编译的时候使用。（你真的应该修复这些警告，他们的出现一定是有原因的） 因此我们强烈推荐总是使用最新的 SDK 进行编译。在现有代码上使用新的编译检查可以获得很多好处，避免新弃用的 API ，并且为使用新的 API 做好准备。 注意，如果使用 Support Library ，那么使用最新发布的 Support Library 就需要使用最新的 SDK 编译。例如，要使用 23.1.1 版本的 Support Library ，compileSdkVersion 就必需至少是 23 （大版本号要一致！）。通常，新版的 Support Library 随着新的系统版本而发布，它为系统新增加的 API 和新特性提供兼容性支持。 MinSdkVersion 如果 compileSdkVersion 设置为可用的最新 API，那么 minSdkVersion 则是应用可以运行的最低要求。minSdkVersion 是 Google Play 商店用来判断用户设备是否可以安装某个应用的标志之一。 在开发时 minSdkVersion 也起到一个重要角色：lint 默认会在项目中运行，它在你使用了高于 minSdkVersion 的 API 时会警告你，帮你避免调用不存在的 API 的运行时问题。如果只在较高版本的系统上才使用某些 API，通常使用运行时检查系统版本的方式解决。 请记住，你所使用的库，如 Support Library 或 Google Play services，可能有他们自己的 minSdkVersion 。你的应用设置的 minSdkVersion 必需大于等于这些库的 minSdkVersion 。 当你决定使用什么 minSdkVersion 时候，你应该参考当前的 Android 分布统计，它显示了最近 7 天所有访问 Google Play 的设备信息。他们就是你把应用发布到 Google Play 时的潜在用户。最终这是一个商业决策问题，取决于为了支持额外 3% 的设备，确保最佳体验而付出的开发和测试成本是否值得。 当然，如果某个新的 API 是你整个应用的关键，那么确定 minSdkVersion 的值就比较容易了。不过要记得 14 亿设备中的 0.7％ 也是个不小的数字。 TargetSdkVersion 三个版本号中最有趣的就是 targetSdkVersion 了。 targetSdkVersion 是 Android 提供向前兼容的主要依据，在应用的 targetSdkVersion 没有更新之前系统不会应用最新的行为变化。这允许你在适应新的行为变化之前就可以使用新的 API （因为你已经更新了 compileSdkVersion 不是吗？）。 targetSdkVersion 所暗示的许多行为变化都记录在 VERSION_CODES 文档中了，但是所有恐怖的细节也都列在每次发布的平台亮点中了，在这个 API Level 表中可以方便地找到相应的链接。 例如，Android 6.0 变化文档中谈了 target 为 API 23 时会如何把你的应用转换到运行时权限模型上，Android 4.4 行为变化阐述了 target 为 API 19 及以上时使用 set() 和 setRepeating() 设置 alarm 会有怎样的行为变化。 由于某些行为的变化对用户是非常明显的（弃用的 menu 按钮，运行时权限等），所以将 target 更新为最新的 SDK 是所有应用都应该优先处理的事情。但这不意味着你一定要使用所有新引入的功能，也不意味着你可以不做任何测试就盲目地更新 targetSdkVersion ，请一定在更新 targetSdkVersion 之前做测试！你的用户会感谢你的。 综合来看 如果你按照上面示例那样配置，你会发现这三个值的关系是： minSdkVersion 这种直觉是合理的，如果 compileSdkVersion 是你的最大值，minSdkVersion 是最小值，那么最大值必需至少和最小值一样大且 target 必需在二者之间。 理想上，在稳定状态下三者的关系应该更像这样： minSdkVersion (lowest possible) 用较低的 minSdkVersion 来覆盖最大的人群，用最新的 SDK 设置 target 和 compile 来获得最好的外观和行为。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"android/questions.html":{"url":"android/questions.html","title":"面试题","keywords":"","body":"面试题 APK安装过程 应用安装涉及到如下几个目录： system/app：系统自带的应用程序，无法删除 data/app：用户程序安装的目录，有删除权限。安装时把apk文件复制到此目录 data/data：存放应用程序的数据 data/dalvik-cache：将apk中的dex文件安装到dalvik-cache目录下 复制APK安装包到data/app目录下，解压并扫描安装包，把dex文件(Dalvik字节码)保存到dalvik-cache目录，并在data/data目录下创建对应的应用数据目录。 invalidate()和postInvalidate() 的区别 invalidate()是用来刷新View的，必须是在UI线程中进行工作。比如在修改某个view的显示时，调用invalidate()才能看到重新绘制的界面。 postInvalidate()在工作者线程中被调用。 导入外部数据库 Android系统下数据库应该存放在 /data/data/com.*.*(package name)/ 目录下，所以我们需要做的是把已有的数据库传入那个目录下。操作方法是用FileInputStream读取原数据库，再用FileOutputStream把读取到的东西写入到那个目录。 Parcelable和Serializable区别 Parcelable的性能比Serializable好，在内存开销方面较小，所以在内存间数据传输时推荐使用Parcelable，如activity间传输数据，而Serializable可将数据持久化方便保存，所以在需要保存或网络传输数据时选择Serializable，因为android不同版本Parcelable可能不同，所以不推荐使用Parcelable进行数据持久化。 Serializable序列化不保存静态变量，可以使用Transient关键字对部分字段不进行序列化，也可以覆盖writeObject、readObject方法以实现序列化过程自定义。 Android里跨进程传递数据的几种方案 Binder Socket/LocalSocket 共享内存 匿名共享内存，使用场景 在Android系统中，提供了独特的匿名共享内存子系统Ashmem(Anonymous Shared Memory)，它以驱动程序的形式实现在内核空间中。它有两个特点，一是能够辅助内存管理系统来有效地管理不再使用的内存块，二是它通过Binder进程间通信机制来实现进程间的内存共享。 ashmem并像Binder是Android重新自己搞的一套东西，而是利用了Linux的 tmpfs文件系统。tmpfs是一种可以基于RAM或是SWAP的高速文件系统，然后可以拿它来实现不同进程间的内存共享。 大致思路和流程是： Proc A 通过 tmpfs 创建一块共享区域，得到这块区域的 fd（文件描述符） Proc A 在 fd 上 mmap 一片内存区域到本进程用于共享数据 Proc A 通过某种方法把 fd 倒腾给 Proc B Proc B 在接到的 fd 上同样 mmap 相同的区域到本进程 然后 A、B 在 mmap 到本进程中的内存中读、写，对方都能看到了 其实核心点就是 创建一块共享区域，然后2个进程同时把这片区域 mmap 到本进程，然后读写就像本进程的内存一样。这里要解释下第3步，为什么要倒腾 fd，因为在 linux 中 fd 只是对本进程是唯一的，在 Proc A 中打开一个文件得到一个 fd，但是把这个打开的 fd 直接放到 Proc B 中，Proc B 是无法直接使用的。但是文件是唯一的，就是说一个文件（file）可以被打开多次，每打开一次就有一个 fd（文件描述符），所以对于同一个文件来说，需要某种转化，把 Proc A 中的 fd 转化成 Proc B 中的 fd。这样 Proc B 才能通过 fd mmap 同样的共享内存文件。 使用场景：进程间大量数据传输。 ContentProvider实现原理 ContentProvider 有以下两个特点： 封装：对数据进行封装，提供统一的接口，使用者完全不必关心这些数据是在DB，XML、Preferences或者网络请求来的。当项目需求要改变数据来源时，使用我们的地方完全不需要修改。 提供一种跨进程数据共享的方式。 Content Provider组件在不同应用程序之间传输数据是基于匿名共享内存机制来实现的。其主要的调用过程： 通过ContentResolver先查找对应给定Uri的ContentProvider，返回对应的BinderProxy 如果该Provider尚未被调用进程使用过: 通过ServiceManager查找activity service得到ActivityManagerService对应BinderProxy 调用BinderProxy的transcat方法发送GET_CONTENT_PROVIDER_TRANSACTION命令，得到对应ContentProvider的BinderProxy。 如果该Provider已被调用进程使用过，则调用进程会保留使用过provider的HashMap。此时直接从此表查询即得。 调用BinderProxy的query() 如何使用ContentProvider进行批量操作？ 通常进行数据的批量操作我们都会使用“事务”，但是ContentProvider如何进行批量操作呢？创建 ContentProviderOperation 对象数组，然后使用 ContentResolver.applyBatch() 将其分派给内容提供程序。您需将内容提供程序的授权传递给此方法，而不是特定内容 URI。这样可使数组中的每个 ContentProviderOperation 对象都能适用于其他表。调用 ContentResolver.applyBatch() 会返回结果数组。 同时我们还可以通过ContentObserver对数据进行观察： 创建我们特定的ContentObserver派生类，必须重载onChange()方法去处理回调后的功能实现 利用context.getContentResolover()获得ContentResolove对象，接着调用registerContentObserver()方法去注册内容观察者，为指定的Uri注册一个ContentObserver派生类实例，当给定的Uri发生改变时，回调该实例对象去处理。 由于ContentObserver的生命周期不同步于Activity和Service等，因此，在不需要时，需要手动的调用unregisterContentObserver()去取消注册。 Application类的作用 Android系统会为每个程序运行时创建一个Application类的对象且仅创建一个，所以Application可以说是单例 (singleton)模式的一个类。Application对象的生命周期是整个程序中最长的，它的生命周期就等于这个程序的生命周期。因为它是全局的单例的，所以在不同的Activity,Service中获得的对象都是同一个对象。所以通过Application来进行一些，数据传递，数据共享，数据缓存等操作。 广播注册后不解除注册会有什么问题？(内存泄露) 我们可以通过两种方式注册BroadcastReceiver，一是在Activity启动过程中通过代码动态注册，二是在AndroidManifest.xml文件中利用标签进行静态注册。 对于第一种方法，我们需要养成一个良好的习惯：在Activity进入停止或者销毁状态的时候使用unregisterReceiver方法将注册的BroadcastReceiver注销掉。 对于标签进行注册的，那么该对象的实例在onReceive被调用之后就会在任意时间内被销毁。 属性动画(Property Animation)和补间动画(Tween Animation)的区别 补间动画只是针对于View，超脱了View就无法操作了。 补间动画有四种动画操作（移动，缩放，旋转，淡入淡出）。 补间动画只是改变View的显示效果而已，但是不会真正的去改变View的属性。 属性动画改变View的实际属性值，当然它也可以不作用于View。 BrocastReceive里面可不可以执行耗时操作? 不能，当 onReceive() 方法在 10 秒内没有执行完毕，Android 会认为该程序无响应，所以在BroadcastReceiver里不能做一些比较耗时的操作，否侧会弹出 ANR 的对话框。 Android优化工具 TraceView traceview 是Android SDK中自带的一个工具，可以 对应用中方法调用耗时进行统计分析，是Android性能优化和分析时一个很重要的工具。使用方法：第一种是在相应进行traceview分析的开始位置和结束位置分别调用startMethodTracing和stopMethodTracing方法。第二种是在ddms中直接使用，即在ddms中在选中某个要进行监控的进程后，点击如图所示的小图标开始监控，在监控结束时再次点击小图标，ddms会自动打开traceview视图。 Systrace Systrace是Android4.1中新增的性能数据采样和分析工具。它可帮助开发者收集Android关键子系统（如surfaceflinger、WindowManagerService等Framework部分关键模块、服务）的运行信息，从而帮助开发者更直观的分析系统瓶颈，改进性能。 Systrace的功能包括跟踪系统的I/O操作、内核工作队列、CPU负载以及Android各个子系统的运行状况等。 Dalvik与ART的区别？ Dalvik是Google公司自己设计用于Android平台的Java虚拟机。Dalvik虚拟机是Google等厂商合作开发的Android移动设备平台的核心组成部分之一，它可以支持已转换为.dex(即Dalvik Executable)格式的Java应用程序的运行，.dex格式是专为Dalvik应用设计的一种压缩格式，适合内存和处理器速度有限的系统。Dalvik经过优化，允许在有限的内存中同时运行多个虚拟机的实例，并且每一个Dalvik应用作为独立的Linux进程执行。独立的进程可以防止在虚拟机崩溃的时候所有程序都被关闭。 ART代表Android Runtime,其处理应用程序执行的方式完全不同于Dalvik，Dalvik是依靠一个Just-In-Time(JIT)编译器去解释字节码。开发者编译后的应用代码需要通过一个解释器在用户的设备上运行，这一机制并不高效，但让应用能更容易在不同硬件和架构上运行。ART则完全改变了这套做法，在应用安装的时候就预编译字节码到机器语言，这一机制叫 Ahead-Of-Time(AOT) 编译 。在移除解释代码这一过程后，应用程序执行将更有效率，启动更快。 ART优点： 系统性能的显著提升 应用启动更快、运行更快、体验更流畅、触感反馈更及时 更长的电池续航能力 支持更低的硬件 ART缺点： 更大的存储空间占用，可能会增加10%-20% 更长的应用安装时间 Android动态权限？ Android 6.0 动态权限，这里以拨打电话的权限为例，首先需要在Manifest里添加android.permission.CALL_PHONE权限。 int checkCallPhonePermission = ContextCompat.checkSelfPermission(this, Manifest.permission.CALL_PHONE); if (checkCallPhonePermission != PackageManager.PERMISSION_GRANTED) { ActivityCompat.requestPermissions( this, new String[]{Manifest.permission.CALL_PHONE}, REQUEST_CODE_ASK_CALL_PHONE); return; } 在获取权限后，可以重写Activity.onRequestPermissionsResult方法来进行回调。 @Override public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) { switch (requestCode) { case REQUEST_CODE_ASK_CALL_PHONE: if (grantResults[0] == PackageManager.PERMISSION_GRANTED) { // Permission Granted Toast.makeText(MainActivity.this, \"CALL_PHONE Granted\", Toast.LENGTH_SHORT) .show(); } else { // Permission Denied Toast.makeText(MainActivity.this, \"CALL_PHONE Denied\", Toast.LENGTH_SHORT) .show(); } break; default: super.onRequestPermissionsResult(requestCode, permissions, grantResults); } } ViewPager如何判断左右滑动？ 实现OnPageChangeListener并重写onPageScrolled方法，通过参数进行判断。 ListView与RecyclerView ViewHolder：在ListView中，ViewHolder需要自己来定义，且这只是一种推荐的使用方式，不使用当然也可以，这不是必须的。而在RecyclerView中使用 RecyclerView.ViewHolder 则变成了必须，尽管实现起来稍显复杂，但它却解决了ListView面临的上述不使用自定义ViewHolder时所面临的问题。 LayoutManager：RecyclerView提供了更加丰富的布局管理。LinearLayoutManager，可以支持水平和竖直方向上滚动的列表。StaggeredGridLayoutManager，可以支持交叉网格风格的列表，类似于瀑布流或者Pinterest。GridLayoutManager，支持网格展示，可以水平或者竖直滚动，如展示图片的画廊。 ItemAnimator：相比较于ListView，RecyclerView.ItemAnimator 则被提供用于在RecyclerView添加、删除或移动item时处理动画效果。 ItemDecoration：RecyclerView在默认情况下并不在item之间展示间隔符。如果你想要添加间隔符，你必须使用RecyclerView.ItemDecoration类来实现。 ListView可以设置选择模式，并添加MultiChoiceModeListener，RecyclerView中并没有提供这样功能。 SpannableString TextView通常用来显示普通文本，但是有时候需要对其中某些文本进行样式、事件方面的设置。Android系统通过SpannableString类来对指定文本进行相关处理。可以通过SpannableString来对TextView进行富文本设置，包括但不限于文本颜色，删除线，图片，超链接，字体样式。 描述一下Android手机启动过程和App启动过程？ Android手机启动过程 当我们开机时，首先是启动Linux内核，在Linux内核中首先启动的是init进程，这个进程会去读取配置文件system\\core\\rootdir\\init.rc配置文件，这个文件中配置了Android系统中第一个进程Zygote进程。 启动Zygote进程 --> 创建AppRuntime（Android运行环境） --> 启动虚拟机 --> 在虚拟机中注册JNI方法 --> 初始化进程通信使用的Socket（用于接收AMS的请求） --> 启动系统服务进程 --> 初始化时区、键盘布局等通用信息 --> 启动Binder线程池 --> 初始化系统服务（包括PMS，AMS等等） --> 启动Launcher App启动过程 应用的启动是从其他应用调用startActivity开始的。通过代理请求AMS启动Activity。 AMS创建进程，并进入ActivityThread的main入口。在main入口，主线程初始化，并loop起来。主线程初始化，主要是实例化ActivityThread和ApplicationThread，以及MainLooper的创建。ActivityThread和ApplicationThread实例用于与AMS进程通信。 应用进程将实例化的ApplicationThread，Binder传递给AMS，这样AMS就可以通过代理对应用进程进行访问。 AMS通过代理，请求启动Activity。ApplicationThread通知主线程执行该请求。然后，ActivityThread执行Activity的启动。 Activity的启动包括，Activity的实例化，Application的实例化，以及Activity的启动流程：create、start、resume。 可以看到 入口Activity其实是先于Application实例化，只是onCreate之类的流程，先于Activity的流程。另外需要scheduleLaunchActivity，在ApplicationThreaad中，对应AMS管理Activity生命周期的方法都以scheduleXXXActivity，ApplicationThread在Binder线程中，它会向主线程发送消息，ActivityThread的Handler会调用相应的handleXXXActivity方法，然后会执行performXXXActivity方法，最终调用Activity的onXXX方法 Include、Merge、ViewStub的作用 Include：布局重用 标签可以使用单独的layout属性，这个也是必须使用的。 可以使用其他属性。标签若指定了ID属性，而你的layout也定义了ID，则你的layout的ID会被覆盖，解决方案。 在标签中所有的android:layout_*都是有效的，前提是必须要写layout_width和layout_height两个属性。 布局中可以包含两个相同的include标签 Merge：减少视图层级，多用于替换FrameLayout或者当一个布局包含另一个时，标签消除视图层次结构中多余的视图组。 例如：你的主布局文件是垂直布局，引入了一个垂直布局的include，这是如果include布局使用的LinearLayout就没意义了，使用的话反而减慢你的UI表现。这时可以使用标签优化。 ViewStub：需要时使用。优点是当你需要时才会加载，使用他并不会影响UI初始化时的性能。需要使用时调用inflate()。 Asset目录与res目录的区别 assets 目录：不会在R.java文件下生成相应的标记，assets文件夹可以自己创建文件夹，必须使用AssetsManager类进行访问，存放到这里的资源在运行打包的时候都会打入程序安装包中， res 目录：会在R.java文件下生成标记，这里的资源会在运行打包操作的时候判断哪些被使用到了，没有被使用到的文件资源是不会打包到安装包中的。 res/raw 和 assets文件夹来存放不需要系统编译成二进制的文件，例如字体文件等 res/raw不可以有目录结构，而assets则可以有目录结构，也就是assets目录下可以再建立文件夹 System.gc && Runtime.gc System.gc和Runtime.gc是等效的，在System.gc内部也是调用的Runtime.gc。调用两者都是通知虚拟机要进行gc，但是否立即回收还是延迟回收由JVM决定。两者唯一的区别就是一个是类方法，一个是实例方法。 Application 在多进程下会多次调用 onCreate() 么？ 当采用多进程的时候，比如下面的Service 配置： android:process 属性中 :的作用就是把这个名字附加到你的包所运行的标准进程名字的后面作为新的进程名称。 这样配置会调用 onCreate() 两次。 Theme && Style Style 是一组外观、样式的属性集合，适用于 View 和 Window 。 Theme 是一种应用于整个 Activity 或者 Application ，而不是独立的 View。 SQLiteOpenHelper.onCreate() 调用时机？ 在调getReadableDatabase或getWritableDatabase时，会判断指定的数据库是否存在，不存在则调SQLiteDatabase.onCreate创建， onCreate只在数据库第一次创建时才执行。 Removecallback 失效？ Removecallback 必须是同一个Handler才能移除。 Toast 如果会短时间内频繁显示怎么优化？ public void update(String msg){ toast.setText(msg); toast.show(); } Notification 如何优化？ 可以通过 相同 ID 来更新 Notification 。 应用怎么判断自己是处于前台还是后台？ 主要是通过 getRunningAppProcesses() 方法来实现。 ActivityManager activityManager = (ActivityManager) getSystemService(Context.ACTIVITY_SERVICE); List appProcesses = activityManager.getRunningAppProcesses(); for (ActivityManager.RunningAppProcessInfo appProcess : appProcesses) { if (appProcess.processName.equals(getPackageName())) { if (appProcess.importance == ActivityManager.RunningAppProcessInfo.IMPORTANCE_FOREGROUND) { Log.d(TAG, String.format(\"Foreground App:%s\", appProcess.processName)); } else { Log.d(TAG, \"Background App:\" + appProcess.processName); } } } FragmentPagerAdapter 和 FragmentStateAdapter 的区别？ FragmentStatePagerAdapter 是 PagerAdapter 的子类，这个适配器对实现多个 Fragment 界面的滑动是非常有用的，它的工作方式和listview是非常相似的。当Fragment对用户不可见的时候，整个Fragment会被销毁，只会保存Fragment的保存状态。基于这样的特性，FragmentStatePagerAdapter 比 FragmentPagerAdapter 更适合用于很多界面之间的转换，而且消耗更少的内存资源。 Bitmap的本质？ 本质是 SkBitmap 详见 Pocket SurfaceView && View && GLSurfaceView View：显示视图，内置画布，提供图形绘制函数、触屏事件、按键事件函数等；必须在UI主线程内更新画面，速度较慢。 SurfaceView：基于view视图进行拓展的视图类，更适合2D游戏的开发；View的子类，类似使用双缓机制，在新的线程（也可以在UI线程）中更新画面所以刷新界面速度比 View 快，但是会涉及到线程同步问题。 　- GLSurfaceView：openGL专用。基于SurfaceView视图再次进行拓展的视图类，专用于3D游戏开发的视图。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/":{"url":"basic/","title":"计算机基础","keywords":"","body":"计算机基础 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/1-algo/":{"url":"basic/1-algo/","title":"算法","keywords":"","body":"数据结构与算法 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/1-algo/1-algo.html":{"url":"basic/1-algo/1-algo.html","title":"基本算法","keywords":"","body":"常用算法 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/1-algo/1-tree.html":{"url":"basic/1-algo/1-tree.html","title":"树","keywords":"","body":"树 二叉树 L、D、R分别表示遍历左子树、访问根结点和遍历右子树 先序遍历：DLR 中序遍历：LDR 后序遍历：LRD 仅有前序和后序遍历，不能确定一个二叉树，必须有中序遍历的结果 二叉树的性质 性质1：在二叉树中第 i 层的结点数最多为2^(i-1)（i ≥ 1） 性质2：高度为k的二叉树其结点总数最多为2^k－1（ k ≥ 1） 性质3：对任意的非空二叉树 T ，如果叶结点的个数为 n0，而其度为 2 的结点数为 n2，则：n0 = n2 + 1 满二叉树 深度为k，且有2^k-1个节点称之为满二叉树； 性质4：第i层上的节点数为2^(i-1)； 完全二叉树 深度为k，有n个节点的二叉树，当且仅当其每一个节点都与深度为k的满二叉树中，序号为1至n的节点对应时，称之为完全二叉树。 性质5：对于具有n个结点的完全二叉树的高度为log2(n)+1 求完全二叉树的叶子结点个数： 二叉树的构造 //n 表示当前结点字符 Node* tree(vector data, int n) { Node* node; if (n >= data.size()) return NULL; if (data[n] == '#') return NULL; node = new Node; node->data = data[n]; node->left = tree(data, n + 1); node->right = tree(data, n + 2); return node; } 堆 堆通常是一个可以被看做一棵树的数组对象。堆的实现通过构造二叉堆（binary heap），实为二叉树的一种； 任意节点小于（或大于）它的所有后裔，最小元（或最大元）在堆的根上（堆序性）。 堆总是一棵完全树。即除了最底层，其他层的节点都被元素填满，且最底层尽可能地从左到右填入。 将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。常见的堆有二叉堆、斐波那契堆等。 通常堆是通过一维数组来实现的。在数组起始位置为1的情形中： 父节点i的左子节点在位置(2*i); 父节点i的右子节点在位置(2*i+1); 子节点i的父节点在位置(i/2); 霍夫曼树 霍夫曼树又称最优二叉树，是一种带权路径长度最短的二叉树。所谓树的带权路径长度，就是树中所有的叶结点的权值乘上其到根结点的路径长度（若根结点为0层，叶结点到根结点的路径长度为叶结点的层数）。树的路径长度是从树根到每一结点的路径长度之和，记为WPL=（W1L1+W2L2+W3L3+...+WnLn），N个权值Wi（i=1,2,...n）构成一棵有N个叶结点的二叉树，相应的叶结点的路径长度为Li（i=1,2,...n）。可以证明霍夫曼树的WPL是最小的。 霍夫曼树构造 根据给定的n个权值(W1,W2...Wn)，使对应节点构成n个二叉树的森林T=(T1,T2...Tn)，其中每个二叉树Ti(1 中都有一个带权值为Wi的根节点，其左、右子树均为空。 在森林T中选取两个节点权值最小的子树，分别作为左、右子树构造一个新的二叉树，且置新的二叉树的根节点的权值为其左右子树上根节点权值之和。 在森林T中，用新得到的二叉树替代选取的两个二叉树。 重复2和3，直到T只包含一个树为止。这个数就是霍夫曼树。 定理：对于具有n个叶子节点的霍夫曼树，共有2n-1个节点。这是由于霍夫曼树只有度为0和度为2的结点，根据二叉树的性质 n0 = n2 + 1，因此度为2的结点个数为n-1个，总共有2n-1个节点。 霍夫曼编码 对于一个霍夫曼树，所有左链接取'0'、右链接取'1'。从树根至树叶依序记录所有字母的编码。 带权路径 结点的权：若将树中结点赋给一个有着某种含义的数值，则这个数值称为该结点的权。 结点的带权路径：从根结点到该结点之间的路径长度与该结点的权的乘积。 树的带权路径：所有叶子结点的带权路径长度之和，记为WPL。 二叉排序树 二叉查找树，也称二叉搜索树、有序二叉树，排序二叉树，是指一棵空树或者具有下列性质的二叉树： 任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二分查找的时间复杂度是O(log(n))，最坏情况下的时间复杂度是O(n)（相当于顺序查找） 平衡二叉树 平衡树是计算机科学中的一类改进的二叉查找树。一般的二叉查找树的查询复杂度是跟目标结点到树根的距离（即深度）有关，因此当结点的深度普遍较大时，查询的均摊复杂度会上升，为了更高效的查询，平衡树应运而生了。平衡指所有叶子的深度趋于平衡，更广义的是指在树上所有可能查找的均摊复杂度偏低。 AVL树 AVL树是最先发明的 自平衡二叉查找树。在AVL树中任何节点的两个子树的高度最大差别为一，所以它也被称为高度平衡树。 它的左子树和右子树都是平衡二叉树。 左子树和右子树的深度之差的绝对值不超过1。 增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。 右旋：左结点转到根节点位置。 左旋：右节点转到根节点位置。 高度为k的AVL树，节点数N最多2^k -1，即满二叉树； 红黑树 红黑树是一种自平衡二叉查找树，每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求： 节点是红色或黑色。 根是黑色。 所有叶子都是黑色（叶子是NIL节点）。 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 如果一条路径上的顶点除了起点和终点可以相同外，其它顶点均不相同，则称此路径为一条简单路径；起点和终点相同的简单路径称为回路（或环）。 红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入/删除操作时少量的旋转操作，整体来说性能要优于AVL树。 这些约束确保了红黑树的关键特性：从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限 允许红黑树在最坏情况下都是高效的，而不同于普通的二叉查找树。 在很多树数据结构的表示中，一个节点有可能只有一个子节点，而叶子节点包含数据。用这种范例表示红黑树是可能的，但是这会改变一些性质并使算法复杂。为此，本文中我们使用\"nil叶子\"或\"空（null）叶子\"，如上图所示，它不包含数据而只充当树在此结束的指示。这些节点在绘图中经常被省略，导致了这些树好像同上述原则相矛盾，而实际上不是这样。与此有关的结论是所有节点都有两个子节点，尽管其中的一个或两个可能是空叶子。 因为每一个红黑树也是一个特化的二叉查找树，因此红黑树上的只读操作与普通二叉查找树上的只读操作相同。然而，在红黑树上进行插入操作和删除操作会导致不再符合红黑树的性质。恢复红黑树的性质需要少量（O(log n)）的颜色变更（实际是非常快速的）和不超过三次树旋转（对于插入操作是两次）。虽然插入和删除很复杂，但操作时间仍可以保持为O(log n)次。 B-树 是一种多路搜索树（并不是二叉的）： 所有叶子结点位于同一层，并且 不带信息。 树中每个节点最多有m个子树(即至多含有m-1个关键字)。 若根节点不是终端节点，则根节点子树[2,m]. 除根节点外其他非叶子节点至少有[m/2]个子树(即至少含有[m/2]-1个关键字)。 每个非叶子节点的结构为： | n | p0 | k1 | p1 | k2 | p2 | ... | kn | pn | n为该节点中的关键字个数，除根节点外，其他所有非叶子节点的关键字个数n：[m/2]-1 ki(i pi(0 B-树的阶：所有节点的孩子节点数的最大值 B-树的查找 在B-树中的查找给定关键字的方法 类似于二叉排序树上的查找，不同的是在每个节点上确定向下查找的路径不一定是二路的，而是n+1路的。因为节点内的关键字序列key[1..n]有序，故既可以使用顺序查找，也可以使用二分查找。在一棵B-树上查找关键字为k的方法为：将k与根节点中的key[i]进行比较： 若k=key[i]，则查找成功； 若k 若key[i] 若k>key[n]，则沿着指针ptr[n]所指的子树继续查找。 B-树的插入 将关键字k插入到B-树的过程分两步完成： 利用B-树的查找算法查找出该关键字的插入节点(注意B-树的插入节点一定属于最低非叶子节点层)。 判断该节点是否还有空位，即判断该节点是否满足n B-树的删除 首先查找B树中需删除的元素，如果该元素在B树中存在，则将该元素在其结点中进行删除；如果删除该元素后，首先判断该元素是否有左右孩子结点，如果有，则上移孩子结点中的某相近元素到父节点中，然后是移动之后的情况；如果没有，直接删除后，然后是移动之后的情况。 删除元素，移动相应元素之后，如果某结点中元素数目（即关键字数）小于Min(m/2)-1，则需要看其某相邻兄弟结点是否丰满，如果丰满，则向父节点借一个元素来满足条件；如果其相邻兄弟都刚脱贫，即借了之后其结点数目小于Min(m/2)-1，则该结点与其相邻的某一兄弟结点进行“合并”成一个结点， B+树 是一种自平衡二叉树，通常用于数据库和操作系统的文件系统中。B+树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+树元素自底向上插入，这与二叉树恰好相反。B+树不需要象其他自平衡二叉查找树那样经常的重新平衡。 B+树是B-树的变体，也是一种多路搜索树： 每个分支节点最多m个子树 根节点没有子树或至少两个子树 除根节点外，其他每个分支节点至少[m/2]个子树 有n个子树的节点有n个关键字 所有叶子节点包含全部关键字及指向相应记录的指针，而且叶子节点按关键字大小顺序链接(可以把每个叶子及诶单看成一个基本索引块，它的指针不再指向另一级索引块，而是直接指向数据文件中的记录) 所有分支节点中仅仅包含它的哥哥子节点(即下级索引块)中最大关键字及指向子节点的指针。 m阶的B+树和B-树的主要差异如下： 在B+树中，具有n个关键字的节点含有n个子树，即每个关键字对应一个子树，而在B-树中，具有n个关键字的节点含有(n+1)个子树。 在B+树中，每个节点(除根节点外)中的关键字个数n的取值范围是[m/2] B+树中所有叶子节点包含了全部关键字，即其他非叶子节点中的关键字包含在叶子节点中，而在B-树中，关键字是不重复的。 B+树中所有非叶子节点仅起到索引的作用，即节点中每个索引项值含有对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址。而在B-树中，每个关键字对应一个记录的存储地址。 通常B+树上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，所有叶子节点链接成一个不定长的线性表。 B+树的查找 在B+树中可以采用两种查找方式： 直接从最小关键字开始顺序查找。 从B+树的根节点开始随机查找。这种查找方式与B-树的查找方式类似，只是在分支节点上的关键字与查找值相等时，查找并不会结束，要继续查到叶子节点为止，此时若查找成功，则按所给指针取出对应元素。 在B+树中，不管查找是否成功，每次查找都是经历一条树从根节点到叶子节点的路径。 B+树的插入 首先，查找要插入其中的节点的位置。接着把值插入这个节点中。 如果没有节点处于违规状态则处理结束。 如果某个节点有过多元素，则把它分裂为两个节点，每个都有最小数目的元素。在树上递归向上继续这个处理直到到达根节点，如果根节点被分裂，则创建一个新根节点。为了使它工作，元素的最小和最大数目典型的必须选择为使最小数不小于最大数的一半。 B+树的删除 首先，查找要删除的值。接着从包含它的节点中删除这个值。 如果没有节点处于违规状态则处理结束。 如果节点处于违规状态则有两种可能情况： 它的兄弟节点，就是同一个父节点的子节点，可以把一个或多个它的子节点转移到当前节点，而把它返回为合法状态。如果是这样，在更改父节点和两个兄弟节点的分离值之后处理结束。 它的兄弟节点由于处在低边界上而没有额外的子节点。在这种情况下把两个兄弟节点合并到一个单一的节点中，而且我们递归到父节点上，因为它被删除了一个子节点。持续这个处理直到当前节点是合法状态或者到达根节点，在其上根节点的子节点被合并而且合并后的节点成为新的根节点。 B-树和B+树 主要用于外部查找，即数据在外存中。 B+树的优势所在 为什么说B+树比B-树更适合实际应用中操作系统的文件索引和数据库索引？ B+树的磁盘读写代价更低 我们都知道磁盘时可以块存储的，也就是同一个磁道上同一盘块中的所有数据都可以一次全部读取。而B+树的内部结点并没有指向关键字具体信息的指针(比如文件内容的具体地址 ） 。因此其内部结点相对B-树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。这样，一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。 举个例子，假设磁盘中的一个盘块容纳16bytes，而一个关键字2bytes，一个关键字具体信息指针2bytes。一棵9阶B-树(一个结点最多8个关键字)的内部结点需要2个盘块。而B+树内部结点只需要1个盘块。当需要把内部结点读入内存中的时候，B-树就比B+数多一次盘块查找时间（在磁盘中就是盘片旋转的时间）。 B+树的查询效率更加稳定。 由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 Trie树 Trie树，又称前缀树，字典树， 是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。 Trie树查询和插入时间复杂度都是 O(n)，是一种以空间换时间的方法。当节点树较多的时候，Trie 树占用的内存会很大。 Trie树常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/1-algo/2-hash.html":{"url":"basic/1-algo/2-hash.html","title":"Hash","keywords":"","body":"Hash 哈希表（Hash Table，也叫散列表），是根据关键码值 (Key-Value) 而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。哈希表的实现主要需要解决两个问题，哈希函数和冲突解决。 哈希函数 哈希函数也叫散列函数，它对不同的输出值得到一个固定长度的消息摘要。理想的哈希函数对于不同的输入应该产生不同的结构，同时散列结果应当具有同一性（输出值尽量均匀）和雪崩效应（微小的输入值变化使得输出值发生巨大的变化）。 冲突解决 开放地址法：以发生冲突的哈希地址为输入，通过某种哈希冲突函数得到一个新的空闲的哈希地址的方法。有以下几种方式： 线性探查法：从发生冲突的地址开始，依次探查下一个地址，直到找到一个空闲单元。 平方探查法：设冲突地址为d0，则探查序列为：d0+1^2,d0-1^2,d0+2^2... 拉链法：把所有的同义词用单链表链接起来。在这种方法下，哈希表每个单元中存放的不再是元素本身，而是相应同义词单链表的头指针。HashMap就是使用这种方法解决冲突的。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/1-algo/3-mst.html":{"url":"basic/1-algo/3-mst.html","title":"最小生成树算法","keywords":"","body":"最小生成树算法 连通图：在无向图G中，若从顶点i到顶点j有路径，则称顶点i和顶点j是连通的。若图G中任意两个顶点都连通，则称G为连通图。 生成树：一个连通图的生成树是该连通图的一个极小连通子图，它含有全部顶点，但只有构成一个数的(n-1)条边。 最小生成树：对于一个带权连通无向图G中的不同生成树，各树的边上的 权值之和最小。构造最小生成树的准则有三条： 必须只使用该图中的边来构造最小生成树。 必须使用且仅使用(n-1)条边来连接图中的n个顶点。 不能使用产生回路的边。 Prim算法 假设G=(V,E)是一个具有n个顶点的带权连通无向图，T(U,TE)是G的最小生成树，其中U是T的顶点集，TE是T的边集，则由G构造从起始顶点v出发的最小生成树T的步骤为： 初始化U={v}，以v到其他顶点的所有边为候选边(U中所有点到其他顶点的边)。 重复以下步骤(n-1)次，使得其他(n-1)个顶点被加入到U中。 从候选边中挑选权值最小的边加入TE，设该边在V-U(这里是集合减)中的顶点是k，将k加入U中。 考察当前V-U中的所有顶点j，修改候选边，若边(k,j)的权值小于原来和顶点j关联的候选边，则用(k,j)取代后者作为候选边。 Kruskal算法 假设G=(V,E)是一个具有n个顶点的带权连通无向图，T(U,TE)是G的最小生成树，其中U是T的顶点集，TE是T的边集，则由G构造从起始顶点v出发的最小生成树T的步骤为： 置U的初始值等于V(即包含G中的全部顶点)，TE的初始值为空 将图G中的边按权值从小到大的顺序依次选取，若选取的边未使生成树T形成回路，则加入TE，否则放弃，知道TE中包含(n-1)条边为止。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/1-algo/4-path.html":{"url":"basic/1-algo/4-path.html","title":"最短路径算法","keywords":"","body":"最短路径算法 Dijkstra —— 贪心算法 从一个顶点到其余顶点的最短路径 设G=(V,E)是一个带权有向图，把图中顶点集合V分成两组，第1组为已求出最短路径的顶点（用S表示，初始时S只有一个源点，以后每求得一条最短路径v,...k，就将k加到集合S中，直到全部顶点都加入S）。第2组为其余未确定最短路径的顶点集合（用U表示），按最短路径长度的递增次序把第2组的顶点加入S中。 步骤： 1. 初始时，S只包含源点，即`S={v}`，顶点v到自己的距离为0。U包含除v外的其他顶点，v到U中顶点i的距离为边上的权。 2. 从U中选取一个顶点u，顶点v到u的距离最小，然后把顶点u加入S中。 3. 以顶点u为新考虑的中间点，修改v到U中各个点的距离。 4. 重复以上步骤知道S包含所有顶点。 Floyd —— 动态规划 Floyd 算法是解决任意两点间的最短路径的一种算法，可以正确处理有向图或负权（但不可存在负权回路）的最短路径问题。该算法的时间复杂度为 O(N^{3})，空间复杂度为 O(N^{2}) 设 D_{i,j,k} 为从 i 到 j 的只以 (1..k) 集合中的节点为中间节点的最短路径的长度。 D_{i,j,k}=\\begin{cases} D_{i,j,k-1} & 最短路径不经过 k\\\\ D_{i,k,k-1}+D_{k,j,k-1} & 最短路径经过 k \\end{cases} 因此， D_{i,j,k}=min(D_{i,k,k-1}+D_{k,j,k-1},D_{i,j,k-1})。伪代码描述如下： // let dist be a |V| × |V| array of minimum distances initialized to ∞ (infinity) for each vertex v dist[v][v] ← 0 for each edge (u,v) dist[u][v] ← w(u,v) // the weight of the edge (u,v) for k from 1 to |V| for i from 1 to |V| for j from 1 to |V| if dist[i][j] > dist[i][k] + dist[k][j] dist[i][j] ← dist[i][k] + dist[k][j] end if 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/1-algo/5-kmp.html":{"url":"basic/1-algo/5-kmp.html","title":"KMP算法","keywords":"","body":"KMP算法 KMP算法解决的问题是字符匹配，这个算法把字符匹配的时间复杂度缩小到O(m+n),而空间复杂度也只有O(m),n是target的长度，m是pattern的长度。 部分匹配表（Next数组）：表的作用是 让算法无需多次匹配S中的任何字符。能够实现线性时间搜索的关键是 在不错过任何潜在匹配的情况下，我们\"预搜索\"这个模式串本身并将其译成一个包含所有可能失配的位置对应可以绕过最多无效字符的列表。 Next数组（前缀和前缀的比较）：t为模式串，j为下标 Next[0] = -1 Next[j] = MAX{ k | 0 i 0 1 2 3 4 5 6 t[i] A B C D A B D next[i] -1 0 0 0 0 1 2 NextVal数组：是一种优化后的Next数组，是为了解决类似aaaab这种模式串的匹配，减少重复的比较。 如果t[next[j]]=t[j]：nextval[j]=nextval[next[j]]，否则nextval[j]=next[j]。 i 0 1 2 3 4 5 6 t a b c a b a a next[j] -1 0 0 0 1 2 1 nextval[j] -1 0 0 -1 0 2 1 在上面的表格中，t[next[4]]=t[4]=b，所以nextval[4]=nextval[next[4]]=0 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/1-algo/6-search.html":{"url":"basic/1-algo/6-search.html","title":"查找算法","keywords":"","body":"查找算法 ASL 由于查找算法的主要运算是关键字的比较，所以通常把查找过程中对关键字的平均比较次数（平均查找长度）作为衡量一个查找算法效率的标准。ASL= ∑(n,i=1) Pi*Ci，其中n为元素个数，Pi是查找第i个元素的概率，一般为Pi=1/n，Ci是找到第i个元素所需比较的次数。 顺序查找 原理是让关键字与队列中的数从最后一个开始逐个比较，直到找出与给定关键字相同的数为止，它的缺点是效率低下。时间复杂度o(n)。 折半查找 折半查找要求线性表是有序表。搜索过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜索过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组为空，则代表找不到。这种搜索算法每一次比较都使搜索范围缩小一半。折半搜索每次把搜索区域减少一半，时间复杂度为O(log n)。 可以借助二叉判定树求得折半查找的平均查找长度：log2(n+1)-1。 折半查找在失败时所需比较的关键字个数不超过判定树的深度，n个元素的判定树的深度和n个元素的完全二叉树的深度相同log2(n)+1。 public int binarySearchStandard(int[] num, int target){ int start = 0; int end = num.length - 1; while(start > 1); if(num[mid] == target) return mid; else if(num[mid] > target){ end = mid - 1; //注意2 } else{ start = mid + 1; //注意3 } } return -1; } 如果是start 因为num[mid] > target, 所以如果有num[index] == target, index一定小于mid，能不能写成end = mid呢？举例来说：num = {1, 2, 5, 7, 9}; 如果写成end = mid，当循环到start = 0, end = 0时（即num[start] = 1, num[end] = 1时），mid将永远等于0，此时end也将永远等于0，陷入死循环。也就是说寻找target = -2时，程序将死循环。 因为num[mid] 分块查找 分块查找又称索引顺序查找，它是一种性能介于顺序查找和折半查找之间的查找方法。分块查找由于只要求索引表是有序的，对块内节点没有排序要求，因此特别适合于节点动态变化的情况。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/1-algo/7-sort.html":{"url":"basic/1-algo/7-sort.html","title":"排序算法","keywords":"","body":"排序算法 常见排序算法 稳定排序： 冒泡排序 — O(n²) 插入排序 — O(n²) 桶排序 — O(n); 需要 O(k) 额外空间 归并排序 — O(nlogn); 需要 O(n) 额外空间 二叉排序树排序 — O(n log n) 期望时间; O(n²)最坏时间; 需要 O(n) 额外空间 基数排序 — O(n·k); 需要 O(n) 额外空间 不稳定排序 选择排序 — O(n²) 希尔排序 — O(nlogn) 堆排序 — O(nlogn) 快速排序 — O(nlogn) 期望时间, O(n²) 最坏情况; 对于大的、乱数串行一般相信是最快的已知排序 交换排序 冒泡排序 它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。冒泡排序总的平均时间复杂度为O(n^2)。冒泡排序是一种稳定排序算法。 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 void bubble_sort(int a[], int n) { int i, j, temp; for (j = 0; j a[i + 1]) { temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; } } } 快速排序 快速排序-百度百科 快速排序是一种 不稳定 的排序算法，平均时间复杂度为 O(nlogn)。快速排序使用分治法（Divide and conquer）策略来把一个序列（list）分为两个子序列（sub-lists）。 步骤为： 从数列中挑出一个元素，称为\"基准\"（pivot）， 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。 快排的时间花费主要在划分上，所以 最坏情况：时间复杂度为O(n^2)。因为最坏情况发生在每次划分过程产生的两个区间分别包含n-1个元素和1个元素的时候。 最好情况：每次划分选取的基准都是当前无序区的中值。如果每次划分过程产生的区间大小都为n/2，则快速排序法运行就快得多了。 public void sort(int[] arr, int low, int high) { int l = low; int h = high; int povit = arr[low]; while (l = povit) h--; if (l low) sort(arr, low, l - 1); if (h + 1 快排的优化 当待排序序列的长度分割到一定大小后，使用插入排序。 快排函数在函数尾部有两次递归操作，我们可以对其使用尾递归优化。优化后，可以缩减堆栈深度，由原来的O(n)缩减为O(logn)，将会提高性能。 从左、中、右三个数中取中间值。 插入排序 直接插入排序 插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的、个数加一的有序数据，算法适用于少量数据的排序，时间复杂度为O(n^2)。是稳定的排序方法。 插入算法把要排序的数组分成两部分：第一部分包含了这个数组的所有元素，但将最后一个元素除外（让数组多一个空间才有插入的位置），而第二部分就只包含这一个元素（即待插入元素）。在第一部分排序完成后，再将这个最后元素插入到已排好序的第一部分中。 void insert_sort(int* a, int len) { for (int i = 1; i = 0 && temp 希尔排序 也称缩小增量排序，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。 希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。 void shell_sort(int* a, int len) { int step = len / 2; int temp; while (step > 0) { for (int i = step; i = 0 && temp 选择排序 直接选择排序 首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。实际适用的场合非常罕见。 void selection_sort(int arr[], int len) { int i, j, min, temp; for (i = 0; i arr[j]) min = j; temp = arr[min]; arr[min] = arr[i]; arr[i] = temp; } } 堆排序 堆排序利用了大根堆（或小根堆）堆顶记录的关键字最大（或最小）这一特征，使得在当前无序区中选取最大（或最小）关键字的记录变得简单。 将数组分为有序区和无序区，在无序区中建立最大堆 将堆顶的数据与无序区末尾的数据交换 从后往前，直到所有数据排序完成 public void heapSort(int[] nums) { for (int i = nums.length - 1; i >= 0; i--) { maxHeap(nums, 0, i); swap(nums, 0, i); } } public void maxHeap(int[] heap, int start, int end) { if (start == end) { return; } int parent = start; int childLeft = start * 2 + 1; int childRight = childLeft + 1; if (childLeft heap[parent]) { swap(heap, parent, childLeft); } } if (childRight heap[parent]) { swap(heap, parent, childRight); } } } private void swap(int[] nums, int a, int b) { int t = nums[a]; nums[a] = nums[b]; nums[b] = t; } 归并排序 归并排序采用分治的思想： Divide：将n个元素平均划分为各含n/2个元素的子序列； Conquer：递归的解决俩个规模为n/2的子问题； Combine：合并俩个已排序的子序列。 性能：时间复杂度总是为O(NlogN)，空间复杂度也总为为O(N)，算法与初始序列无关，排序是稳定的。 public void mergeSort(int[] array, int start, int end, int[] temp) { if (start >= end) { return; } int mid = (start + end) / 2; mergeSort(array, start, mid, temp); mergeSort(array, mid + 1, end, temp); int f = start, s = mid + 1; int t = 0; while (f 基数排序 对于有d个关键字时，可以分别按关键字进行排序。有俩种方法： MSD：先从高位开始进行排序，在每个关键字上，可采用基数排序 LSD：先从低位开始进行排序，在每个关键字上，可采用桶排序 即通过每个数的每位数字的大小来比较 //找出最大数字的位数 int maxNum(int arr[], int len) { int _max = 0; for (int i = 0; i 拓扑排序 在有向图中找拓扑序列的过程，就是拓扑排序。拓扑序列常常用于判定图是否有环。 从有向图中选择一个入度为0的结点，输出它。 将这个结点以及该结点出发的所有边从图中删除。 重复前两步，直到没有入度为0的点。 如果所有点都被输出，即存在一个拓扑序列，则图没有环。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/1-algo/9-skip_list.html":{"url":"basic/1-algo/9-skip_list.html","title":"跳跃表","keywords":"","body":"跳跃表 跳跃列表是一种数据结构。它允许快速查询一个有序连续元素的数据链表。跳跃列表的平均查找和插入时间复杂度都是 O(log n) ，优于普通队列的 O(n)。 快速查询是通过维护一个多层次的链表，且每一层链表中的元素是前一层链表元素的子集。一开始时，算法在最稀疏的层次进行搜索，直至需要查找的元素在该层两个相邻的元素中间。这时，算法将跳转到下一个层次，重复刚才的搜索，直到找到需要查找的元素为止。跳过的元素的方法可以是 随机性选择 或 确定性选择，其中前者更为常见。 在查找目标元素时，从顶层列表、头元素起步。算法沿着每层链表搜索，直至找到一个大于或等于目标的元素，或者到达当前层列表末尾。如果该元素等于目标元素，则表明该元素已被找到；如果该元素大于目标元素或已到达链表末尾，则退回到当前层的上一个元素，然后转入下一层进行搜索。 跳跃列表不像平衡树等数据结构那样提供对最坏情况的性能保证：由于用来建造跳跃列表采用随机选取元素进入更高层的方法，在小概率情况下会生成一个不平衡的跳跃列表（最坏情况例如最底层仅有一个元素进入了更高层，此时跳跃列表的查找与普通列表一致）。但是在实际中它通常工作良好，随机化平衡方案也比平衡二叉查找树等数据结构中使用的确定性平衡方案容易实现。跳跃列表在并行计算中也很有用：插入可以在跳跃列表不同的部分并行地进行，而不用对数据结构进行全局的重新平衡。 跳跃表插入一个元素： 实现 因为跳跃列表中的元素可以在多个列表中，所以每个元素可以有多于一个指针。跳跃列表的插入和删除的实现与普通的链表操作类似，但高层元素必须在进行多个链表中进行插入或删除。 package io.github.hadyang.leetcode.algo; import lombok.Getter; import lombok.Setter; import java.util.Arrays; import java.util.Random; /** * @author haoyang.shi */ public class SkipList, V> { @Getter @Setter static final class Node, V> { private K key; private V value; private Node up, down, pre, next; Node(K key, V value) { this.key = key; this.value = value; } @Override public String toString() { return \"Node{\" + \"key=\" + key + \", value=\" + value + \", hashcode=\" + hashCode() + \", up=\" + (up == null ? \"null\" : up.hashCode()) + \", down=\" + (down == null ? \"null\" : down.hashCode()) + \", pre=\" + (pre == null ? \"null\" : pre.hashCode()) + \", next=\" + (next == null ? \"null\" : next.hashCode()) + '}'; } } private Node head;//k,v都是NULL private Integer levels = 0; private Integer length = 0; private Random random = new Random(System.currentTimeMillis()); public SkipList() { createNewLevel(); } public void put(K key, V value) { if (key == null || value == null) { return; } Node newNode = new Node<>(key, value); insertNode(newNode); } private void insertNode(Node newNode) { Node curNode = findNode(newNode.getKey()); if (curNode.getKey() == null) { insertNext(curNode, newNode); } else if (curNode.getKey().compareTo(newNode.getKey()) == 0) { //update curNode.setValue(newNode.getValue()); return; } else { insertNext(curNode, newNode); } int currentLevel = 1; Node oldTop = newNode; while (random.nextInt(100) newTop = new Node<>(newNode.getKey(), null); if (currentLevel >= levels) { createNewLevel(); } while (curNode.getPre() != null && curNode.getUp() == null) { curNode = curNode.getPre(); } if (curNode.getUp() == null) { continue; } curNode = curNode.getUp(); Node curNodeNext = curNode.getNext(); curNode.setNext(newTop); newTop.setPre(curNode); newTop.setDown(oldTop); oldTop.setUp(newTop); newTop.setNext(curNodeNext); oldTop = newTop; currentLevel++; } } private void createNewLevel() { Node newHead = new Node<>(null, null); if (this.head == null) { this.head = newHead; this.levels++; return; } this.head.setUp(newHead); newHead.setDown(this.head); this.head = newHead; this.levels++; } private void insertNext(Node curNode, Node newNode) { Node curNodeNext = curNode.getNext(); newNode.setNext(curNodeNext); if (curNodeNext != null) { curNodeNext.setPre(newNode); } curNode.setNext(newNode); newNode.setPre(curNode); this.length++; } public V get(K key) { Node node = findNode(key); if (key.equals(node.getKey())) { return node.getValue(); } return null; } private Node findNode(K key) { Node curNode = this.head; for (; ; ) { while (curNode.getNext() != null && curNode.getNext().getKey().compareTo(key) curI = this.head; String[][] strings = new String[levels][length + 1]; for (String[] string : strings) { Arrays.fill(string, \"0\"); } while (curI.getDown() != null) { curI = curI.getDown(); } System.out.println(\"levels:\" + levels + \"_\" + \"length:\" + length); int i = 0; while (curI != null) { Node curJ = curI; int j = levels - 1; while (curJ != null) { strings[j][i] = String.valueOf(curJ.getKey()); if (curJ.getUp() == null) { break; } curJ = curJ.getUp(); j--; } if (curI.getNext() == null) { break; } curI = curI.getNext(); i++; } for (String[] string : strings) { System.out.println(Arrays.toString(string)); } } public static void main(String[] args) { SkipList skipList = new SkipList<>(); skipList.put(2, \"B\"); skipList.put(1, \"A\"); skipList.put(3, \"C\"); skipList.print(); System.out.println(skipList.get(2)); } } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/1-algo/8-questions.html":{"url":"basic/1-algo/8-questions.html","title":"面试题","keywords":"","body":"面试题 什么是迭代器失效？ 对于vector而言，添加和删除操作可能使容器的部分或者全部迭代器失效。那为什么迭代器会失效呢？vector元素在内存中是顺序存储，试想：如果当前容器中已经存在了10个元素，现在又要添加一个元素到容器中，但是内存中紧跟在这10个元素后面没有一个空闲空间，而vector的元素必须顺序存储一边索引访问，所以我们不能在内存中随便找个地方存储这个元素。于是vector必须重新分配存储空间，用来存放原来的元素以及新添加的元素：存放在旧存储空间的元素被复制到新的存储空间里，接着插入新的元素，最后撤销旧的存储空间。这种情况发生，一定会导致vector容器的所有迭代器都失效。 二叉树如何转换为森林？ 若结点x是双亲y的左孩子，则把x的右孩子，右孩子的右孩子，…，都与y用连线连起来，最后去掉所有双亲到右孩子的连线。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/2-op/":{"url":"basic/2-op/","title":"操作系统","keywords":"","body":"操作系统 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/2-op/1-arch.html":{"url":"basic/2-op/1-arch.html","title":"计算机体系结构","keywords":"","body":"计算机体系结构 冯·诺依曼体系结构 计算机处理的数据和指令一律用二进制数表示 顺序执行程序 计算机运行过程中，把要执行的程序和处理的数据首先存入主存储器（内存），计算机执行程序时，将自动地并按顺序从主存储器中取出指令一条一条地执行，这一概念称作顺序执行程序。 计算机硬件由运算器、控制器、存储器、输入设备和输出设备五大部分组成。 数据的机内表示 二进制表示 机器数 由于计算机中符号和数字一样，都必须用二进制数串来表示，因此，正负号也必须用0,1来表示。 原码 原码用第一位表示符号, 其余位表示值. 比如如果是8位二进制: [+1]原 = 0000 0001 [-1]原 = 1000 0001 第一位是符号位. 因为第一位是符号位, 所以8位二进制数的取值范围就是: [1111 1111 , 0111 1111] 即 [-127 , 127] 原码是人脑最容易理解和计算的表示方式 反码 正数的反码是其本身 负数的反码是在其原码的基础上, 符号位不变，其余各个位取反. [+1] = [00000001]原 = [00000001]反 [-1] = [10000001]原 = [11111110]反 可见如果一个反码表示的是负数，人脑无法直观的看出来它的数值， 通常要将其转换成原码再计算。 补码 正数的补码就是其本身 负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1。 (即在反码的基础上+1) [+1] = [00000001]原 = [00000001]反 = [00000001]补 [-1] = [10000001]原 = [11111110]反 = [11111111]补 1+（-1)= 00000001 + 11111111 = 00000000 = 0 对于负数, 补码表示方式也是人脑无法直观看出其数值的. 通常也需要转换成原码在计算其数值. 在计算机系统中，数值一律用补码来表示和存储。原因在于，使用补码，可以将符号位和数值域统一处理；同时，加法和减法也可以统一处理。此外，补码与原码相互转换，其运算过程是相同的，不需要额外的硬件电路。 定点数与浮点数 定点数是小数点固定的数。在计算机中没有专门表示小数点的位，小数点的位置是约定默认的。一般固定在机器数的最低位之后，或是固定在符号位之后。前者称为定点纯整数，后者称为定点纯小数。 定点数表示法简单直观，但是 数值表示的范围太小，运算时容易产生溢出。 浮点数是小数点的位置可以变动的数。为增大数值表示范围，防止溢出，采用浮点数表示法。浮点表示法类似于十进制中的科学计数法。 在计算机上，通常使用2为基数的幂数来表式。一个浮点数a由两个数m和e来表示：a = m × b^e。在任意一个这样的系统中，我们选择一个基数b（记数系统的基）和精度p（即使用多少位来存储）。m （即尾数）是形如±d.ddd...ddd的p位数（每一位是一个介于0到b-1之间的整数，包括0和b-1）。如果m的第一位是非0整数，m称作正规化的。e是指数。 | 数符± | 阶码e | 尾数m | 数符表示尾数的符号位，阶码表示幂次，尾数表示规格化后的小数值。 32位单精度：单精度二进制小数，使用32位存储。1 8 23 位长 64位双精度：双精度二进制小数，使用64位存储。1 11 52 位长 位、字节、字 位(Bit)：电子计算机中最小的数据单位。每一位的状态只能是0或1。 字节(Byte)：8个二进制位构成1个字节，它是存储空间的基本计量单位。1个字节可以储存1个英文字母或者半个汉字，换句话说，1个汉字占据2个字节的存储空间。 字(Word)：由若干个字节构成，字的位数叫做字长，不同档次的机器有不同的字长。例如一台8位机，它的1个字就等于1个字节，字长为8位。如果是一台16位机，那么，它的1个字就由2个字节构成，字长为16位。字是计算机进行数据处理和运算的单位。 字节序 字节顺序是指占内存多于一个字节类型的数据在内存中的存放顺序，通常有小端、大端两种字节顺序。 小端字节序：低字节数据存放在内存低地址处，高字节数据存放在内存高地址处。 大端字节序：高字节数据存放在低地址处，低字节数据存放在高地址处。 基于X86平台的PC机是小端字节序的，而有的嵌入式平台则是大端字节序的。所有网络协议也都是采用大端字节序的方式来传输数据的。所以有时我们也会把大端字节序方式称之为网络字节序。 比如数字 0x12345678 在两种不同字节序CPU中的存储顺序如下所示： Big Endian 低地址 高地址 ----------------------------------------------------> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | 12 | 34 | 56 | 78 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Little Endian 低地址 高地址 ----------------------------------------------------> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | 78 | 56 | 34 | 12 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 从上面两图可以看出，采用Big Endian方式存储数据是符合我们人类的思维习惯的。 联合体union的存放顺序是所有成员都从低地址开始存放，利用该特性，就能判断CPU对内存采用Little-endian还是Big-endian模式读写。 字节对齐 现代计算机中内存空间都是按照字节划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但实际情况是在访问特定类型变量的时候经常在特定的内存地址访问，这就需要各种类型数据按照一定的规则在空间上排列，而不是顺序的一个接一个的排放，这就是对齐。 为什么要进行字节对齐？ 某些平台只能在特定的地址处访问特定类型的数据; 最根本的原因是效率问题，字节对齐能提高存取数据的速度。 比如有的平台每次都是从偶地址处读取数据,对于一个int型的变量,若从偶地址单元处存放,则只需一个读取周期即可读取该变量，但是若从奇地址单元处存放，则需要2个读取周期读取该变量。 字节对齐的原则 数据成员对齐规则：结构体或联合体的数据成员，第一个数据成员放在 offset 为0的地方，以后每个数据成员存储的起始位置要从该成员大小或者成员的子成员大小（只要该成员有子成员，比如说是数组，结构体等）的整数倍开始（比如int在32位机为4字节,则要从4的整数倍地址开始存储）。 结构体作为成员：如果一个结构里有某些结构体成员，则结构体成员要从其内部最大元素大小的整数倍地址开始存储。(struct a里存有struct b,b里有char,int ,double等元素,那b应该从8的整数倍开始存储。) 收尾工作：结构体的总大小，也就是sizeof的结果，必须是其内部最大成员的整数倍，不足的要补齐。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/2-op/2-os.html":{"url":"basic/2-op/2-os.html","title":"操作系统基础","keywords":"","body":"操作系统基础 操作系统提供的服务 操作系统的五大功能，分别为：作业管理、文件管理、存储管理、输入输出设备管理、进程及处理机管理 中断 所谓的中断就是在计算机执行程序的过程中，由于出现了某些特殊事情，使得CPU暂停对程序的执行，转而去执行处理这一事件的程序。等这些特殊事情处理完之后再回去执行之前的程序。中断一般分为三类： 内部异常中断：由计算机硬件异常或故障引起的中断； 软中断：由程序中执行了引起中断的指令而造成的中断（这也是和我们将要说明的系统调用相关的中断）； 外部中断：由外部设备请求引起的中断，比如I/O请求。 简单来说，对中断的理解就是对一些特殊事情的处理。 与中断紧密相连的一个概念就是中断处理程序了。当中断发生的时候，系统需要去对中断进行处理，对这些中断的处理是由操作系统内核中的特定函数进行的，这些处理中断的特定的函数就是我们所说的中断处理程序了。 另一个与中断紧密相连的概念就是中断的优先级。中断的优先级说明的是当一个中断正在被处理的时候，处理器能接受的中断的级别。中断的优先级也表明了中断需要被处理的紧急程度。每个中断都有一个对应的优先级，当处理器在处理某一中断的时候，只有比这个中断优先级高的中断可以被处理器接受并且被处理。优先级比这个当前正在被处理的中断优先级要低的中断将会被忽略。 典型的中断优先级如下所示： 机器错误 > 时钟 > 磁盘 > 网络设备 > 终端 > 软件中断 当发生软件中断时，其他所有的中断都可能发生并被处理；但当发生磁盘中断时，就只有时钟中断和机器错误中断能被处理了。 系统调用 在讲系统调用之前，先说下进程的执行在系统上的两个级别：用户级和核心级，也称为用户态和系统态(user mode and kernel mode)。 程序的执行一般是在用户态下执行的，但当程序需要使用操作系统提供的服务时，比如说打开某一设备、创建文件、读写文件等，就需要向操作系统发出调用服务的请求，这就是系统调用。 Linux系统有专门的函数库来提供这些请求操作系统服务的入口，这个函数库中包含了操作系统所提供的对外服务的接口。当进程发出系统调用之后，它所处的运行状态就会由用户态变成核心态。但这个时候，进程本身其实并没有做什么事情，这个时候是由内核在做相应的操作，去完成进程所提出的这些请求。 系统调用和中断的关系就在于，当进程发出系统调用申请的时候，会产生一个软件中断。产生这个软件中断以后，系统会去对这个软中断进行处理，这个时候进程就处于核心态了。 那么用户态和核心态之间的区别是什么呢？ 用户态的进程能存取它们自己的指令和数据，但不能存取内核指令和数据（或其他进程的指令和数据）。然而，核心态下的进程能够存取内核和用户地址 某些机器指令是特权指令，在用户态下执行特权指令会引起错误 对此要理解的一个是，在系统中内核并不是作为一个与用户进程平行的估计的进程的集合，内核是为用户进程运行的。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/2-op/3-concurrency.html":{"url":"basic/2-op/3-concurrency.html","title":"并发","keywords":"","body":"并发 进程 进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的代码，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示。 进程的概念主要有两点： 进程是一个实体，每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。 进程是一个“执行中的程序”，程序是一个没有生命的实体，只有处理器赋予程序生命时，它才能成为一个活动的实体，我们称其为进程。 进程的基本状态 阻塞态：等待某个事件的完成； 就绪态：等待系统分配处理器以便运行； 执行态：占有处理器正在运行。 执行态 -> 阻塞态：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。 阻塞态 -> 就绪态：则是等待的条件已满足，只需分配到处理器后就能运行。 执行态 -> 就绪态：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。 就绪态 -> 执行态：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态 进程调度 调度种类 高级、中级和低级调度作业从提交开始直到完成，往往要经历下述三级调度： 高级调度：又称为作业调度，它决定把后备作业调入内存运行； 中级调度：又称为在虚拟存储器中引入，在内、外存对换区进行进程对换。 低级调度：又称为进程调度，它决定把就绪队列的某进程获得CPU； 非抢占式调度与抢占式调度 非抢占式：分派程序一旦把处理机分配给某进程后便让它一直运行下去，直到进程完成或发生进程调度进程调度某事件而阻塞时，才把处理机分配给另一个进程。 抢占式：操作系统将正在运行的进程强行暂停，由调度程序将CPU分配给其他就绪进程的调度方式。 调度策略的设计 响应时间：从用户输入到产生反应的时间 周转时间：从任务开始到任务结束的时间 平均周转时间：周转总时间除以作业个数 CPU任务可以分为交互式任务和批处理任务，调度最终的目标是合理的使用CPU，使得交互式任务的响应时间尽可能短，用户不至于感到延迟，同时使得批处理任务的周转时间尽可能短，减少用户等待的时间。 调度算法 FCFS：调度的顺序就是任务到达就绪队列的顺序。对短作业不公平。 公平、简单(FIFO队列)、非抢占、不适合交互式。未考虑任务特性，平均等待时间可以缩短 SJF：最短的作业(CPU区间长度最小)最先调度。 可以证明，SJF可以保证最小的平均等待时间。 SRJF：SJF的可抢占版本，比SJF更有优势。 SJF(SRJF): 如何知道下一CPU区间大小？根据历史进行预测: 指数平均法。 HRN：最高响应比优先法，是FCFS和SJF的综合平衡，响应比R定义如下： R =(W+T)/T 。 优先权调度：每个任务关联一个优先权，调度优先权最高的任务。 注意：优先权太低的任务一直就绪，得不到运行，出现“饥饿”现象。 FCFS是RR的特例，SJF是优先权调度的特例。这些调度算法都不适合于交互式系统。 Round-Robin(RR)：设置一个时间片，按时间片来轮转调度 优点: 定时有响应，等待时间较短；缺点: 上下文切换次数较多； 时间片太大，响应时间太长；吞吐量变小，周转时间变长；当时间片过长时，退化为FCFS。 多级队列调度 按照一定的规则建立多个进程队列 不同的队列有固定的优先级（高优先级有抢占权） 不同的队列可以给不同的时间片和采用不同的调度方法 存在问题1：没法区分I/O bound和CPU bound； 存在问题2：也存在一定程度的“饥饿”现象； 多级反馈队列：在多级队列的基础上，任务可以在队列之间移动，更细致的区分任务。可以根据“享用”CPU时间多少来移动队列，阻止“饥饿”。 最通用的调度算法，多数OS都使用该方法或其变形，如UNIX、Windows等。 进程同步 临界资源与临界区 在操作系统中，进程是占有资源的最小单位（线程可以访问其所在进程内的所有资源，但线程本身并不占有资源或仅仅占有一点必须资源）。但对于某些资源来说，其在同一时间只能被一个进程所占用。这些一次只能被一个进程所占用的资源就是所谓的临界资源。典型的临界资源比如物理上的打印机，或是存在硬盘或内存中被多个进程所共享的一些变量和数据等(如果这类资源不被看成临界资源加以保护，那么很有可能造成丢数据的问题)。 对于临界资源的访问，必须是互斥进行。也就是当临界资源被占用时，另一个申请临界资源的进程会被阻塞，直到其所申请的临界资源被释放。而进程内访问临界资源的代码被成为临界区。 对于临界区的访问过程分为四个部分： 进入区:查看临界区是否可访问，如果可以访问，则转到步骤二，否则进程会被阻塞 临界区:在临界区做操作 退出区:清除临界区被占用的标志 剩余区：进程与临界区不相关部分的代码 解决临界区问题可能的方法： 一般软件方法 关中断方法 硬件原子指令方法 信号量方法 信号量 信号量是一个确定的二元组（s，q），其中s是一个具有非负初值的整形变量，q是一个初始状态为空的队列，整形变量s表示系统中某类资源的数目： 当其值 >= 0 时，表示系统中当前可用资源的数目 当其值 时，其绝对值表示系统中因请求该类资源而被阻塞的进程数目 除信号量的初值外，信号量的值仅能由P操作和V操作更改，操作系统利用它的状态对进程和资源进行管理 P操作 P操作记为P(s)，其中s为一信号量，它执行时主要完成以下动作： s.value = s.value - 1； /*可理解为占用1个资源，若原来就没有则记帐“欠”1个*/ 若s.value ≥ 0，则进程继续执行，否则（即s.value 实际上，P操作可以理解为分配资源的计数器，或是使进程处于等待状态的控制指令 V操作 V操作记为V(s)，其中s为一信号量，它执行时，主要完成以下动作： s.value = s.value + 1；/*可理解为归还1个资源，若原来就没有则意义是用此资源还1个欠帐*/ 若s.value > 0，则进程继续执行，否则（即s.value ≤ 0），则从信号量s的等待队s.queue中移出第一个进程，使其变为就绪状态，然后返回原进程继续执行 实际上，V操作可以理解为归还资源的计数器，或是唤醒进程使其处于就绪状态的控制指令 锁 互斥锁：同一时间只能有一个线程访问加锁的数据。 自旋锁：互斥锁的一种实现，如果自旋锁已经被别的执行单元保持，调用者就一直 循环等待 是否该自旋锁的保持者已经释放了锁。 读写锁：一种特殊的自旋锁，它把对共享资源的访问者划分成读者和写者，读者只对共享资源进行读访问，写者则需要对共享资源进行写操作。写者是排他性的，一个读写锁同时只能有一个写者或多个读者（与CPU数相关），但不能同时既有读者又有写者。 阻塞锁：与自旋锁不同，改变了线程的运行状态。让线程进入阻塞状态进行等待，当获得相应的信号（唤醒，时间） 时，才可以进入线程的准备就绪状态，准备就绪状态的所有线程，通过竞争，进入运行状态。 在Java中synchronized,ReentrantLock,Object.wait() / notify()都属于阻塞锁。 可重入锁：也叫做递归锁，指的是同一线程上该锁是可重入的，对于不同线程则相当于普通的互斥锁。 公平锁：加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得。 非公平锁：加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待。ReentrantLock中的lock()默认就是非公平锁。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。加锁的时间可能会很长，也就是说悲观锁的并发访问性不好。 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。乐观锁不能解决脏读的问题，可以通过添加时间戳和版本来来解决。 CAS 比较并交换(compare and swap, CAS)，是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作。该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值。 在使用上，通常会记录下某块内存中的旧值，通过对旧值进行一系列的操作后得到新值，然后通过CAS操作将新值与旧值进行交换。如果这块内存的值在这期间内没被修改过，则旧值会与内存中的数据相同，这时CAS操作将会成功执行使内存中的数据变为新值。如果内存中的值在这期间内被修改过，则一般来说旧值会与内存中的数据不同，这时CAS操作将会失败，新值将不会被写入内存。 死锁 死锁是指多个进程因循环等待资源而造成无法执行的现象。死锁会造成进程无法执行，同时会造成系统资源的极大浪费(资源无法释放)。 死锁产生的四个必要条件 互斥使用：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。 不可抢占：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。 请求和保持：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。 循环等待：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。 死锁避免 银行家算法：判断此次请求是否造成死锁若会造成死锁，则拒绝该请求。 进程间通信 本地进程间通信的方式有很多，可以总结为下面四类： 消息传递（管道、FIFO、消息队列） 同步（互斥量、条件变量、读写锁、文件和写记录锁、信号量） 共享内存（匿名的和具名的） 远程过程调用（Solaris门和Sun RPC） 线程 线程是 操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。在Unix System V及SunOS中也被称为轻量进程(lightweight processes)，但轻量进程更多指内核线程(kernel thread)，而把用户线程(user thread)称为线程。 线程是独立调度和分派的基本单位。线程可以操作系统内核调度的内核线程，如Win32线程；由用户进程自行调度的用户线程，如Linux平台的POSIX Thread；或者由内核与用户进程，如Windows 7的线程，进行混合调度。 同一进程中的多条线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等。但同一进程中的多个线程有各自的调用栈，自己的寄存器环境，自己的线程本地存储。 线程的属性： 轻型实体：线程中的实体基本上不拥有系统资源，只是有一点必不可少的、能保证独立运行的资源。线程的实体包括程序、数据和TCB。线程是动态概念，它的动态特性由线程控制块TCB（Thread Control Block）描述。TCB包括以下信息： 线程状态。 当线程不运行时，被保存的现场资源。 一组执行堆栈。 存放每个线程的局部变量主存区。 访问同一个进程中的主存和其它资源。 用于指示被执行指令序列的程序计数器、保留局部变量、少数状态参数和返回地址等的一组寄存器和堆栈。 独立调度和分派的基本单位：在多线程OS中，线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位。由于线程很“轻”，故线程的切换非常迅速且开销小（在同一进程中的）。 可并发执行：在一个进程中的多个线程之间，可以并发执行，甚至允许在一个进程中所有线程都能并发执行；同样，不同进程中的线程也能并发执行，充分利用和发挥了处理机与外围设备并行工作的能力。 共享进程资源：在同一进程中的各个线程，都可以共享该进程所拥有的资源，这首先表现在：所有线程都具有相同的地址空间（进程的地址空间），这意味着，线程可以访问该地址空间的每一个虚地址；此外，还可以访问进程所拥有的已打开文件、定时器、信号量机构等。由于同一个进程内的线程共享内存和文件，所以线程之间互相通信不必调用内核。 线程共享的环境包括：进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。 线程是程序执行的一条路径，在多线程的OS中，线程是调度和分配的基本单位，而进程是拥有资源的基本单位。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/2-op/4-memory.html":{"url":"basic/2-op/4-memory.html","title":"内存管理","keywords":"","body":"内存管理 存储器工作原理 应用程序如何在计算机系统上运行的呢？首先，用编程语言编写和编辑应用程序，所编写的程序称为源程序，源程序不能再计算机上直接被运行，需要通过三个阶段的处理：编译程序处理源程序并生成目标代码，链接程序把他们链接为一个可重定位代码，此时该程序处于逻辑地址空间中；下一步装载程序将可执行代码装入物理地址空间，直到此时程序才能运行。 程序编译 源程序经过编译程序的处理生成目标模块（目标代码）。一个程序可由独立编写且具有不同功能的多个源程序模块组成，由于模块包含外部引用（即指向其他模块中的数据或指令地址，或包含对库函数的引用），编译程序负责记录引用发生的位置，其处理结果将产生相应的多个目标模块，每个模块都附有供引用使用的内部符号表和外部符号表。符号表中依次给出各个符号名及在本目标模块中的名字地址，在模块链接时进行转换。 程序链接 链接程序(Linker)的作用是根据目标模块之间的调用和依赖关系，将主调模块、被调模块以及所用到的库函数装配和链接成一个完整的可装载执行模块。根据程序链接发生的时间和链接方式，程序链接可分为以下三种方式： 静态链接：在程序装载到内存和运行前，就已将它所有的目标模块及所需要的库函数进行链接和装配成一个完整的可执行程序且此后不再拆分。 动态链接：在程序装入内存前并未事先进行程序各目标模块的链接，而是在程序装载时一边装载一边链接，生成一个可执行程序。在装载目标模块时，若发生外部模块调用，将引发响应外部目标模块的搜索、装载和链接。 运行时链接：在程序执行过程中，若发现被调用模块或库函数尚未链接，先在内存中进行搜索以查看是否装入内存；若已装入，则直接将其链接到调用程序中，否则进行该模块在外存上的搜索，以及装入内存和进行链接，生成一个可执行程序。 运行时链接将链接推迟到程序执行时，可以很好的提高系统资源的利用率和系统效率。 程序装载 程序装载就是将可执行程序装入内存，这里有三种方式： 绝对装载：装载模块中的指令地址始终与其内存中的地址相同，即模块中出现的所有地址均为绝对地址。 可重定位装载：根据内存当时的使用情况，决定将装载代码模块放入内存的物理位置。模块内使用的都是相对地址。 动态运行时装载：为提高内存利用率，装入内存的程序可换出到磁盘上，适当时候再换入内存中，对换前后程序在内存中的位置可能不同，即允许进程的内存映像在不同时候处于不同位置，此时模块内使用的地址必定为相对地址。 磁盘中的装载模块所使用的是逻辑地址，其逻辑地址集合称为进程的逻辑地址空间。进程运行时，其装载代码模块将被装入物理地址空间中，此时程序和数据的实际地址不可能同原来的逻辑一致。可执行程序逻辑地址转换为物理地址的过程被称为 “地址重定位”。 静态地址重定位：由装载程序实现装载代码模块的加载和物理地址转换，把它装入分配给进程的内存指定区域，其中所有逻辑地址修改为物理地址。地址转换在进程执行前一次完成，易于实现，但不允许程序在执行过程中移动位置。 动态地址重定位：由装载程序实现装载代码模块的加载，把它装入分配给进程的内存指定区域，但对链接程序处理过的程序的逻辑地址不做任何改变，程序内存起始地址被置入硬件专用寄存器 —— 重定位寄存器。程序执行过程中，每当CPU引用内存地址时，有硬件截取此逻辑地址，并在它被发送到内存之前加上重定位寄存器的值，以实现地址转换。 运行时链接地址重定位：对于静态和动态地址重定位装载方式而言，装载代码模块是由整个程序的所有目标模块及库函数经链接和整合构成的可执行程序，即在程序启动执行前已经完成了程序的链接过程。可见，装载代码的正文结构是静态的，在程序运行期间保持不变。运行时链接装载方式必然采用运行时链接地址重定位。 重定位寄存器：用于保存程序内存起始地址。 连续存储管理 固定分区存储管理 固定分区存储管理又称为静态分区模式，基本思想是：内存空间被划分成数目固定不变的分区，各分区大小不等，每个分区装入一个作业，若多个分区中都有作业，则他们可以并发执行。 为说明各分区分配和使用情况，需要设置一张内存分配表，记录内存中划分的分区及其使用情况。内存分配表中指出各分区起始地址和长度，占用标志用来指示此分区是否被使用。 可变分区存储管理 可变分区存储管理按照作业大小来划分分区，但划分的时间、大小、位置都是动态的。系统把作业装入内存时，根据其所需要的内存容量查看是否有足够空间，若有则按需分割一个分区分配给此作业；若无则令此作业等待内存资源。 在可变分区模式下，内存中分区数目和大小随作业的执行而不断改变，为了方便内存空间的分配和去配，用于管理的数据结构可由两张表组成：已分配区表和未分配区表。当装入新作业时，从未分配区表中找出一个足够容纳它的空闲区，将此区分为两个部分，一部分用来装入作业，成为已分配区；另一部分仍是空闲区（若有）。这时，应从已分配区表中找出一个空栏目登记新作业的起始地址、占用长度，同时修改未分配区表中空闲区的长度和起始地址。当作业撤离时，已分配区表中的相应状态改为空闲，而将收回的分区登记到为分配区中，若有相邻空闲区再将其连接后登记。 常用的可变分区分配算法 最先适应分配算法：该算法顺序查找未分配区表，直到找到第一个能满足长度要求的空闲区为止，分割此分区，一部分分配给作业，另一部分仍为空闲区。 下次适应分配算法：该算法总是从未分配区的上次扫描结束处顺序查找未分配区表，直到找到第一个能满足长度要求的空闲区为止。 最优适应分配算法：该算法扫描整个未分配区表，从空闲区中挑选一个能满足用户进程要求的最小分区进行分配。 最坏适应分配算法：该算法扫描整个未分配区表，总是挑选一个最大的空闲区分割给作业使用，其优点是使剩下的空闲区不至于过小。 快速适应分配算法：该算法为那些经常用到的长度的空闲区设立单独的空闲区链表。 分页存储管理 逻辑空间等分为页；并从0开始编号 内存空间等分为块，与页面大小相同；从0开始编号 分配内存时，以块为单位将进程中的若干个页分别装入到多个可以不相邻接的物理块中。 分段存储管理 逻辑空间分为若干个段，每个段定义了一组有完整逻辑意义的信息（如主程序Main()）。 内存空间为每个段分配一个连续的分区。 分页和分段的主要区别： 分页：信息的物理单位。大小一样，由系统决定。地址空间是一维的。 分段：信息的逻辑单位。大小不一样，由程序员决定。地址空间是二维的。 段页式存储管理 用户程序先分段，每个段内部再分页（内部原理同基本的分页、分段相同） 内存分配 虚拟地址：用户编程时将代码（或数据）分成若干个段，每条代码或每个数据的地址由段名称 + 段内相对地址构成，这样的程序地址称为虚拟地址 逻辑地址：虚拟地址中，段内相对地址部分称为逻辑地址 物理地址：实际物理内存中所看到的存储地址称为物理地址 逻辑地址空间：在实际应用中，将虚拟地址和逻辑地址经常不加区分，通称为逻辑地址。逻辑地址的集合称为逻辑地址空间 线性地址空间：CPU地址总线可以访问的所有地址集合称为线性地址空间 物理地址空间：实际存在的可访问的物理内存地址集合称为物理地址空间 MMU(Memery Management Unit内存管理单元)：实现将用户程序的虚拟地址（逻辑地址） -> 物理地址映射的CPU中的硬件电路 基地址：在进行地址映射时，经常以段或页为单位并以其最小地址（即起始地址）为基值来进行计算 偏移量：在以段或页为单位进行地址映射时，相对于基地址的地址值 虚拟地址先经过分段机制映射到线性地址，然后线性地址通过分页机制映射到物理地址。 虚拟内存--请求分页虚拟存储管理 请求调页，也称按需调页，即对不在内存中的“页”，当进程执行时要用时才调入，否则有可能到程序结束时也不会调入。 页面置换算法 FIFO算法：先入先出，即淘汰最早调入的页面。 OPT(MIN)算法：选未来最远将使用的页淘汰，是一种最优的方案，可以证明缺页数最小。可惜，MIN需要知道将来发生的事，只能在理论中存在，实际不可应用。 LRU(Least-Recently-Used)算法：用过去的历史预测将来，选最近最长时间没有使用的页淘汰(也称最近最少使用)。性能最接近OPT。与页面使用时间有关。 LFU(Least Frequently Used)算法：即最不经常使用页置换算法，要求在页置换时置换引用计数最小的页，因为经常使用的页应该有一个较大的引用次数。与页面使用次数有关。 Clock：给每个页帧关联一个使用位，当该页第一次装入内存或者被重新访问到时，将使用位置为1。每次需要替换时，查找使用位被置为0的第一个帧进行替换。在扫描过程中，如果碰到使用位为1的帧，将使用位置为0，在继续扫描。如果所谓帧的使用位都为0，则替换第一个帧。 内存抖动现象：页面的频繁更换，导致整个系统效率急剧下降，这个现象称为内存抖动（或颠簸）。抖动一般是内存分配算法不好，内存太小引或者程序的算法不佳引起的。 交换区：用于保存请求分页淘汰出来的页面。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/2-op/5-disk.html":{"url":"basic/2-op/5-disk.html","title":"磁盘与文件","keywords":"","body":"磁盘与文件 磁盘调度 磁盘访问延迟 = 队列时间 + 控制器时间 + 寻道时间 + 旋转时间 + 传输时间 磁盘调度的目的是减小延迟，其中前两项可以忽略，寻道时间是主要矛盾。 磁盘调度算法 FCFS：先进先出的调度策略，这个策略具有公平的优点，因为每个请求都会得到处理，并且是按照接收到的顺序进行处理。 SSTF(Shortest-seek-time First 最短寻道时间优先)：选择使磁头从当前位置开始移动最少的磁盘I/O请求，所以 SSTF 总是选择导致最小寻道时间的请求。总是选择最小寻找时间并不能保证平均寻找时间最小，但是能提供比 FCFS 算法更好的性能，会存在饥饿现象（会导致较远的I/O请求不能满足）。 SCAN：SSTF+中途不回折，每个请求都有处理机会。SCAN 要求磁头仅仅沿一个方向移动，并在途中满足所有未完成的请求，直到它到达这个方向上的最后一个磁道，或者在这个方向上没有其他请求为止。由于磁头移动规律与电梯运行相似，SCAN 也被称为电梯算法。 SCAN 算法对最近扫描过的区域不公平，因此，它在访问局部性方面不如 FCFS 算法和 SSTF 算法好。 C-SCAN：SCAN+直接移到另一端，两端请求都能很快处理。把扫描限定在一个方向，当访问到某个方向的最后一个磁道时，磁道返回磁盘相反方向磁道的末端，并再次开始扫描。其中“C”是Circular（环）的意思。 LOOK(C-LOOK)：釆用SCAN算法和C-SCAN算法时磁头总是严格地遵循从盘面的一端到另一端，显然，在实际使用时还可以改进，即磁头移动只需要到达最远端的一个请求即可返回，不需要到达磁盘端点。这种形式的SCAN算法和C-SCAN算法称为LOOK和C-LOOK调度。这是因为它们在朝一个给定方向移动前会查看是否有请求。 文件系统 分区表 MBR：支持最大卷为2 TB（Terabytes）并且每个磁盘最多有4个主分区（或3个主分区，1个扩展分区和无限制的逻辑驱动器） GPT：支持最大卷为18EB（Exabytes）并且每磁盘的分区数没有上限，只受到操作系统限制（由于分区表本身需要占用一定空间，最初规划硬盘分区时，留给分区表的空间决定了最多可以有多少个分区，IA-64版Windows限制最多有128个分区，这也是EFI标准规定的分区表的最小尺寸。另外，GPT分区磁盘有备份分区表来提高分区数据结构的完整性。 RAID 技术 磁盘阵列（Redundant Arrays of Independent Disks，RAID），独立冗余磁盘阵列之。原理是利用数组方式来作磁盘组，配合数据分散排列的设计，提升数据的安全性。 常见文件系统 Windows: FAT, FAT16, FAT32, NTFS Linux: ext2/3/4, btrfs, ZFS Mac OS X: HFS+ Linux文件权限 Linux文件采用10个标志位来表示文件权限，如下所示： -rw-r--r-- 1 skyline staff 20B 1 27 10:34 1.txt drwxr-xr-x 5 skyline staff 170B 12 23 19:01 ABTableViewCell 第一个字符一般用来区分文件和目录，其中： d：表示是一个目录，事实上在ext2fs中，目录是一个特殊的文件。 －：表示这是一个普通的文件。 l: 表示这是一个符号链接文件，实际上它指向另一个文件。 b、c：分别表示区块设备和其他的外围设备，是特殊类型的文件。 s、p：这些文件关系到系统的数据结构和管道，通常很少见到。 第2～10个字符当中的每3个为一组，左边三个字符表示所有者权限，中间3个字符表示与所有者同一组的用户的权限，右边3个字符是其他用户的权限。 这三个一组共9个字符，代表的意义如下： r(Read，读取)：对文件而言，具有读取文件内容的权限；对目录来说，具有浏览目录的权限 w(Write,写入)：对文件而言，具有新增、修改文件内容的权限；对目录来说，具有删除、移动目录内文件的权限。 x(eXecute，执行)：对文件而言，具有执行文件的权限；对目录来说该用户具有进入目录的权限。 权限的掩码可以使用十进制数字表示： 如果可读，权限是二进制的100，十进制是4； 如果可写，权限是二进制的010，十进制是2； 如果可运行，权限是二进制的001，十进制是1； chmod命令 chmod命令非常重要，用于改变文件或目录的访问权限。用户用它控制文件或目录的访问权限。 该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。 文字设定法 chmod ［who］ ［+ | - | =］ ［mode］ 文件名 命令中各选项的含义为： 操作对象who可是下述字母中的任一个或者它们的组合： u 表示“用户（user）”，即文件或目录的所有者。 g 表示“同组（group）用户”，即与文件属主有相同组ID的所有用户。 o 表示“其他（others）用户”。 a 表示“所有（all）用户”。它是系统默认值。 操作符号可以是： 添加某个权限。 取消某个权限。 = 赋予给定权限并取消其他所有权限（如果有的话）。 设置mode所表示的权限可用下述字母的任意组合： r 可读。 w 可写。 x 可执行。 X 只有目标文件对某些用户是可执行的或该目标文件是目录时才追加x 属性。 s 在文件执行时把进程的属主或组ID置为该文件的文件属主。方式“u＋s”设置文件的用户ID位，“g＋s”设置组ID位。 t 保存程序的文本到交换设备上。 u 与文件属主拥有一样的权限。 g 与和文件属主同组的用户拥有一样的权限。 o 与其他用户拥有一样的权限。 文件名：以空格分开的要改变权限的文件列表，支持通配符。 在一个命令行中可给出多个权限方式，其间用逗号隔开。例如：chmod g+r，o+r example 使同组和其他用户对文件example 有读权限。 数字设定法 直接使用数字表示的权限来更改： 例： $ chmod 644 mm.txt chgrp命令 功能：改变文件或目录所属的组。 语法：chgrp ［选项］ group filename 例：$ chgrp - R book /opt/local /book 改变/opt/local /book/及其子目录下的所有文件的属组为book。 chown命令 功能：更改某个文件或目录的属主和属组。这个命令也很常用。例如root用户把自己的一个文件拷贝给用户xu，为了让用户xu能够存取这个文件，root用户应该把这个文件的属主设为xu，否则，用户xu无法存取这个文件。 语法：chown ［选项］ 用户或组 文件 说明：chown将指定文件的拥有者改为指定的用户或组。用户可以是用户名或用户ID。组可以是组名或组ID。文件是以空格分开的要改变权限的文件列表，支持通配符。 例：把文件shiyan.c的所有者改为wang。 chown wang shiyan.c 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/2-op/6-linux.html":{"url":"basic/2-op/6-linux.html","title":"Linux系统","keywords":"","body":"Linux系统 sed sed是非交互式的编辑器。它不会修改文件，除非使用shell重定向来保存结果。默认情况下，所有的输出行都被打印到屏幕上。sed编辑器逐行处理文件（或输入），并将结果发送到屏幕。 sed命令行格式为： sed [-nefri] ‘command’ 输入文本 常用选项： -n∶使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN的资料一般都会被列出到萤幕上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。 -e∶直接在指令列模式上进行 sed 的动作编辑； -f∶直接将 sed 的动作写在一个档案内， -f filename 则可以执行 filename 内的sed 动作； -r∶sed 的动作支援的是延伸型正规表示法的语法。(预设是基础正规表示法语法) -i∶直接修改读取的档案内容，而不是由萤幕输出。 常用命令： a ∶新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ c ∶取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ d ∶删除，因为是删除啊，所以 d 后面通常不接任何咚咚； i ∶插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； p ∶列印，亦即将某个选择的资料印出。通常 p 会与参数 sed -n 一起运作～ s ∶取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g！ g 是行内进行全局替换 　umask 当我们登录系统之后创建一个文件总是有一个默认权限的，那么这个权限是怎么来的呢？这就是umask干的事情。umask设置了用户创建文件的默认权限，它与chmod的效果刚好相反，umask设置的是权限“补码”，而chmod设置的是文件权限码。 计算方法如下： 例如，对于umask值0 0 2，相应的文件和目录缺省创建权限是什么呢？ // 664 775 第一步，我们首先写下目录具有全部权限的模式，即777 (所有用户都具有读、写和执行权限)，文件默认是666。 第二步，在下面一行按照umask值写下相应的位，在本例中是0 0 2。 第三步，在接下来的一行中记下上面两行中没有匹配的位。这就是目录的缺省创建权限。 稍加练习就能够记住这种方法。 第四步，对于文件来说，在创建时不能具有执行权限，只要拿掉相应的执行权限比特即可。 useradd 格式：useradd [选项] 用户名 -p 设定帐号的密码 -d 指定用户的主目录 -m 自动建立用户的主目录 -M 不要自动建立用户的主目录 mount && umount mount [选项] [-o 挂载选项] umount find find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec] [path...] [expression] grep 在文件中搜索指定字符所在行格式： grep [选项] 指定字符 文件-i 忽略大小写 -r 递归 -v 排除指定字符串 -n 显示列数 eg: grep -i ab /etc/inittab tar 常用的打包压缩和解压命令之一格式: tar 选项 [压缩后文件名] [目录] 注意：打包和压缩是两个不同概念，打包只是把所有文件放在一具类似包中，并不改变其大小，而压缩才会改变其大小 压缩时常用 -c 打包(create) -v显示详细信息(view) -f指定文件名(filename) -z 打包同时压缩 eg: tar -zvf word.tar word 解压缩时常用 -x 解包 -v显示详细信息(view) -f指定解压文件名(filename) -z 解压缩 eg: tar -zxf word.tar 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/2-op/7-interrupt.html":{"url":"basic/2-op/7-interrupt.html","title":"中断","keywords":"","body":"中断 中断（英语：Interrupt）是指 处理器接收到来自硬件或软件的信号，提示发生了某个事件，应该被注意，这种情况就称为中断。 通常，在接收到来自外围硬件（相对于中央处理器和内存）的异步信号，或来自软件的同步信号之后，处理器将会进行相应的 硬件／软件 处理。发出这样的信号称为进行中断请求（interrupt request，IRQ）。硬件中断导致处理器通过一个运行信息切换（context switch）来保存执行状态（以程序计数器和程序状态字等寄存器信息为主）；软件中断则通常作为CPU指令集中的一个指令，以可编程的方式直接指示这种运行信息切换，并将处理导向一段中断处理代码。中断在计算机多任务处理，尤其是即时系统中尤为有用。 中断分类 硬件中断 由硬件发出或产生的中断称为硬中断，按硬中断事件的来源和实现手段可将中断划分为外中断和内中断： 外中断：又称为中断或异步中断，是指 来自处理器以外的中断信号，包括时钟中断、键盘中断、外部设备中断等。外中断又分为可屏蔽中断和不可屏蔽中断，各个中断具有不同的优先级，表示事件的紧急程度，在处理高一级中断时，往往会部分或全部屏蔽低等级中断。 内中断：又称为异常或同步中断（产生时必须考虑与处理器时钟同步），是指 来自处理器内部的中断信号，通常是由于程序执行过程中，发现与当前指令关联的、不正常的或错误的事件。内中断可以细分为： 访管中断，由执行系统调用而引起的。 硬件故障中断，如电源失效、总线超时等。 程序性中断，如非法操作、地址越界、除数为0和浮点溢出等。 软件中断 软件中断：是一条CPU指令，用以自陷一个中断。由于 软中断指令通常要运行一个切换CPU至内核态（Kernel Mode/Ring 0）的子例程，它常被用作实现系统调用（System call）。 处理器通常含有一个内部中断屏蔽位，并允许通过软件来设定。一旦被设定，所有外部中断都将被系统忽略。这个屏蔽位的访问速度显然快于中断控制器上的中断屏蔽寄存器，因此可提供更快速地中断屏蔽控制。 中断尽管可以提高计算机处理性能，但 过于密集的中断请求／响应反而会影响系统性能。这类情形被称作中断风暴（interrupt storm）。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/2-op/8-device.html":{"url":"basic/2-op/8-device.html","title":"设备管理","keywords":"","body":"设备管理 外部设备分为两大类： 存储型设备：以存储大量信息和快速检索为目标，在系统中存储持久性信息。 I/O型设备：如显示器、打印机等。 I/O硬件原理 I/O系统 通常把I/O设备及其接口线路、控制部件、通道和管理软件称为I/O系统，把计算机的内存和设备介质之间的信息传送操作称为I/O操作。可按照不同方式对设备进行分类：按I/O操作特性分为输入型设备、输出型设备和存储型设备；按I/O信息交换单位分为字符设备和块设备。 输入、输出型设备通常是字符设备，存储型设备通常是块设备。 存储型设备又分为顺序存储设备和直接存取设备。前者严格依赖信息的物理位置进行读写和定位，如磁带。后者的特点是存取任何一个物理块所需要的时间几乎不依赖于此信息所处的位置，如磁盘。 I/O控制方式 轮询方式 轮询方式又称程序直接控制方式，使用查询指令测试设备控制器的忙闲状态位，确定内存和设备是否能交换数据。轮询方式采用三条指令：查询指令，查询设备是否就绪；读写指令，当设备就绪时执行数据交换；转移指令，当设备未就绪时执行转移指令指向查询指令继续查询。可见，在这种方式下CPU和设备只能串行工作。 中断方式 在这种方式下CPU和设备之间传输数据的过程如下： 进程发出启动I/O指令，CPU加载控制信息到设备控制器的寄存器，然后进程继续执行不涉及本次I/O数据的任务，或放弃CPU等待设备I/O操作完成。 设备控制器检查寄存器的内容，按照I/O指令的要求执行相应I/O操作，一旦传输完成，设备控制器发出I/O中断请求信号。 CPU收到并响应I/O中断后，转向设备的I/O中断处理程序执行。 中断处理程序执行数据读取操作，将I/O缓冲寄存器的内容写入内存，操作结束后退出中断处理程序，返回发生中断前的状态。 进程调度程序在适当的时候让得到数据的进程恢复执行。 在I/O中断方式中，如果设备控制器的数据缓冲区较小，当缓冲器装满后便会发生中断，那么在数据传输过程中发生中断次数会很多，这样就消耗了大量CPU时间。 DMA方式 虽然中断方式提高了CPU利用率，但是在响应中断请求后必须停止现行程序，转入中断处理程序并参与数据传输操作。在DMA(Direct Memory Access)方式中，内存和设备之间有一条数据通路成块地传送数据，无须CPU干预，实际数据传输操作由DMA直接完成。为实现DMA，至少需要以下逻辑部件： 内存地址寄存器：存放内存中需要交换数据的地址，DMA传送之前由程序送入首地址；DMA传送过程中，每次交换数据都把地址寄存器的内容加1。 字计数器：记录传送数据的总字数，每次传送一个字就把字计数器减1。 数据缓冲寄存器或数据缓冲区：暂存每次传送的数据。 设备地址寄存器：存放I/O信息的地址，如磁盘的柱面号。 中断机制和控制逻辑：用于向CPU提出I/O中断请求及CPU发来的I/O命令，管理DMA的传送过程。 通道方式 通道又称I/O处理器，能完成内存和设备之间的信息传送，与CPU并行地执行操作。采用I/O通道设计后，I/O操作过程如下：CPU在执行主程序时遇到I/O请求，启动在指定通道上选址的设备，一旦启动成功，通道开始控制设备进行操作，这时CPU就可以执行其他任务并与通道并行工作，直到I/O操作完成；当通道发出I/O操作结束中断时，处理器才响应并停止当前工作，转向I/O操作结束事件。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/2-op/9-io.html":{"url":"basic/2-op/9-io.html","title":"I/O","keywords":"","body":"I/O 基本概念 文件描述符fd 文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于 UNIX、Linux 这样的操作系统。 缓存 I/O 缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 IO模式 刚才说了，对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段： 等待数据准备 将数据从内核拷贝到进程中 正式因为这两个阶段，Linux系统产生了下面五种网络模式的方案。 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO） 由于signal driven IO在实际中并不常用，所以这里只提及剩下的四种 IO Model。 阻塞IO 在 Linux 中，默认情况下所有的 socket 都是 blocking ，一个典型的读操作流程大概是这样： 当用户进程调用了 recvfrom 这个系统调用， kernel 就开始了 IO 的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的 UDP 包。这个时候 kernel 就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当 kernel 一直等到数据准备好了，它就会将数据从 kernel 中拷贝到用户内存，然后 kernel 返回结果，用户进程才解除 block 的状态，重新运行起来。 blocking IO的特点就是在IO执行的两个阶段都被block了 非阻塞 I/O Linux 下，可以通过设置 socket 使其变为 non-blocking 。当对一个 non-blocking socket 执行读操作时，流程是这个样子： 当用户进程发出 read 操作时，如果 kernel 中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 error 。从用户进程角度讲 ，它发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。一旦 kernel 中的数据准备好了，并且又再次收到了用户进程的 system call ，那么它马上就将数据拷贝到了用户内存，然后返回。 nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有 IO多路复用 IO多路复用就是我们说的 select，poll，epoll ，有些地方也称这种IO方式为 event driven IO 。select/epoll 的好处就在于单个 process 就可以同时处理多个网络连接的 IO 。它的基本原理就是 select，poll，epoll 这个 function 会不断的轮询所负责的所有 socket ，当某个 socket 有数据到达了，就通知用户进程。 当用户进程调用了 select，那么整个进程会被 block，而同时， kernel 会监视所有 select 负责的 socket ，当任何一个 socket 中的数据准备好了， select 就会返回。这个时候用户进程再调用 read 操作，将数据从 kernel 拷贝到用户进程。 I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select() 函数就可以返回。 这个图和 blocking IO 的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个 system call (select 和 recvfrom)，而 blocking IO 只调用了一个 system call (recvfrom)。但是，用 select 的优势在于它可以同时处理多个 connection 。 所以，如果处理的连接数不是很高的话，使用 select/epoll 的 web server 不一定比使用 multi-threading + blocking IO 的 web server 性能更好，可能延迟还更大。select/epoll 的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。 在IO多路复用实际使用中，对于每一个socket，一般都设置成为 non-blocking ，但是，如上图所示，整个用户的 process 其实是一直被block的。只不过 process 是被 select 这个函数 block ，而不是被 socket IO 给 block 。 基本概念 在 I/O 编程过程中,当需要同时处理多个客户端接入请求时，可以利用多线程或者 I/O 多路复用 技术进行处理。I/O多路复用 技术通过把多个I/O的阻塞复用到同一个selct的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。与传统的 多线程/多进程 模型比，I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源，I/O多路复用的主要应用场景如下。 服务器需要同时处理多个处于监听状态或者多个连接状态的套接字 服务器需要同时处理多种网络协议的套接字 目前支持I/O多路复用的系统调用有 select、pselect、poll、epoll，在Linux网络编程; 过程中，很长一段时间都使用 select 做轮询和网络事件通知，然而 select 的一些固有缺陷导致了它的应用受到了很大的限制。最终 Linux 不得不在新的内核版本中寻找 select 的替代方案，最终选择了 epoll。 epoll 与 select 的原理比较类似，为了克服 select 的缺点， epoll 作了很多重大改进，现总结如下。 支持一个进程打开的 socket 描述符（FD）不受限制（仅受限于操作系统的最大文件句柄数）。 select 最大的缺陷就是单个进程所打开的 FD 是有一定限制的，它由 FD_SETSIZE 设置，默认值是 1024 。对于那些需要支持上万个 TCP 连接的大型服务器来说显然太少了。可以选择修改这个宏然后重新编译内核，不过这会带来网络效率的下降。我们也可以通过选择多进程的方案（传统的 Apache 方案）解决这个问题，不过虽然在 Linux上创建进程的代价比较小，但仍旧是不可忽视的，另外，进程间的数据交换非常麻烦，对于 Java 由于没有共享内存，需要通过 Socket 通信或者其他方式进行数据同步，这带来了额外的性能损耗，增加了程序复杂度，所以也不是一种完美的解决方案。值得庆幸的是， epoll 并没有这个限制，它所支持的 FD 上限是操作系统的 最大文件句柄数，这个数字远远大于 1024 。例如，在 1 GB 内存的机器上大约是 10万个句柄左右，具体的值可以通过cat /proc/sys/fs/file- max 察看，通常情况下这个值跟系统的内存关系比较大。 I/O效率不会随着FD数目的增加而线性下降。 传统的 select/poll 另-个致命弱点就是当你拥有一个很大的 socket 集合，由于网络延时或者链路空闲，任一时刻只有少部分的 socket 是“活跃”的，但是 select/poll 每次调用都会线性扫描全部的集合，导致效率呈现线性下降。 epoll 不存在这个问题，它只会对“活跃”的 socket 进行操作，这是因为在内核实现中 epoll 是根据每个 fd 上面的 callback 函数实现的，那么，只有“活跃”的 socket 才会主动的去调用 callback 函数，其他 idle 状态 socket 则不会。在这点上， epoll 实现了一个伪 AIO。针对 epoll 和 select 性能对比的 benchmark 测试表明：如果所有的 socket 都处于活跃态，例如一个高速 LAN 环境， epoll 并不比 select/poll 效率高太多；相反，如果过多使用 epoll_ ctl , 效率相比还有稍微的下降。但是一旦使用 idleconnections 模拟 WAN 环境，epoll 的效率就远在 select/poll 之上了。 使用 mmap 加速内核与用户空间的消息传递。 无论是 select，poll 还是 epoll 都需要内核把 FD 消息通知给用户空间，如何避免不必要的内存复制就显得非常重要， epoll 是通过内核和用户空间 mmap 同一块内存实现。 Epoll 的 API 更加简单。 包括创建一个 epoll 描述符、添加监听事件、阻塞等待所监听的事件发生，关闭 epoll 描述符等。 值得说明的是，用来克服 select/poll 缺点的方法不只有 epoll , epoll 只是一种 Linux 的 实现方案。在 freeBSD 下有 kqueue Epoll 边缘触发&水平触发 epoll 对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是 默认模式 ，LT模式与ET模式的区别如下： LT模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用 epoll_wait 时，会再次响应应用程序并通知此事件。 ET模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用 epoll_wait 时，不会再次响应应用程序并通知此事件。 ET模式 在很大程度上减少了 epoll 事件被重复触发的次数，因此 效率要比LT模式高。epoll 工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 异步 I/O 用户进程发起 read 操作之后，立刻就可以开始去做其它的事。而另一方面，从 kernel 的角度，当它受到一个 asynchronous read 之后，首先它会立刻返回，所以不会对用户进程产生任何 block 。然后，kernel 会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel 会给用户进程发送一个 signal ，告诉它 read 操作完成了。 blocking vs non-blocking 调用 blocking IO 会一直 block 住对应的进程直到操作完成，而 non-blocking IO 在 kernel 还准备数据的情况下会立刻返回。 synchronous IO vs asynchronous IO 在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。 POSIX 的定义是这样子的： A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked; 两者的区别就在于 synchronous IO 做 IO operation 的时候会将 process 阻塞。按照这个定义，之前所述的 blocking IO，non-blocking IO，IO multiplexing 都属于 synchronous IO。 有人会说，non-blocking IO 并没有被 block 啊。这里有个非常 狡猾 的地方，定义中所指的 IO operation 是指真实的 IO 操作，就是例子中的 recvfrom 这个 system call 。non-blocking IO 在执行 recvfrom 这个 system call 的时候，如果 kernel 的数据没有准备好，这时候不会 block 进程。但是，当 kernel 中数据准备好的时候，recvfrom 会将数据从 kernel 拷贝到用户内存中，这个时候进程是被 block 了，在这段时间内，进程是被 block 的。 而 asynchronous IO 则不一样，当进程发起 IO 操作之后，就直接返回再也不理睬了，直到 kernel 发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被 block 。 参考 Linux IO模式及 select、poll、epoll详解 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/2-op/9-questions.html":{"url":"basic/2-op/9-questions.html","title":"面试题","keywords":"","body":"面试题 PE文件 PE文件的全称是Portable Executable，意为可移植的可执行的文件，常见的EXE、DLL、OCX、SYS、COM都是PE文件，PE文件是微软Windows操作系统上的程序文件（可能是间接被执行，如DLL）。 什么是活锁？与死锁有和区别？ 活锁指的是 任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。 活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。 活锁应该是一系列进程在轮询地等待某个不可能为真的条件为真。活锁的时候进程是不会blocked，这会导致耗尽CPU资源。 为解决活锁可以引入一些随机性，例如如果检测到冲突，那么就暂停随机的一定时间进行重试。这回大大减少碰撞的可能性。典型的例子是以太网的CSMA/CD检测机制。 直接寻址与间接寻址？ 寻址方式就是处理器根据指令中给出的地址信息来寻找物理地址的方式，是确定本条指令的数据地址以及下一条要执行的指令地址的方法。在操作系统中分为指令寻址和操作数寻址。 指令寻址：在内存中查找指令的方式。 顺序寻址方式：即采用PC计数器来计数指令的顺序； 跳跃寻址方式：下条指令的地址码不是由程序计数器给出，而是由本条指令给出。 操作数寻址：形成操作数的有效地址的方法称为操作数的寻址方式。 立即寻址：操作数作为指令的一部分而直接写在指令中； 直接寻址：直接寻址是一种基本的寻址方法。在指令格式的地址的字段中直接指出操作数在内存的地址。由于操作数的地址直接给出而不需要经过某种变换，所以称这种寻址方式为直接寻址方式。 简介寻址：间接寻址是相对直接寻址而言的，在间接寻址的情况下，指令地址字段中的形式地址不是操作数的真正地址，而是操作数地址的指示器，或者说此形式地址单元的内容才是操作数的有效地址。 如何从用户态切换到内核态？ 程序请求系统服务，执行系统调用 程序运行期间产生中断事件，运行程序被中断，转向中断处理程序处理 程序运行时产生异常事件，运行程序被打断，转向异常处理程序。 这三种情况都是通过中断机制发生，可以说 中断和异常是用户态到内核态转换的仅有途径。 实时操作系统和分时操作系统的区别？ 分时操作系统：多个联机用户同时适用一个计算机系统在各自终端上进行交互式会话，程序、数据和命令均在会话过程中提供，以问答方式控制程序运行。系统把处理器的时间划分为时间片轮流分配给各个连接终端。 实时操作系统：当外部时间或数据产生时，能够对其予以接受并以足够快的速度进行处理，所得结果能够在规定时间内控制生产过程或对控制对象作出快速响应，并控制所有实时任务协调的操作系统。因而，提供及时响应和高可靠性是其主要特点。实时操作系统有硬实时和软实时之分，硬实时要求在规定的时间内必须完成操作，这是在操作系统设计时保证的；软实时则只要按照任务的优先级，尽可能快地完成操作即可。我们通常使用的操作系统在经过一定改变之后就可以变成实时操作系统。 下面还要补充一个批处理操作系统：批处理是指用户将一批作业提交给操作系统后就不再干预，由操作系统控制它们自动运行。这种采用批量处理作业技术的操作系统称为批处理操作系统。批处理操作系统分为单道批处理系统和多道批处理系统。批处理操作系统不具有交互性，它是为了提高CPU的利用率而提出的一种操作系统。 如果某个操作系统兼有批处理、分时和实时处理的全部或两种功能，我们称为通用操作系统。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/3-net/":{"url":"basic/3-net/","title":"计算机网络","keywords":"","body":"计算机网络 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/3-net/1-osi.html":{"url":"basic/3-net/1-osi.html","title":"网络分层","keywords":"","body":"网络分层 OSI 层 功能 应用层 网络进程到应用程序。针对特定应用规定各层协议、时序、表示等，进行封装 。在端系统中用软件来实现，如HTTP等 表示层 数据表示形式，加密和解密，把机器相关的数据转换成独立于机器的数据。规定数据的格式化表示 ，数据格式的转换等 会话层 主机间通讯，管理应用程序之间的会话。规定通信时序 ；数据交换的定界、同步，创建检查点等 传输层 在网络的各个节点之间可靠地分发数据包。所有传输遗留问题；复用；流量；可靠 网络层 在网络的各个节点之间进行地址分配、路由和（不一定可靠的）分发报文。路由（ IP寻址）；拥塞控制。 数据链路层 一个可靠的点对点数据直链。检错与纠错（CRC码）；多路访问；寻址 物理层 一个（不一定可靠的）点对点数据直链。定义机械特性；电气特性；功能特性；规程特性 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/3-net/2-base_protocol.html":{"url":"basic/3-net/2-base_protocol.html","title":"底层网络协议","keywords":"","body":"底层网络协议 ARP（地址解析协议） 基本功能为透过目标设备的IP地址，查询目标设备的MAC地址，以保证通信的顺利进行。在每台安装有TCP/IP协议的电脑或路由器里都有一个ARP缓存表，表里的IP地址与MAC地址是一对应的。 当发送数据时，主机A会在自己的ARP缓存表中寻找是否有目标IP地址。如果找到就知道目标MAC地址为（00-BB-00-62-C2-02），直接把目标MAC地址写入帧里面发送就可；如果在ARP缓存表中没有找到相对应的IP地址，主机A就会在网络上发送一个 广播（ARP request），目标MAC地址是“FF.FF.FF.FF.FF.FF”，这表示向同一网段内的所有主机发出这样的询问：“192.168.38.11的MAC地址是什么？”网络上其他主机并不响应ARP询问，只有主机B接收到这个帧时，才向主机A做出这样的回应（ARP response）：“192.168.38.11的MAC地址是（00-BB-00-62-C2-02）”。这样，主机A就知道主机B的MAC地址，它就可以向主机B发送信息。同时它还更新自己的ARP缓存表，下次再向主机B发送信息时，直接从ARP缓存表里查找就可。ARP缓存表采用老化机制，在一段时间内如果表中的某一行没有使用，就会被删除，这样可以大大减少ARP缓存表的长度，加快查询速度。 当发送主机和目的主机不在同一个局域网中时，即便知道目的主机的MAC地址，两者也不能直接通信，必须经过路由转发才可以。所以此时，发送主机通过ARP协议获得的将不是目的主机的真实MAC地址，而是一台可以通往局域网外的路由器的MAC地址。于是此后发送主机发往目的主机的所有帧，都将发往该路由器，通过它向外发送。这种情况称为ARP代理（ARP Proxy）。 ICMP（互联网控制消息协议） 它 用于TCP/IP网络中发送控制消息，提供可能发生在通信环境中的各种问题反馈，通过这些信息，令管理者可以对所发生的问题作出诊断，然后采取适当的措施解决。它与传输协议最大的不同：它一般不用于在两点间传输数据，而常常 用于返回的错误信息或是分析路由。 ICMP控制的内容包括但不仅限于：echo响应（ping）、目标网络不可达、目标端口不可达、禁止访问的网络、拥塞控制、重定向、TTL超时... 路由选择协议 路由选择协议分为：静态的和动态的。Internet中使用的是动态路由选择协议，在Internet的概念中，将整个互联网划分为许多个小的自治系统（AS）。AS的最主要的特征：一个AS对其他AS表现出的是一个单一 和一致的路由选择策略。 由于AS的存在，路由选择协议又分为两种： 内部网关协议（IGP）：即在一个AS内部使用的路由选择协议，而这与互联网中其他AS选用什么路由协议无关。比如：OSPF 外部网关协议（EGP）：若源主机和目的主机不再同一个AS中，就需要使用一种协议将路由选择信息传递到另一个AS中，这就是EGP。比如：BGP。 OSPF（开放式最短路径优先） OSPF属于内部网关协议（IGP）的一种，使用Dijkstra提出的最短路径算法。 OSPF提出了“区域（Area）”的概念，一个网络可以由单一区域或者多个区域组成。其中，一个特别的区域被称为骨干区域（Backbone Area），该区域是整个OSPF网络的核心区域，并且所有其他的区域都与之直接连接。所有的内部路由都通过骨干区域传递到其他非骨干区域。所有的区域都必须直接连接到骨干区域，如果不能创建直接连接，那么可以通过虚拟链路（Virtual-link）和骨干区域创建虚拟连接。 划分区域的优点： 将洪泛法的范围限制在一个区域中。 减少每个区域内部路由信息交换的通信量。 OSPF使用的是分布式链路状态协议，使用 洪泛法向该路由器所有的相邻路由器发送信息。最终整个区域的所有路由器都得到一个这个信息的副本。这个副本就是 链路状态数据库（LSDB）用来保存当前网络拓扑结构，路由器上属于同一区域的链路状态数据库是相同的（属于多个区域的路由器会为每个区域维护一份链路状态数据库）。 OSPF使用 “代价（Cost）”作为路由度量。 只有当链路发生变化时才会更新信息。 如果同一个目的网络有多条路径，OSPF协议可以进行 负载均衡。 BGP（边界网关协议） 由于BGP是工作在AS之间的协议，并且各个AS的情况复杂，所以 BGP只是力求找到一个可以到达目的网络且比较好的路由，而并不是寻找一条最佳路由。每一个AS都应该有一个“BGP发言人“，一般来说，两个BGP发言人是通过一个共享网络连接在一起的，BGP发言人往往是BGP边界路由，但也可以不是。 一个BGP发言人与其他AS的BGP发言人要交换路由信息，首先要建立TCP连接，然后在此连接上交换BGP报文以建立BGP会话。当BGP发言人交换了路由信息后，就构造自治系统连通图，最后通过该图来进行路由选择。 DHCP（动态主机设置协议） DHCP是一个局域网的网络协议，使用UDP协议工作，主要有两个用途： 用于内部网络或网络服务供应商自动分配IP地址给用户 用于内部网络管理员作为对所有电脑作中央管理的手段 动态主机设置协议（DHCP）是一种使网络管理员能够集中管理和自动分配IP网络地址的通信协议。在IP网络中，每个连接Internet的设备都需要分配唯一的IP地址。DHCP使网络管理员能从中心结点监控和分配IP地址。当某台计算机移到网络中的其它位置时，能自动收到新的IP地址。 DHCP使用了 租约 的概念，或称为计算机IP地址的有效期。租用时间是不定的，主要取决于用户在某地连接Internet需要多久，这对于教育行业和其它用户频繁改变的环境是很实用的。通过较短的租期，DHCP能够在一个计算机比可用IP地址多的环境中动态地重新配置网络。DHCP支持为计算机分配静态地址，如需要永久性IP地址的Web服务器。 NAT（地址转换协议） NAT是一种 在IP封包通过路由器或防火墙时重写来源IP地址或目的IP地址的技术。这种技术被普遍使用在有多台主机但只通过一个公有IP地址访问因特网的私有网络中。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/3-net/3-tcp.html":{"url":"basic/3-net/3-tcp.html","title":"TCP","keywords":"","body":"TCP TCP概述 TCP的特点 TCP是面向连接的传输层协议。 TCP连接是点对点的（套接字--IP:Port到套接字）。 TCP提供可靠交付的服务。 TCP提供全双工通信。 面向字节流。 TCP与UDP的区别。 TCP UDP 是否连接 面向连接 面向非连接 传输可靠性 可靠 不可靠 应用场合 传输大量数据 少量数据 速度 慢 快 基本概念： 发送缓存和接受缓存：用来临时保存双向通信的数据。在发送时，应用程序将数据传送给TCP发送缓存后，就可以做自己的事情，TCP在合适的时候发送数据；在接受数据时，TCP把发送的数据放入缓存，上层应用在合适的时候读取缓存即可。 滑动窗口：TCP的滑动窗口以字节为单位，用3个指针进行表示。当窗口内连续报文段被确认收到后，可以将窗口向前滑动。窗口大小应小于等于缓存区的大小。 滑动窗口协议：只有在接收窗口向前滑动时（与此同时也发送了确认），发送窗口才有可能向前滑动。收发两端的窗口按照以上规律不断地向前滑动，因此这种协议又称为滑动窗口协议。 当发送窗口和接收窗口的大小都等于 1时，就是停止等待协议。 当发送窗口大于1，接收窗口等于1时，就是回退N步协议。 当发送窗口和接收窗口的大小均大于1时，就是选择重发协议。 TCP报文结构。 源端口、目的端口：16位长。标识出远端和本地的端口号。 序列号：32位长。表明了发送的数据报的顺序，不一定从0开始。 确认号：32位长。希望收到的下一个数据报的序列号，表明到序列号N-1为止的所有数据已经正确收到。 TCP协议数据报头长：4位长。表明TCP头中包含多少个32位字。 接下来的6位未用。 ACK：ACK位置1表明确认号是合法的。如果ACK为0，那么数据报不包含确认信息，确认字段被省略。 PSH：表示是带有PUSH标志的数据。接收方因此请求数据报一到便可送往应用程序而不必等到缓冲区装满时才传送。 RST：用于复位由于主机崩溃或其它原因而出现的错误的连接。还可以用于拒绝非法的数据报或拒绝连接请求。 SYN：用于建立连接。 FIN：用于释放连接。 窗口大小：16位长。窗口大小字段表示在确认了字节之后还可以发送多少个字节。 校验和：16位长。是为了确保高可靠性而设置的。它校验头部、数据和伪TCP头部之和。 紧急指针：URG=1时才有意义。 可选项：长度可变，最长40个字节。 MMS SACK：选择确认。 时间戳：计算往返时间；用于处理TCP序号超过2^32的情况，又称为防止序号回绕（PAWS）。 TCP最小长度为20个字节。 三次握手 第一次握手：建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。 内核对 TCP 的处理 Socket 是一个由 源IP、源Port、目标IP、目标Port、协议 组成的五元组，唯一标示一个 socket 连接。 TCP 建立连接的整体流程： 服务器端在调用 listen 之后，内核会建立两个队列，SYN队列和ACCEPT队列，其中ACCPET队列的长度由backlog指定。 服务器端在调用 accpet 之后，将阻塞，等待 ACCPT 队列有元素。 客户端在调用 connect 之后，将开始发起 SYN 请求，请求与服务器建立连接，此时称为第一次握手。 服务器端在接受到 SYN 请求之后，把请求方放入 SYN 队列中，并给客户端回复一个确认帧 ACK ，此帧还会携带一个请求与客户端建立连接的请求标志，也就是 SYN ，这称为第二次握手 客户端收到 SYN+ACK 帧后， connect 返回，并发送确认建立连接帧 ACK 给服务器端。这称为第三次握手 服务器端收到 ACK 帧后，会把请求方从 SYN 队列中移出，放至 ACCEPT 队列中，而 accept 函数也等到了自己的资源，从阻塞中唤醒，从 ACCEPT 队列中取出请求方，重新建立一个新的 sockfd ，并返回。 在服务端如何分发多个连接的请求？ 由于 TCP/IP 协议栈是维护着一个接收和发送缓冲区的。在接收到来自客户端的数据包后，服务器端的 TCP/IP 协议栈应该会做如下处理： 如果收到的是请求连接的数据包，则传给监听着连接请求端口的 socetfd 套接字。 如果是已经建立过连接后的客户端数据包，则将数据放入接收缓冲区。这样，当服务器端需要读取指定客户端的数据时，则可以利用 socketfd_new 套接字通过 recv 或者 read 函数到缓冲区里面去取指定的数据（因为 socketfd_new 代表的 socket 对象记录了客户端IP和端口，因此可以鉴别）。 数据包如何找到相对应的 socket ，这个方法在 Linux Kernel 代码里也是有体现的： static inline struct sock *__inet_lookup(struct net *net, struct inet_hashinfo *hashinfo, const __be32 saddr, const __be16 sport, const __be32 daddr, const __be16 dport, const int dif) { u16 hnum = ntohs(dport); /* 先尝试查找处于连接成功的 socket */ struct sock *sk = __inet_lookup_established(net, hashinfo, saddr, sport, daddr, hnum, dif); /* 如果没有找到连接成功的socket，那么就去处于 listen 状态的 socket 查找 */ return sk ? : __inet_lookup_listener(net, hashinfo, daddr, hnum, dif); } 四次挥手 在Time_Wait阶段，主动端等待2*MSL时间，MSL建议为2分钟。 由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。 客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送（报文段4）。 服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1（报文段5）。和SYN一样，一个FIN将占用一个序号。 服务器B关闭与客户端A的连接，发送一个FIN给客户端A（报文段6）。 客户端A发回ACK报文确认，并将确认序号设置为收到序号加1（报文段7） TCP采用四次挥手关闭连接如图所示为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？ 这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建连请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。 ARQ协议 ARQ协议（自动重传请求）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。 停止等待ARQ 发送点对接收点发送数据包，然后等待接收点回复ACK并且开始计时。 在等待过程中，发送点停止发送新的数据包。 当数据包没有成功被接收点接收时候，接收点不会发送ACK.这样发送点在等待一定时间后，重新发送数据包。 反复以上步骤直到收到从接收点发送的ACK。 这个协议的缺点是较长的等待时间导致低的数据传输速度。在低速传输时，对连接频道的利用率比较好，但是在高速传输时，频道的利用率会显著下降。 连续ARQ协议（累积确认） 为了克服停止并等待ARQ协议长时间等待ACK的缺点。这个协议会连续发送一组数据包，然后再等待这些数据包的ACK。 在连续ARQ协议中涉及到滑动窗口协议，这是TCP协议的精髓所在。 回退N重传 接收点丢弃从第一个没有收到的数据包开始的所有数据包。 发送点收到NACK后，从NACK中指明的数据包开始重新发送。 选择重传（SACK） 发送点连续发送数据包但对每个数据包都设有个一个计时器。 当在一定时间内没有收到某个数据包的ACK时，发送点只重新发送那个没有ACK的数据包。 相对于回退N重传来说，选择重传可以减少重传的数据。 TCP流量控制 流量控制指点对点通信量的控制，是端到端正的问题。流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。这里是通过滑动窗口机制来实现的。发送方的发送窗口不能超过接收方的接收窗口。TCP的窗口单位是字节，不是报文段。 这上图中B一共进行了三次流量控制：第一次将窗口减小到300，第二次减小到100，最后减小到0，这时发送方暂停发送知道B发送一个新的窗口值为止。 如果B发送了一个新的窗口值到A，但是A并没有收到，就会造成死锁。为解决这个问题，TCP为每个链接设置有一个持续计时器。只要TCP收到一个0窗口，就启动计时器。若计时器设置的时间到了，就发送一个探测报文，而接收方在确认的时候会给出一个现在的窗口值。 TCP拥塞控制 防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提：网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的所有因素。 慢开始和拥塞避免 发送方维持一个拥塞窗口cwnd的状态变量。发送方让自己的发送窗口小于等于拥塞窗口。 慢开始：由小到大的逐渐增大拥塞窗口。首先将cwnd设置为一个最大报文段MMS，在收到一个对新的报文段的确认后，把拥塞窗口增加一个MMS。——指数增长 拥塞避免：当慢开始到门限值（ssthresh）后，使用拥塞避免算法（cwnd每次加1）。当发现网络拥塞后，将cwnd置为1，ssthresh减半，再次执行慢开始。 快重传和快恢复 快重传：当接收方收到一个失序报文段后就立即发送重复确认而不要等到自己发送数据时捎带确认。当发送方连续收到三个重复确认时，应立即重传接收方尚未收到的报文段。 快恢复：与快重传结合使用。 在连续收到三个重复确认时，将慢开始的ssthresh减半，这是为了防止网络拥塞（ 接下来并不执行慢开始 ）。 由于发送方现在认为 网络很可能没有拥塞，于是接下来不执行慢开始，而是将cwnd值设置为ssthresh减半后的值，然后执行拥塞避免。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/3-net/4-ip.html":{"url":"basic/3-net/4-ip.html","title":"IP","keywords":"","body":"IP 地址分类 A类：8位网络号，0_ _ _ _ _ _ _，1.0.0.0 ~ 126.0.0.0 B类：16位网络号，10 _ _ ...，128.0.0.0 ~ 191.255.255.255 C类：24位网络号，110_ _ _...，192.0.0.0 ~ 223.255.255.255 D类：多播地址，1110_ _ _... E类：保留地址，1111_ _ _ ... 私有地址 A类:10.0.0.0 ~ 10.255.255.255(长度相当于1个A类IP地址) B类:172.16.0.0 ~ 172.31.255.255(长度相当于16个连续的B类IP地址) C类:192.168.0.0 ~ 192.168.255.255(长度相当于256个连续的C类IP地址) 特殊的IP地址 0.0.0.0：已经不是一个真正意义上的IP地址。它表示的是这样一个集合：所有不清楚的主机和目的网络。这里的“不清楚”是指在本机的路由表里没有特定条目指明如何到达。如果在网络设置中设置了缺省网关,那么系统会自动产生一个目的地址为0.0.0.0的缺省路由.对本机来说,它就是一个“收容所”,所有不认识的“三无”人员,一 律送进去。 255.255.255.255： 限制广播地址，对本机来说,这个地址指本网段内(同一广播域)的所有主机。这个地址不能被路由器转发。 127.0.0.1：本机地址主要用于测试。这样一个地址,是不能把它发到网络接口的。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/3-net/5-http.html":{"url":"basic/3-net/5-http.html","title":"HTTP","keywords":"","body":"HTTP HTTP构建于TCP/IP协议之上，默认端口号是80。 HTTP是 无连接无状态 的。 无连接的含义是 限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。后来使用了Keep-Alive技术。 无状态是指 协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。即我们给服务器发送 HTTP 请求之后，服务器根据请求，会给我们发送数据过来，但是，发送完，不会记录任何信息。 HTTP 协议这种特性有优点也有缺点，优点在于解放了服务器，每一次请求“点到为止”不会造成不必要连接占用，缺点在于每次请求会传输大量重复的内容信息。 为了解决HTTP无状态的缺点，两种用于保持 HTTP 连接状态的技术就应运而生了，一个是 Cookie，而另一个则是 Session。Cookie在客户端记录状态，比如登录状态。Session在服务器记录状态。 Http的报文结构 HTTP 请求报文头部 User-Agent：产生请求的浏览器类型。 Accept：客户端可识别的响应内容类型列表; Accept-Language：客户端可接受的自然语言; Accept-Encoding：客户端可接受的编码压缩格式; Accept-Charset：可接受的应答的字符集; Host：请求的主机名，允许多个域名同处一个IP 地址，即虚拟主机;（必选） Connection：连接方式(close 或 keep-alive); Cookie：存储于客户端扩展字段，向同一域名的服务端发送属于该域的cookie; 请求包体：在POST方法中使用。 Referer：包含一个URL，用户从该URL代表的页面出发访问当前请求的页面。 If-Modified-Since：文档的最后改动时间 HTTP 响应头 Allow 服务器支持哪些请求方法（如GET、POST等）。 Content-Encoding 文档的编码（Encode）方法。 Content-Length 表示内容长度。只有当浏览器使用持久HTTP连接时才需要这个数据。 Content-Type 表示后面的文档属于什么MIME类型。 Date 当前的GMT时间。你可以用setDateHeader来设置这个头以避免转换时间格式的麻烦。 Expires 应该在什么时候认为文档已经过期，从而不再缓存它。 Last-Modified 文档的最后改动时间。 Refresh 表示浏览器应该在多少时间之后刷新文档，以秒计。 Server 服务器名字。 Set-Cookie 设置和页面关联的Cookie。 ETag：被请求变量的实体值。ETag是一个可以与Web资源关联的记号（MD5值）。 Cache-Control：这个字段用于指定所有缓存机制在整个请求/响应链中必须服从的指令。 max-age：表示当访问此网页后的 x 秒内再次访问不会去服务器；no-cache，实际上Cache-Control: no-cache是会被缓存的，只不过每次在向客户端（浏览器）提供响应数据时，缓存都要向服务器评估缓存响应的有效性；no-store，这个才是响应不被缓存的意思； Last-Modified与If-Modified-Since都是用来记录页面的最后修改时间。当客户端访问页面时，服务器会将页面最后修改时间通过 Last-Modified 标识由服务器发往客户端，客户端记录修改时间，再次请求本地存在的cache页面时，客户端会通过 If-Modified-Since 头将先前服务器端发过来的最后修改时间戳发送回去，服务器端通过这个时间戳判断客户端的页面是否是最新的，如果不是最新的，则返回新的内容，如果是最新的，则返回 304。 Http的状态码含义。 1** 信息，服务器收到请求，需要请求者继续执行操作 2** 成功，操作被成功接收并处理 3** 重定向，需要进一步的操作以完成请求 301 Moved Permanently。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 302 Moved Temporarily。与301类似。但资源只是临时被移动。客户端应继续使用原有URI 304 Not Modified。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源。 4** 客户端错误，请求包含语法错误或无法完成请求 400 Bad Request 由于客户端请求有语法错误，不能被服务器所理解。 401 Unauthorized 请求未经授权。这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden 服务器收到请求，但是拒绝提供服务。服务器通常会在响应正文中给出不提供服务的原因 404 Not Found 请求的资源不存在，例如，输入了错误的URL 5** 服务器错误，服务器在处理请求的过程中发生了错误 500 Internal Server Error 服务器发生不可预期的错误，导致无法完成客户端的请求。 503 Service Unavailable 服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常。 Http request的几种类型。 GET 请求指定的页面信息，并返回实体主体。 POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。 PUT 从客户端向服务器传送的数据取代指定的文档的内容。 DELETE 请求服务器删除指定的页面。 GET可提交的数据量受到URL长度的限制，HTTP协议规范没有对URL长度进行限制。这个限制是特定的浏览器及服务器对它的限制 理论上讲，POST是没有大小限制的，HTTP协议规范也没有进行大小限制，出于安全考虑，服务器软件在实现时会做一定限制 条件 GET HTTP条件GET 是 HTTP 协议为了减少不必要的带宽浪费，提出的一种方案。实际上就是利用If-Modified-Since做浏览器缓存。 持久连接 我们知道 HTTP 协议采用请求-应答模式，当使用普通模式，即非 Keep-Alive 模式时，每个请求/应答客户和服务器都要新建一个连接，完成之后立即断开连接（HTTP协议为无连接的协议）；当使用 Keep-Alive 模式（又称持久连接、连接重用）时，Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免了建立或者重新建立连接。 在 HTTP 1.0 中, 没有官方的 keep alive 的操作。通常是在现有协议上添加一个指数。如果浏览器支持 keep-alive，它会在请求的包头中添加： Connection: Keep-Alive 然后当服务器收到请求，作出回应的时候，它也添加一个头在响应中： Connection: Keep-Alive 这样做，连接就不会中断（超过 Keep-Alive 规定的时间--服务器设置，意外断电等情况除外），而是保持连接。当客户端发送另一个请求时，它会使用同一个连接。这一直继续到客户端或服务器端认为会话已经结束，其中一方中断连接。 在 HTTP 1.1 版本中，默认情况下所有连接都被保持，如果加入 \"Connection: close\" 才关闭。 HTTP Keep-Alive 简单说就是保持当前的TCP连接，避免了重新建立连接。 HTTP 长连接不可能一直保持，例如 Keep-Alive: timeout=5, max=100，表示这个TCP通道可以保持5秒，max=100，表示这个长连接最多接收100次请求就断开。 HTTP是一个无状态协议，这意味着每个请求都是独立的，Keep-Alive没能改变这个结果。另外，Keep-Alive也不能保证客户端和服务器之间的连接一定是活跃的，在HTTP1.1版本中也如此。唯一能保证的就是当连接被关闭时你能得到一个通知，所以不应该让程序依赖于Keep-Alive的保持连接特性，否则会有意想不到的后果。 使用长连接之后，客户端、服务端怎么知道本次传输结束呢？两部分：1. 判断传输数据是否达到了Content-Length 指示的大小；2. 动态生成的文件没有 Content-Length ，它是分块传输（chunked），这时候就要根据 chunked 编码来判断，chunked 编码的数据在最后有一个空 chunked 块，表明本次传输数据结束。 跨站攻击 CSRF（Cross-site request forgery，跨站请求伪造）伪造请求，冒充用户在站内的正常操作，比如爬虫。 防范的方法 关键操作只接受POST请求 验证码 检测 Referer Token Token 要足够随机——只有这样才算不可预测 Token 是一次性的，即每次请求成功后要更新Token——这样可以增加攻击难度，增加预测难度 Token 要注意保密性——敏感操作使用 post，防止 Token 出现在 URL 中 断点续传 要实现断点续传的功能，通常都需要客户端记录下当前的下载进度，并在需要续传的时候通知服务端本次需要下载的内容片段。 HTTP1.1协议中定义了断点续传相关的HTTP头 Range 和 Content-Range 字段，一个最简单的断点续传实现大概如下： 客户端下载一个1024K的文件，已经下载了其中512K 网络中断，客户端请求续传，因此需要在HTTP头中申明本次需要续传的片段：Range:bytes=512000-，这个头通知服务端从文件的512K位置开始传输文件。 服务端收到断点续传请求，从文件的512K位置开始传输，并且在HTTP头中增加：Content-Range:bytes 512000-/1024000，并且此时服务端返回的HTTP状态码应该是206，而不是200。 但是在实际场景中，会出现一种情况，即在终端发起续传请求时，URL对应的文件内容在服务端已经发生变化，此时续传的数据肯定是错误的。如何解决这个问题了？显然此时我们需要有一个标识文件唯一性的方法。在RFC2616中也有相应的定义，比如 实现Last-Modified来标识文件的最后修改时间，这样即可判断出续传文件时是否已经发生过改动。同时RFC2616中还定义有一个ETag的头，可以使用ETag头来放置文件的唯一标识，比如文件的MD5值。 客户端在发起续传请求时应该在HTTP头中申明If-Match 或者 If-Modified-Since 字段，帮助服务端判别文件变化。 一次HTTP请求 域名解析 浏览器缓存 系统缓存 hosts ISP DNS 缓存 DNS 服务器搜索 浏览器发送 HTTP 请求到目标服务器 服务器永久重定向 浏览器跟踪重定向地址 服务器“处理”请求 服务器发回一个HTML响应 浏览器开始显示HTML 浏览器请求获取嵌入在 HTML 中的对象（图片&脚本等） 浏览器发送异步（AJAX）请求 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/3-net/6-https.html":{"url":"basic/3-net/6-https.html","title":"HTTPS","keywords":"","body":"HTTPS HTTPS 是一种通过计算机网络进行安全通信的传输协议。HTTPS经由HTTP进行通信，但利用 SSL/TLS 来加密数据包。 HTTPS 开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。 HTTPS 的主要思想是在不安全的网络上创建一安全信道，并可在使用适当的加密包和服务器证书可被验证且可被信任时，对窃听和中间人攻击提供合理的防护。HTTPS的信任继承基于预先安装在浏览器中的证书颁发机构（如Symantec、Comodo、GoDaddy和GlobalSign等）（意即“我信任证书颁发机构告诉我应该信任的”） HTTP 为什么不安全 http 协议属于 明文传输协议 ，交互过程以及数据传输都没有进行加密，通信双方也没有进行任何认证，通信过程非常容易遭遇劫持、监听、篡改，严重情况下，会造成恶意的流量劫持等问题，甚至造成个人隐私泄露（比如银行卡卡号和密码泄露）等严重的安全问题。 比如常见的，在 http 通信过程中，“中间人”将广告链接嵌入到服务器发给用户的 http 报文里，导致用户界面出现很多不良链接； 或者是修改用户的请求头 URL ，导致用户的请求被劫持到另外一个网站，用户的请求永远到不了真正的服务器。这些都会导致用户得不到正确的服务，甚至是损失惨重。 HTTPS 如何保证安全 要解决 http 带来的问题，就要引入加密以及身份验证机制。 数字证书 服务器首先生成公私钥，将公钥提供给相关机构（CA），CA 将公钥放入数字证书并将数字证书颁布给服务器，此时服务器就不是简单的把公钥给客户端，而是给客户端一个数字证书，数字证书中加入了一些数字签名的机制，保证了数字证书一定是服务器给客户端的。中间人发送的伪造证书，不能够获得 CA 的认证，此时，客户端和服务器就知道通信被劫持了。 证书由 公钥、证书主体、数字签名 等内容组成。在客户端发起 SSL 请求后，服务端会将数字证书发给客户端，客户端会对证书进行验证（验证这张证书是否是伪造的？也就是公钥是否是伪造的），如果证书不是伪造的，客户端就获取用于对称密钥交换的非对称密钥（获取公钥） 数字证书有三个作用： 身份授权：确保浏览器访问的网站是经过CA验证的可信任的网站。 分发公钥：每个数字证书都包含了注册者生成的公钥（验证确保是合法的，非伪造的公钥）。在 SSL 握手时会通过 certificate 消息传输给客户端。 验证证书合法性：客户端接收到数字证书后，会对证书合法性进行验证。只有验证通过后的证书，才能够进行后续通信过程。 证书的认证 信任：浏览器内置了信任的根证书，就是看看web服务器的证书是不是这些信任根发的或者信任根的二级证书机构颁发的。 对方是不是上述证书的合法持有者。简单来说证明对方是否持有证书的对应私钥。验证方法两种，一种是对方签个名，我用证书验证签名；另外一种是用证书做个信封，看对方是否能解开。 有效，就是看看web服务器证书是否在有效期，是否被吊销了。 验证正式是否吊销可以采用黑名单方式或者OCSP方式。黑名单就是定期从CA下载一个名单列表，里面有吊销的证书序列号，自己在本地比对一下就行。优点是效率高。缺点是不实时。OCSP是实时连接CA去验证，优点是实时，缺点是效率不高。 怎样避免第三方伪造这个证书？答案就是数字签名（ digital signature ）。数字签名是证书的防伪标签，目前使用最广泛的 SHA-RSA （SHA用于哈希算法，RSA用于非对称加密算法）。数字签名的制作和验证过程如下： 1. 数字签名的签发：首先是使用哈希函数对证书内容进行安全哈希，生成消息摘要，然后使用CA自己的私钥对消息摘要进行加密。 2. 数字签名的校验：使用 CA 的公钥和证书里的解密算法解密签名，根据证书的摘要算法计算证书摘要信息，并进行比较，如果相同就认为校验成功。 需要注意的是： 1. 数字签名签发和校验使用的非对称密钥是CA自己的公钥和私钥，跟证书申请者（提交证书申请的公司实体）提交的公钥没有任何关系。 2. 数字签名的签发过程跟公钥加密的过程刚好相反，即是用私钥加密，公钥解密。（一对公钥和私钥，公钥加密的内容只有私钥能够解密；反过来，私钥加密的内容，也就有公钥才能够解密） 3. 现在大的CA都会有证书链，证书链的好处：首先是安全，保持CA的私钥离线使用。第二个好处是方便部署和撤销。这里为啥要撤销呢？因为，如果CA数字证书出现问题（被篡改或者污染），只需要撤销相应级别的证书，根证书依然是安全的。 4. 根CA证书都是自签名，即用自己的公钥和私钥完成了签名的制作和验证。而证书链上的证书签名都是使用上一级证书的非对称密钥进行签名和验证的。 5. 怎样获取根CA和多级CA的密钥对？还有，既然是自签名和自认证，那么它们是否安全可信？这里的答案是：当然可信，因为这些厂商跟浏览器和操作系统都有合作，它们的根公钥都默认装到了浏览器或者操作系统环境里。 SSL/TLS协议 不使用SSL/TLS的HTTP通信，就是不加密的通信。所有信息明文传播，带来了三大风险。 （1） 窃听风险（eavesdropping）：第三方可以获知通信内容。 （2） 篡改风险（tampering）：第三方可以修改通信内容。 （3） 冒充风险（pretending）：第三方可以冒充他人身份参与通信。 SSL/TLS协议是为了解决这三大风险而设计的，希望达到： （1） 所有信息都是加密传播，第三方无法窃听。 （2） 具有校验机制，一旦被篡改，通信双方会立刻发现。 （3） 配备身份证书，防止身份被冒充。 目前，应用最广泛的是 TLS 1.0，接下来是SSL 3.0。但是，主流浏览器都已经实现了 TLS 1.2 的支持。TLS 1.0通常被标示为SSL 3.1，TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3。 1994年，NetScape公司设计了SSL协议（Secure Sockets Layer）的1.0版，但是未发布。 1995年，NetScape公司发布SSL 2.0版，很快发现有严重漏洞。 1996年，SSL 3.0版问世，得到大规模应用。 1999年，互联网标准化组织ISOC接替NetScape公司，发布了SSL的升级版TLS 1.0版。 2006年和2008年，TLS进行了两次升级，分别为TLS 1.1版和TLS 1.2版。最新的变动是2011年TLS 1.2的修订版。 TLS 运行过程 SSL/TLS协议的基本思路是采用 公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。因此，SSL/TLS协议的基本过程是这样的： （1） 客户端向服务器端索要并验证公钥。 （2） 双方协商生成\"对话密钥\"。 （3） 双方采用\"对话密钥\"进行加密通信。 \"握手阶段\"涉及四次通信，我们一个个来看。需要注意的是，\"握手阶段\"的所有通信都是明文的。 客户端发出请求（ClientHello） 首先，客户端（通常是浏览器）先向服务器发出加密通信的请求，这被叫做 ClientHello 请求。 在这一步，客户端主要向服务器提供以下信息。 （1） 支持的协议版本，比如TLS 1.0版。 （2） 一个客户端生成的随机数，稍后用于生成\"对话密钥\"。 （3） 支持的加密方法，比如RSA公钥加密。 （4） 支持的压缩方法。 这里需要注意的是，客户端发送的信息之中不包括服务器的域名。也就是说，理论上服务器只能包含一个网站，否则会分不清应该向客户端提供哪一个网站的数字证书。这就是为什么通常一台服务器只能有一张数字证书的原因。 对于虚拟主机的用户来说，这当然很不方便。2006年，TLS协议加入了一个 Server Name Indication 扩展，允许客户端向服务器提供它所请求的域名。 服务器回应（SeverHello） 服务器收到客户端请求后，向客户端发出回应，这叫做 SeverHello 。服务器的回应包含以下内容。 （1）确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。 （2） 一个服务器生成的随机数，稍后用于生成 对话密钥。 （3） 确认使用的加密方法，比如 RSA 公钥加密。 （4） 服务器证书。 除了上面这些信息，如果服务器需要确认客户端的身份，就会再包含一项请求，要求客户端提供 \"客户端证书\"。比如，金融机构往往只允许认证客户连入自己的网络，就会向正式客户提供 USB 密钥，里面就包含了一张客户端证书。 客户端回应 客户端收到服务器回应以后，首先验证服务器证书。如果证书不是可信机构颁布、或者证书中的域名与实际域名不一致、或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。 如果证书没有问题，客户端就会从证书中取出服务器的公钥。然后，向服务器发送加密信息，包含下面三项信息。 （1） 一个随机数。该随机数用服务器公钥加密，防止被窃听。 （2） 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 （3） 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验。 上面第一项的随机数，是整个握手阶段出现的第三个随机数，又称 pre-master key 。有了它以后，客户端和服务器就同时有了三个随机数，接着双方就用事先商定的加密方法，各自生成本次会话所用的同一把\"会话密钥\"。 至于 为什么一定要用三个随机数，来生成\"会话密钥\"： 不管是客户端还是服务器，都需要随机数，这样生成的密钥才不会每次都一样。由于SSL协议中证书是静态的，因此十分有必要引入一种随机因素来保证协商出来的密钥的随机性。 对于 RSA 密钥交换算法来说，pre-master-key本身就是一个随机数，再加上 hello 消息中的随机，三个随机数通过一个密钥导出器最终导出一个对称密钥。 pre master 的存在在于 SSL 协议不信任每个主机都能产生完全随机的随机数，如果随机数不随机，那么 pre master secret（对称密钥） 就有可能被猜出来，那么仅适用 pre master secret 作为密钥就不合适了，因此必须引入新的随机因素，那么客户端和服务器三个随机数一同生成的密钥就不容易被猜出了，一个伪随机可能完全不随机，可是是三个伪随机就十分接近随机了，每增加一个自由度，随机性增加的可不是一个量级。 此外，如果前一步，服务器要求客户端证书，客户端会在这一步发送证书及相关信息。 服务器的最后回应 服务器收到客户端的第三个随机数 pre-master key 之后，计算生成本次会话所用的\"会话密钥\"。然后，向客户端最后发送下面信息。 （1）编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 （2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的 hash 值，用来供客户端校验。 至此，整个握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的HTTP协议，只不过用\"会话密钥\"加密内容。 TCP 流过程 Client Hello：客户端将其SSL版本号、加密设置参数、与session有关的数据以及其它一些必要信息（如加密算法和能支持的密钥大小）发送到服务器。 Server Hello：服务器将其SSL版本号、加密设置参数、与session有关的数据以及其它一些必要信息发送给客户端 Certificate（可选）：服务器发一个证书或一个证书链到客户端，证书链开始于服务器公共钥匙并结束于证明权威的根证书。该证书用于向客户端确认服务器的身份，该消息是可选的。如果配置服务器的SSL需要验证服务器的身份，会发送该消息。多数电子商务应用都需要服务器端身份验证。 Certificate Request（可选）：如果配置服务器的SSL需要验证用户身份，还要发出请求要求浏览器提供用户证书。 多数电子商务不需要客户端身份验证，不过，在支付过程中经常需要客户端身份验证。 Server Key Exchange（可选）：如果服务器发送的公共密钥对加密密钥的交换不是很合适，则发送一个服务器密钥交换消息。 ServerHelloDone：通知客户端，服务器已经完成了交流过程的初始化。 Certificate（可选）：客户端发送客户端证书给服务器。仅当服务器请求客户端身份验证的时候会发送客户端证书 Client Key Exchange：客户端产生一个会话密钥与服务器共享。在SSL握手协议完成后，客户端与服务器端通信信息的加密就会使用该会话密钥。如果使用RSA加密算法，客户端将使用服务器的公钥将会话加密后再发送给服务器。服务器使用自己的私钥对接收的消息进行解密得到共享的会话密钥。 Certificate Verify：如果服务器请求验证客户端，则这消息允许服务器完成验证过程。 Change cipher spec：客户端要求服务器在后续的通信中使用加密模式 Finished：客户端告诉服务器已经准备好安全通信了。 Change cipher spec：服务器要求客户端在后续的通信中使用加密模式 Finished：服务器告诉客户端它已经准备好安全通信了。SSL握手完成的标志 Encrypted Data：客户端和服务端在安全信道上进行加密信息的交流 HTTPS 的七个误解 HTTPS无法缓存？：许多人以为，出于安全考虑，浏览器不会在本地保存HTTPS缓存。实际上，只要在HTTP头中使用特定命令，HTTPS是可以缓存的。 SSL证书很贵？：如果你在网上搜一下，就会发现很多便宜的SSL证书，大概10美元一年，这和一个 .com 域名的年费差不多。而且事实上，还能找到免费的 SSL 证书。 HTTPS站点必须有独享的IP地址？使用子域名通配符SSL证书（wildcard SSL certificate，价格大约是每年125美元），就能在一个IP地址上部署多个HTTPS子域名。 转移服务器时要购买新证书？ HTTPS太慢？：使用HTTPS不会使你的网站变得更快（实际上有可能，请看下文），但是有一些技巧可以大大减少额外开销。 有了HTTPS，Cookie和查询字符串就安全了？：虽然无法直接从HTTPS数据中读取Cookie和查询字符串，但是你仍然需要使它们的值变得难以预测。 只有注册登录页，才需要HTTPS？：这种想法很普遍。人们觉得，HTTPS可以保护用户的密码，此外就不需要了。Firefox浏览器新插件Firesheep，证明了这种想法是错的。我们可以看到，在Twitter和Facebook上，劫持其他人的session是非常容易的。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/3-net/10-questions.html":{"url":"basic/3-net/10-questions.html","title":"面试题","keywords":"","body":"面试题 CSMA/CD有什么作用？ CSMA/CD即带冲突检测的载波监听多路访问技术，应用在 OSI 的第二层数据链路层，是为了解决共享介质的传输效率的问题。其原理简单总结为：先听后发，边发边听，冲突停发，随机延迟后重发。 Http会话的过程？ 建立tcp连接 发出请求文档 发出响应文档 释放tcp连接 TCP协议如何实现可靠传输？ TCP 协议是通过ARQ协议以及等待、确认、重传等机制实现可靠传输。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/4-database/":{"url":"basic/4-database/","title":"数据库","keywords":"","body":"数据库系统 三范式 第一范式 在关系模型中，对域添加的一个规范要求，所有的域都应该是原子性的，即数据库表的每一列都是不可分割的原子数据项，而不能是集合，数组，记录等非原子数据项。 第二范式 在第一范式的基础上，非码属性必须完全依赖于候选码，在第一范式基础上消除非主属性对主码的部分函数依赖。 第三范式 在第一范式基础上，任何非主属性不依赖于其它非主属性，在第二范式基础上消除传递依赖。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/4-database/1-transaction.html":{"url":"basic/4-database/1-transaction.html","title":"事务","keywords":"","body":"事务 事务的特性 所谓事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。 Atomicity（原子性） 原子性是指事务是一个不可再分割的工作单位，事务中的操作要么都发生，要么都不发生。 Consistency（一致性） 一致性是指在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。这是说数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。 Isolation（隔离性） 多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。 这指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看到中间状态的数据。 Durability（持久性） 持久性，意味着在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。 事务隔离级别 数据库是要被广大客户所共享访问的，那么在数据库操作过程中很可能出现以下几种不确定情况： 丢失修改：两个事务T1，T2读入同一数据并修改，T2提交的结果被T1破坏了，导致T1的修改丢失。（订票系统） 不可重复读：事务T1读取数据后，事务T2执行更新操作，使T1无法再次读取结果。 可以通过“读锁”和“写锁”解决不可重复读。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。 读脏数据：事务T1修改某个数据并写回磁盘，事务T2读取同一数据，但T1由于某种原因撤销了，这时T1修改过的数据恢复原来的值，T2读取的数据就与数据库中的数据不一致。 幻读：事务在操作过程中进行两次查询，第二次查询结果包含了第一次查询中未出现的数据（这里并不要求两次查询SQL语句相同）这是因为在两次查询过程中有另外一个事务插入数据造成的。 为了避免上面出现几种情况在标准SQL规范中定义了4个事务隔离级别，不同隔离级别对事务处理不同 。 未提交读（Read Uncommitted） 未提交读(READ UNCOMMITTED)是最低的隔离级别。允许脏读(dirty reads)，但不允许更新丢失，事务可以看到其他事务“尚未提交”的修改。 提交读（Read Committed） 允许不可重复读取，但不允许脏读取。这可以通过“瞬间共享读锁”和“排他写锁”实现。读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。 可重复读（Repeatable Read） 禁止不可重复读取和脏读取，但是有时可能出现幻读数据。这可以通过“共享读锁”和“排他写锁”实现。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。 可序列化(Serializable) 最高的隔离级别，它要求事务序列化执行，事务只能一个接着一个地执行，不能并发执行。仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。 隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。 隔离级别的实现 数据库对于隔离级别的实现就是使用并发控制机制对在同一时间执行的事务进行控制，限制不同的事务对于同一资源的访问和更新，而最重要也最常见的并发控制机制，在这里我们将简单介绍三种最重要的并发控制器机制的工作原理。 锁 锁是一种最为常见的并发控制机制，在一个事务中，我们并不会将整个数据库都加锁，而是只会锁住那些需要访问的数据项， MySQL 和常见数据库中的锁都分为两种，共享锁（Shared）和互斥锁（Exclusive），前者也叫读锁，后者叫写锁。 读锁保证了读操作可以并发执行，相互不会影响，而写锁保证了在更新数据库数据时不会有其他的事务访问或者更改同一条记录造成不可预知的问题。 时间戳 除了锁，另一种实现事务的隔离性的方式就是通过时间戳，使用这种方式实现事务的数据库，例如 PostgreSQL 会为每一条记录保留两个字段；读时间戳中包括了所有访问该记录的事务中的最大时间戳，而记录行的写时间戳中保存了将记录改到当前值的事务的时间戳。 使用时间戳实现事务的隔离性时，往往都会使用乐观锁，先对数据进行修改，在写回时再去判断当前值，也就是时间戳是否改变过，如果没有改变过，就写入，否则，生成一个新的时间戳并再次更新数据，乐观锁其实并不是真正的锁机制，它只是一种思想，在这里并不会对它进行展开介绍。 多版本和快照隔离 通过维护多个版本的数据，数据库可以允许事务在数据被其他事务更新时对旧版本的数据进行读取，很多数据库都对这一机制进行了实现；因为 所有的读操作不再需要等待写锁的释放，所以能够显著地提升读的性能， MySQL 和 PostgreSQL 都对这一机制进行自己的实现，也就是 MVCC ，虽然各自实现的方式有所不同，MySQL 就通过提到的 undo log 实现了 MVCC，保证事务并行执行时能够不等待互斥锁的释放直接获取数据。 ACID vs CAP 数据库对于 ACID 中的一致性的定义是这样的：如果一个事务原子地在一个一致地数据库中独立运行，那么在它执行之后，数据库的状态一定是一致的。对于这个概念，它的第一层意思就是对于数据完整性的约束，包括主键约束、引用约束以及一些约束检查等等，在事务的执行的前后以及过程中不会违背对数据完整性的约束，所有对数据库写入的操作都应该是合法的，并不能产生不合法的数据状态。 CAP 定理中的数据一致性，其实是说分布式系统中的各个节点中对于同一数据的拷贝有着相同的值；而 ACID 中的一致性是指数据库的规则，如果 schema 中规定了一个值必须是唯一的，那么一致的系统必须确保在所有的操作中，该值都是唯一的，由此来看 CAP 和 ACID 对于一致性的定义有着根本性的区别。 数据库的一致性是：应用系统从一个正确的状态到另一个正确的状态.而 ACID 就是说事务能够通过 AID 来保证这个 C 的过程. C 是目的, AID 都是手段. 使用事务 在MySQL中使用START TRANSACTION 或 BEGIN开启事务，提交事务使用COMMIT，ROLLBACK用来放弃事务。MySQL默认设置了事务的自动提交，即一条SQL语句就是一个事务。 总结 事务的（ACID）特性是由关系数据库管理系统（RDBMS，数据库系统）来实现的。数据库管理系统采用日志来保证事务的原子性、一致性和持久性。日志记录了事务对数据库所做的更新，如果某个事务在执行过程中发生错误，就可以根据日志，撤销事务对数据库已做的更新，使数据库退回到执行事务前的初始状态。 数据库管理系统采用锁机制来实现事务的隔离性。当多个事务同时更新数据库中相同的数据时，只允许持有锁的事务能更新该数据，其他事务必须等待，直到前一个事务释放了锁，其他事务才有机会更新该数据。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/4-database/2-index.html":{"url":"basic/4-database/2-index.html","title":"索引","keywords":"","body":"索引 基本概念 在数据库中，索引的含义与日常意义上的“索引”一词并无多大区别（想想小时候查字典），它是用于提高数据库表数据访问速度的数据库对象。 索引可以避免全表扫描。多数查询可以仅扫描少量索引页及数据页，而不是遍历所有数据页。 对于非聚集索引，有些查询甚至可以不访问数据页。 聚集索引可以避免数据插入操作集中于表的最后一个数据页。 一些情况下，索引还可用于避免排序操作。 索引的存储 一条索引记录中包含的基本信息包括：键值（即你定义索引时指定的所有字段的值）+逻辑指针（指向数据页或者另一索引页）。 当你为一张空表创建索引时，数据库系统将为你分配一个索引页，该索引页在你插入数据前一直是空的。此页此时既是根结点，也是叶结点。每当你往表中插入一行数据，数据库系统即向此根结点中插入一行索引记录。当根结点满时，数据库系统大抵按以下步骤进行分裂： 创建两个儿子结点 将原根结点中的数据近似地拆成两半，分别写入新的两个儿子结点 根结点中加上指向两个儿子结点的指针 通常状况下，由于索引记录仅包含索引字段值（以及4-9字节的指针），索引实体比真实的数据行要小许多，索引页相较数据页来说要密集许多。一个索引页可以存储数量更多的索引记录，这意味着在索引中查找时在I/O上占很大的优势，理解这一点有助于从本质上了解使用索引的优势。 索引的分类 汉语字典的正文本身就是一个聚集索引。比如，我们要查“安”字，就会很自然地翻开字典的前几页，因为“安”的拼音是“an”，而按照拼音排序汉字的字典是以英文字母“a”开头并以“z”结尾的，那么“安”字就自然地排在字典的前部。如果您翻完了所有以“a”开头的部分仍然找不到这个字，那么就说明您的字典中没有这个字；同样的，如果查“张”字，那您也会将您的字典翻到最后部分，因为“张”的拼音是“zhang”。也就是说，字典的正文部分本身就是一个目录，您不需要再去查其他目录来找到您需要找的内容。正文内容本身就是一种按照一定规则排列的目录称为“聚集索引”。 如果您认识某个字，您可以快速地从自动中查到这个字。但您也可能会遇到您不认识的字，不知道它的发音，这时候，您就不能按照刚才的方法找到您要查的字，而需要去根据“偏旁部首”查到您要找的字，然后根据这个字后的页码直接翻到某页来找到您要找的字。但您结合“部首目录”和“检字表”而查到的字的排序并不是真正的正文的排序方法，比如您查“张”字，我们可以看到在查部首之后的检字表中“张”的页码是672页，检字表中“张”的上面是“驰”字，但页码却是63页，“张”的下面是“弩”字，页面是390页。很显然，这些字并不是真正的分别位于“张”字的上下方，现在您看到的连续的“驰、张、弩”三字实际上就是他们在非聚集索引中的排序，是字典正文中的字在非聚集索引中的映射。我们可以通过这种方式来找到您所需要的字，但它需要两个过程，先找到目录中的结果，然后再翻到您所需要的页码。 聚集索引 表数据按照索引的顺序来存储的。对于聚集索引，叶子结点即存储了真实的数据行，不再有另外单独的数据页。在聚集索引中，叶结点也即数据结点，所有数据行的存储顺序与索引的存储顺序一致。 在一张表上只能创建一个聚集索引，因为真实数据的物理顺序只可能是一种。如果一张表没有聚集索引，那么它被称为“堆集”（Heap）。这样的表中的数据行没有特定的顺序，所有的新行将被添加的表的末尾位置。 非聚集索引 表数据存储顺序与索引顺序无关。对于非聚集索引，叶结点包含索引字段值及指向数据页数据行的逻辑指针，该层紧邻数据页，其行数量与数据表行数据量一致。 非聚集索引与聚集索引相比： 叶子结点并非数据结点 叶子结点为每一真正的数据行存储一个“键-指针”对 叶子结点中还存储了一个指针偏移量，根据页指针及指针偏移量可以定位到具体的数据行。 类似的，在除叶结点外的其它索引结点，存储的也是类似的内容，只不过它是指向下一级的索引页的。 索引失效 索引并不是时时都会生效的，比如以下几种情况，将导致索引失效： 如果条件中有or，即使其中有条件带索引也不会使用。 要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引 对于多列索引，不是使用的第一部分，则不会使用索引。 like查询是以%开头。 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来，否则不使用索引。 如果 mysql 估计使用全表扫描要比使用索引快，则不使用索引。例如，使用<>、not in 、not exist，对于这三种情况大多数情况下认为结果集很大，MySQL就有可能不使用索引。 索引设计的原则 表的某个字段值得离散度越高，该字段越适合选作索引的关键字。主键字段以及唯一性约束字段适合选作索引的关键字，原因就是这些字段的值非常离散。 占用存储空间少的字段更适合选作索引的关键字。例如，与字符串相比，整数字段占用的存储空间较少，因此，较为适合选作索引关键字。 存储空间固定的字段更适合选作索引的关键字。与 text 类型的字段相比， char 类型的字段较为适合选作索引关键字。 Where 子句中经常使用的字段应该创建索引，分组字段或者排序字段应该创建索引，两个表的连接字段应该创建索引。 更新频繁的字段不适合创建索引，不会出现在 where 子句中的字段不应该创建索引。 最左前缀原则。 尽量使用前缀索引。 总结 聚集索引是一种稀疏索引，数据页上一级的索引页存储的是页指针，而不是行指针。而对于非聚集索引，则是密集索引，在数据页的上一级索引页它为每一个数据行存储一条索引记录。 与非聚集索引相比，聚集索引有着更快检索速度、更快的字段排序。 在MySQL中InnoDB按照主键进行聚集，如果没有定义主键，InnoDB会试着使用唯一的非空索引来代替。如果没有这种索引，InnoDB就会定义隐藏的主键然后在上面进行聚集，但是主键和聚集索引是不等价的。在InnoDB中Normal索引即非聚集索引。 参考链接 MySQL 索引设计概要 MySQL 索引性能分析概要 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/4-database/3-sql.html":{"url":"basic/4-database/3-sql.html","title":"SQL","keywords":"","body":"SQL语句 CRUD CREATE TABLE CREATE TABLE `user` ( `id` INT AUTO_INCREMENT, `name` VARCHAR (20), PRIMARY KEY (`id`) ); VARCHAR记得指定长度。 UPDATE UPDATE 表名称 SET 列名称 = 新值 WHERE 列名称 = 某值 INSERT INSERT INTO 表名称 VALUES (值1, 值2,....) INSERT INTO table_name (列1, 列2,...) VALUES (值1, 值2,....) DELETE DELETE FROM 表名称 WHERE 列名称 = 值 修改表结构 ALTER TABLE table_name add column_name datatype ALTER TABLE table_name drop COLUMN column_name ALTER TABLE table_name modify COLUMN column_name datatype MySQL SQL 查询语句执行顺序 (7) - SELECT (8) - DISTINCT (1) - FROM (3) - JOIN (2) - ON (4) - WHERE (5) - GROUP BY (6) - HAVING (9) - ORDER BY (10 - LIMIT 关于 SQL 语句的执行顺序，有三个值得我们注意的地方： FROM 才是 SQL 语句执行的第一步，并非 SELECT。 数据库在执行 SQL 语句的第一步是将数据从硬盘加载到数据缓冲区中，以便对这些数据进行操作。 SELECT 是在大部分语句执行了之后才执行的，严格的说是在 FROM 和 GROUP BY 之后执行的。理解这一点是非常重要的，这就是你不能在 WHERE 中使用在 SELECT 中设定别名的字段作为判断条件的原因。 无论在语法上还是在执行顺序上， UNION 总是排在在 ORDER BY 之前。很多人认为每个 UNION 段都能使用 ORDER BY 排序，但是根据 SQL 语言标准和各个数据库 SQL 的执行差异来看，这并不是真的。尽管某些数据库允许 SQL 语句对子查询（subqueries）或者派生表（derived tables）进行排序，但是这并不说明这个排序在 UNION 操作过后仍保持排序后的顺序。 虽然SQL的逻辑查询是根据上述进行查询，但是数据库也许并不会完全按照逻辑查询处理的方式来进行查询。MYSQL数据库有两个组件 Parser（分析SQL语句）和 Optimizer（优化）。 从官方手册上看，可以理解为， MySQL 采用了基于开销的优化器，以确定处理查询的最解方式，也就是说执行查询之前，都会先选择一条自以为最优的方案，然后执行这个方案来获取结果。在很多情况下， MySQL 能够计算最佳的可能查询计划，但在某些情况下， MySQL 没有关于数据的足够信息，或者是提供太多的相关数据信息，估测就不那么友好了。 存在索引的情况下，优化器优先使用条件用到索引且最优的方案。当 sql 条件有多个索引可以选择，mysql 优化器将直接使用效率最高的索引执行。 子查询 子查询按使用场合分： 作为主查询的结果数据：select c1,(select f1 from tab2) as f11 from tab1; #这里子查询应该只有一个数据（一行一列，标量子查询） 作为主查询的条件数据：select c1 from tab1 where c1 in (select f1 from tab2); #这里子查询可以是多个数据（多行一列，列子查询，以及标量子查询，实际上行子查询也可能，但极少） 作为主查询的来源数据：select c1 from (select f1 as c1, f2 from tab2) as t2; #这里子查询可以是任意查询结果（表子查询）。 权限分配 grant select,insert on userdb.userinfo to'zhangsan'@'localhost' 模糊查询 %：表示任意0个或多个字符。可匹配任意类型和长度的字符，有些情况下若是中文，请使用两个百分号（%%）表示。 select * from test where text like '%1%'; _ ： 表示任意单个字符。匹配单个任意字符，它常用来限制表达式的字符长度语句。 --倒数第三个字符为 1 ，且最小长度为 5 select * from test where text like '__%1__'; 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/4-database/4-join.html":{"url":"basic/4-database/4-join.html","title":"连接","keywords":"","body":"连接 在数据库原理中，关系运算包含 选择、投影、连接 这三种运算。相应的在SQL语句中也有表现，其中Where子句作为选择运算，Select子句作为投影运算，From子句作为连接运算。 连接运算是从两个关系的笛卡尔积中选择属性间满足一定条件的元组，在连接中最常用的是等值连接和自然连接。 等值连接：关系R、S,取两者笛卡尔积中属性值相等的元组，不要求属性相同。比如 R.A=S.B 自然连接（内连接）：是一种特殊的等值连接，它要求比较的属性列必须是相同的属性组，并且把结果中重复属性去掉。 -- 关系R -- +----+--------+ -- | A | B | C | -- +----+--------+ -- | a1 | b1 | 5 | -- | a1 | b2 | 6 | -- | a2 | b3 | 8 | -- | a2 | b4 | 12| -- +----+--------+ -- 关系S -- +----+----+ -- | B | E | -- +----+----+ -- | b1 | 3 | -- | b2 | 7 | -- | b3 | 10 | -- | b3 | 2 | -- | b5 | 2| -- +----+----+ 自然连接 R & S的结果为： -- +----+----+-----+----+ -- | A | B | C | E | -- +----+----+-----+----+ -- | a1 | b1 | 5 | 3 | -- | a1 | b2 | 6 | 7 | -- | a2 | b3 | 8 | 10 | -- | a2 | b3 | 8 | 2 | -- +----+----+-----+----+ 两个关系在做自然连接时，选择两个关系在公共属性上值相等的元组构成新的关系。此时关系R中某些元组有可能在S中不存在公共属性上相等的元组，从而造成R中这些元组在操作时被舍弃，同样，S中某些元组也可能被舍弃。这些舍弃的元组被称为 悬浮元组。 如果把悬浮元组也保存在结果中，而在其他属性上置为NULL，那么这种连接就成为 外连接，如果只保留左边关系R中的悬浮元组就叫做 左外连接（左连接），如果只保留右边关系S中的悬浮元组就叫做 右外连接（右连接）。 Join Join 用于多表中字段之间的联系，语法如下： ... FROM table1 INNER|LEFT|RIGHT JOIN table2 ON conditiona -- table1:左表；table2:右表。 JOIN 按照功能大致分为如下三类： INNER JOIN（内连接，或等值连接）：取得两个表中存在连接匹配关系的记录。 LEFT JOIN（左连接）：取得左表（table1）完全记录，即是右表（table2）并无对应匹配记录。 RIGHT JOIN（右连接）：与 LEFT JOIN 相反，取得右表（table2）完全记录，即是左表（table1）并无匹配对应记录。 在下面的示例中使用以下数据： mysql> select A.id,A.name,B.name from A,B where A.id=B.id; -- +----+-----------+-------------+ -- | id | name | name | -- +----+-----------+-------------+ -- | 1 | Pirate | Rutabaga | -- | 2 | Monkey | Pirate | -- | 3 | Ninja | Darth Vader | -- | 4 | Spaghetti | Ninja | -- +----+-----------+-------------+ -- 4 rows in set (0.00 sec) Inner Join 内连接，也叫等值连接，inner join产生同时符合A和B的一组数据。 mysql> select * from A inner join B on A.name = B.name; -- +----+--------+----+--------+ -- | id | name | id | name | -- +----+--------+----+--------+ -- | 1 | Pirate | 2 | Pirate | -- | 3 | Ninja | 4 | Ninja | -- +----+--------+----+--------+ Left Join mysql> select * from A left join B on A.name = B.name; -- 或者：select * from A left outer join B on A.name = B.name; -- +----+-----------+------+--------+ -- | id | name | id | name | -- +----+-----------+------+--------+ -- | 1 | Pirate | 2 | Pirate | -- | 2 | Monkey | NULL | NULL | -- | 3 | Ninja | 4 | Ninja | -- | 4 | Spaghetti | NULL | NULL | -- +----+-----------+------+--------+ -- 4 rows in set (0.00 sec) left join，（或left outer join:在Mysql中两者等价，推荐使用left join）左连接从左表(A)产生一套完整的记录，与匹配的记录(右表(B))。如果没有匹配，右侧将包含null。 如果想只从左表(A)中产生一套记录，但不包含右表(B)的记录，可以通过设置where语句来执行，如下： mysql> select * from A left join B on A.name=B.name where A.id is null or B.id is null; -- +----+-----------+------+------+ -- | id | name | id | name | -- +----+-----------+------+------+ -- | 2 | Monkey | NULL | NULL | -- | 4 | Spaghetti | NULL | NULL | -- +----+-----------+------+------+ -- 2 rows in set (0.00 sec) 根据上面的例子可以求差集，如下： SELECT * FROM A LEFT JOIN B ON A.name = B.name WHERE B.id IS NULL union SELECT * FROM A right JOIN B ON A.name = B.name WHERE A.id IS NULL; -- +------+-----------+------+-------------+ -- | id | name | id | name | -- +------+-----------+------+-------------+ -- | 2 | Monkey | NULL | NULL | -- | 4 | Spaghetti | NULL | NULL | -- | NULL | NULL | 1 | Rutabaga | -- | NULL | NULL | 3 | Darth Vader | -- +------+-----------+------+-------------+ union ：用于合并多个 select 语句的结果集，并去掉重复的值。 union all ：作用和 union 类似，但不会去掉重复的值。 Cross join 交叉连接，得到的结果是两个表的乘积，即笛卡尔积。 实际上，在 MySQL 中（仅限于 MySQL） CROSS JOIN 与 INNER JOIN 的表现是一样的，在不指定 ON 条件得到的结果都是笛卡尔积，反之取得两个表完全匹配的结果。 INNER JOIN 与 CROSS JOIN 可以省略 INNER 或 CROSS 关键字，因此下面的 SQL 效果是一样的： ... FROM table1 INNER JOIN table2 ... FROM table1 CROSS JOIN table2 ... FROM table1 JOIN table2 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/4-database/5-mysql.html":{"url":"basic/4-database/5-mysql.html","title":"MySQL","keywords":"","body":"MySql 引擎 MVCC InnoDB 支持 MVCC 来提高系统读写并发性能。InnoDB MVCC 的实现基于 Undo log，通过回滚段来构建需要的版本记录。通过 ReadView 来判断哪些版本的数据可见。同时 Purge 线程是通过 ReadView 来清理旧版本数据。 MVCC最大的优势：读不加锁，读写不冲突。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能 MYSQL 事务日志 事务日志可以帮助提高事务的效率。使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。 事务日志采用的是追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得多。事务日志持久以后，内存中被修改的数据在后台可以慢慢地刷回到磁盘。目前大多数存储引擎都是这样实现的，我们通常称之为预写式日志（Write-Ahead Logging），修改数据需要写两次磁盘。 如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。 MySQL Innodb中跟数据持久性、原子性有关的日志，有以下几种：Redo Log、Undo Log。 回滚日志 -- Undo Log 想要保证事务的 原子性，就需要在异常发生时，对已经执行的操作进行回滚，而在 MySQL 中，恢复机制是通过回滚日志（undo log）实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后在对数据库中的对应行进行写入。 这个过程其实非常好理解，为了能够在发生错误时撤销之前的全部操作，肯定是需要将之前的操作都记录下来的，这样在发生错误时才可以回滚。 回滚日志除了能够在发生错误或者用户执行 ROLLBACK 时提供回滚相关的信息，它还能够在整个系统发生崩溃、数据库进程直接被杀死后，当用户再次启动数据库进程时，还能够立刻通过查询回滚日志将之前未完成的事务进行回滚，这也就需要回滚日志必须先于数据持久化到磁盘上，是我们需要先写日志后写数据库的主要原因。 回滚日志并不能将数据库物理地恢复到执行语句或者事务之前的样子；它是逻辑日志，当回滚日志被使用时，它只会按照日志逻辑地将数据库中的修改撤销掉，可以理解为，我们在事务中使用的每一条 INSERT 都对应了一条 DELETE ，每一条 UPDATE 也都对应一条相反的 UPDATE 语句。 重做日志 -- Redo Log 与原子性一样，事务的持久性也是通过日志来实现的，MySQL 使用重做日志（redo log）实现事务的持久性，重做日志由两部分组成，一是 内存 中的重做日志缓冲区，因为重做日志缓冲区在内存中，所以它是易失的，另一个就是在 磁盘 上的重做日志文件，它是持久的。 当我们在一个事务中尝试对数据进行修改时，它会先将数据从磁盘读入内存，并更新内存中缓存的数据，然后生成一条重做日志并写入重做日志缓存，当事务真正提交时，MySQL 会将重做日志缓存中的内容刷新到重做日志文件，再将内存中的数据更新到磁盘上，图中的第 4、5 步就是在事务提交时执行的。 在 InnoDB 中，重做日志都是以 512 字节的块的形式进行存储的，同时因为块的大小与磁盘扇区大小相同，所以重做日志的写入可以保证原子性，不会由于机器断电导致重做日志仅写入一半并留下脏数据。 除了所有对数据库的修改会产生重做日志，因为回滚日志也是需要持久存储的，它们也会创建对应的重做日志，在发生错误后，数据库重启时会从重做日志中找出未被更新到数据库磁盘中的日志重新执行以满足事务的持久性。 回滚日志和重做日志 在数据库系统中，事务的原子性和持久性是由事务日志（transaction log）保证的，在实现时也就是上面提到的两种日志，前者用于对事务的影响进行撤销，后者在错误处理时对已经提交的事务进行重做，它们能保证两点： 发生错误或者需要回滚的事务能够成功回滚（原子性）； 在事务提交后，数据没来得及写会磁盘就宕机时，在下次重新启动后能够成功恢复数据（持久性）； 在数据库中，这两种日志经常都是一起工作的，我们可以将它们整体看做一条事务日志，其中包含了事务的 ID、修改的行元素以及修改前后的值。 一条事务日志同时包含了修改前后的值，能够非常简单的进行回滚和重做两种操作，在这里我们也不会对重做和回滚日志展开进行介绍，可能会在之后的文章谈一谈数据库系统的恢复机制时提到两种日志的使用。 MySQL Server 日志 binlog 是 Mysql sever 层维护的一种二进制日志，与 innodb 引擎中的 redo/undo log 是完全不同的日志；其主要是用来记录对 mysql 数据更新或潜在发生更新的 SQL 语句，并以\"事务\"的形式保存在磁盘中；作用主要有： 复制：MySQL Replication 在 Master 端开启 binlog ，Master 把它的二进制日志传递给 slaves 并回放来达到 master-slave 数据一致的目的 数据恢复：通过 mysqlbinlog 工具恢复数据 增量备份 Buffer Pool 如果 MySQL 不使用内存缓冲池，每次读取数据时，都需要访问磁盘，会大大的增加磁盘的IO请求，导致效率低下；在 Innodb 引擎在读取数据的时候，把相应的数据和索引载入到内存的缓冲池（buffer pool）中，一定程度的提高了数据的读写速度。 缓存包括：索引页，数据页，undo页，插入缓冲，自适应哈希索引，innodb存储的锁信息，数据字典等。工作方式是将数据库文件按照页（每页16k）读取到缓冲池，然后按照最近最少使用算法（LRU）来保留缓冲池中的缓冲数据。如果数据库文件需要修改，总是首先修改在缓冲池中的页（发生修改后即成为脏页），然后在按照一定的频率将缓冲池中的脏页刷新到文件 MySQL 中的原则是日志先行。为了满足事务的持久性，防止 buffer pool 数据丢失以及事务持久性， InnoDB 引入了 redo log。为了满足事务的原子性，innodb 引入了 undo log。 MVCC实现 MVCC是通过在每行记录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存行的过期时间（或删除时间）。当然存储的并不是实际的时间值，而是系统版本号（system version number)。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。 下面看一下在 REPEATABLE READ 隔离级别下，MVCC 具体是如何操作的： SELECT：InnoDB 会根据以下两个条件检查每行记录： InnoDB 只查找版本早于当前事务版本的数据行（也就是，行的系统版本号小于或等于事务的系统版本号），这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。 行的删除版本要么未定义，要么大于当前事务版本号。这可以确保事务读取到的行，在事务开始之前未被删除。只有符合上述两个条件的记录，才能返回作为查询结果 INSERT：InnoDB 为新插入的每一行保存当前系统版本号作为行版本号。 DELETE：InnoDB 为删除的每一行保存当前系统版本号作为行删除标识。 UPDATE：InnoDB 插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。保存这两个额外系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行，不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作 主从同步 简单来说，就是保证主SQL（Master）和从SQL（Slave）的数据是一致性的，向 Master 插入数据后，Slave 会自动从 Master 把修改的数据同步过来（有一定的延迟），通过这种方式来保证数据的一致性，就是主从复制。 MySQL主从能解决什么问题 高可用 因为数据都是相同的，所以当Master挂掉后，可以指定一台Slave充当Master继续保证服务运行，因为数据是一致性的（如果当插入Master就挂掉，可能不一致，因为同步也需要时间），当然这种配置不是简单的把一台Slave充当Master，毕竟还要考虑后续的Salve同步Master，当然本文并不是将高可用的配置，所以这里就不多讲了。 负载均衡 因为读写分离也算是负载均衡的一种，所以就不单独写了，因为一般都是有多台Slave的，所以可以将读操作指定到Slave服务器上（需要代码控制），然后再用负载均衡来选择那台Slave来提供服务，同时也可以吧一些大量计算的查询指定到某台Slave，这样就不会影响Master的写入以及其他查询 数据备份 一般我们都会做数据备份，可能是写定时任务，一些特殊行业可能还需要手动备份，有些行业要求备份和原数据不能在同一个地方，所以主从就能很好的解决这个问题，不仅备份及时，而且还可以多地备份，保证数据的安全 业务模块化 可以一个业务模块读取一个Slave，再针对不同的业务场景进行数据库的索引创建和根据业务选择MySQL存储引擎 高扩展（硬件扩展） 主从复制支持2种扩展方式： scale-up：向上扩展或者纵向扩展，主要是提供比现在服务器更好性能的服务器，比如增加CPU和内存以及磁盘阵列等，因为有多台服务器，所以可扩展性比单台更大 scale-out：向外扩展或者横向扩展，是指增加服务器数量的扩展，这样主要能分散各个服务器的压力 主从复制的缺点 成本增加 无可厚非的是搭建主从肯定会增加成本，毕竟一台服务器和两台服务器的成本完全不同，另外由于主从必须要开启二进制日志，所以也会造成额外的性能消耗 数据延迟 Slave从Master复制过来肯定是会有一定的数据延迟的，所以当刚插入就出现查询的情况，可能查询不出来，当然如果是插入者自己查询，那么可以直接从Master中查询出来，当然这个也是需要用代码来控制的 写入更慢 主从复制主要是针对读远大于写或者对数据备份实时性要求较高的系统中，因为 Master 在写中需要更多操作，而且只有一台写入的 Master，写入的压力并不能被分散 复制方式 MySQL5.6开始主从复制有两种方式：基于日志（binlog）、基于GTID（全局事务标示符）。 主从延时如何解决？ MySQL 实际上在有两个同步机制，一个是半同步复制，用来 解决主库数据丢失问题；一个是并行复制，用来 解决主从同步延时问题。 半同步复制，也叫 semi-sync 复制，指的就是主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。 并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。 以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。用户跟客服反馈，而客服就会反馈给我们。 我们通过 MySQL 命令： show status 查看 Seconds_Behind_Master ，可以看到从库复制主库的数据落后了几 ms。一般来说，如果主从延迟较为严重，有以下解决方案： 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询设置 直连主库。不推荐这种方法，你要是这么搞，读写分离的意义就丧失了。 复制原理 Master 将数据改变记录到二进制日志(binary log)中，也就是配置文件log-bin指定的文件，这些记录叫做二进制日志事件(binary log events) Slave 通过I/O线程读取 Master 中的binary log events并写入到它的中继日志(relay log) Slave 重做中继日志中的事件，把中继日志中的事件信息一条一条的在本地执行一次，完成数据在本地的存储，从而实现将改变反映到它自己的数据(数据重放) 要求 主从服务器操作系统版本和位数一致 Master和Slave数据库的版本要一致 Master和Slave数据库中的数据要一致 Master开启二进制日志，Master和Slave的server_id在局域网内必须唯一 分库、扩容的时候的数据迁移 分库分表 目前绝大多数应用采取的两种分库分表规则 mod方式 dayofweek系列日期方式（所有星期1的数据在一个库/表,或所有?月份的数据在一个库表） 这两种方式有个本质的特点，就是 离散性加周期性。例如以一个表的主键对 3 取余数的方式分库或分表： 那么随着数据量的增大，每个表或库的数据量都是各自增长。当一个表或库的数据量增长到了一个极限，要加库或加表的时候， 介于这种分库分表算法的离散性，必需要做数据迁移才能完成。例如从3个扩展到5个的时候： 需要将原先以 mod3 分类的数据，重新以 mod5 分类，不可避免的带来数据迁移。每个表的数据都要被重新分配到多个新的表 相似的例子比如从 dayofweek 分的 7 个库/表,要扩张为以 dayofmonth 分的 31 张库/表，同样需要进行数据迁移。 数据迁移带来的问题是 业务至少要两次发布 要专门写工具来导数据。由于各业务之间的差别，很难做出统一的工具。目前几乎都是每个业务写一套 要解决增量、全量、时间点，数据不一致等问题 如何在数据量扩张到现有库表极限，加库加表时避免数据迁移呢？ 通常的数据增长往往是随着时间的推移增长的。随着业务的开展，时间的推移，数据量不断增加。 考虑到数据增长的特点，如果我们以代表时间增长的字段，按递增的范围分库，则可以避免数据迁移。这样的方式下，在数据量再增加达到前几个库/表的上限时，则继续水平增加库表，原先的数据就不需要迁移了。但是这样的方式会带来一个 热点问题：当前的数据量达到某个库表的范围时，所有的插入操作，都集中在这个库/表了。 所以在满足基本业务功能的前提下，分库分表方案应该尽量避免的两个问题： 数据迁移 热点 如何既能避免数据迁移又能避免插入更新的热点问题呢？ 结合离散分库/分表和连续分库/分表的优点，如果一定要写热点和新数据均匀分配在每个库，同时又保证易于水平扩展，可以考虑这样的模式： 水平扩展scale-out方案 -- 模式一 阶段一 一个库 DB0 之内分4个表，id%4 ： 阶段二 增加 DB1 库，t2和t3整表搬迁到 DB1 阶段三 增加 DB2 和 DB3 库，t1 整表搬迁到 DB2 ，t3整表搬迁的 DB3： 为了规则表达，通过内部名称映射或其他方式，我们将DB1和DB2的名称和位置互换得到下图： dbRule: “DB” + (id % 4) tbRule: “t” + (id % 4) 即逻辑上始终保持4库4表，每个表一个库。这种做法也是目前店铺线图片空间采用的做法。 上述方案有一个缺点，就是在从一个库到 4 个库的过程中，单表的数据量一直在增长。当单表的数据量超过一定范围时，可能会带来性能问题。比如索引的问题，历史数据清理的问题。另外当开始预留的表个数用尽，到了 4 物理库每库 1 个表的阶段，再进行扩容的话，不可避免的要从表上下手。 水平扩展scale-out方案 -- 模式二 阶段一 一个数据库，两个表，rule0 = id % 2 分库规则dbRule: “DB0″ 分表规则tbRule: “t” + (id % 2) 阶段二 当单库的数据量接近 1千万，单表的数据量接近 500 万时，进行扩容（数据量只是举例，具体扩容量要根据数据库和实际压力状况决定）：增加一个数据库 DB1，将 DB0.t0 整表迁移到新库 DB1.t1。每个库各增加1个表，未来10M-20M的数据mod2分别写入这2个表：t0_1，t1_1： 分库规则dbRule: “DB” + (id % 2) 分表规则tbRule: if(id 这样 10M 以后的新生数据会均匀分布在 DB0 和 DB1; 插入更新和查询热点仍然能够在每个库中均匀分布。每个库中同时有老数据和不断增长的新数据。每表的数据仍然控制在 500万 以下。 阶段三 当两个库的容量接近上限继续水平扩展时，进行如下操作： 新增加两个库：DB2和DB3，以id % 4分库。余数0、1、2、3分别对应DB的下标. t0和t1不变， 将DB0.t0_1整表迁移到DB2; 将DB1.t1_1整表迁移到DB3 20M-40M的数据 mod4 分为 4 个表：t0_2，t1_2，t2_2，t3_2，分别放到4个库中： 新的分库分表规则如下： 分库规则dbRule: if(id 分表规则tbRule: if(id 随着时间的推移，当第一阶段的t0/t1，第二阶段的t0_1/t1_1逐渐成为历史数据，不再使用时，可以直接truncate掉整个表。省去了历史数据迁移的麻烦。 水平扩展scale-out方案 -- 模式三 非倍数扩展：如果从上文的阶段二到阶段三不希望一下增加两个库呢？尝试如下方案： 迁移前： 新增库为DB2，t0、t1都放在 DB0， t0_1整表迁移到 DB1 t1_1整表迁移到 DB2 迁移后： 这时 DB0 退化为旧数据的读库和更新库。新增数据的热点均匀分布在 DB1 和 DB2 4无法整除3，因此如果从4表2库扩展到3个库，不做行级别的迁移而又保证热点均匀分布看似无法完成。 当然如果不限制每库只有两个表，也可以如下实现： 小于 10M 的 t0 和 t1 都放到 DB0 ，以 mod2 分为两个表，原数据不变 10M-20M的，以 mod2 分为两个表 t0_1、t1_1，原数据不变，分别搬迁到 DB1 ，和 DB2 20M 以上的以 mod3 平均分配到 3 个 DB 库的 t_0、t_2、t_3表中 这样 DB1 包含最老的两个表，和最新的 1/3 数据。DB1 和 DB2 都分表包含次新的两个旧表 t0_1、t1_1 和最新的 1/3 数据。新旧数据读写都可达到均匀分布。 总结 总而言之，两种规则映射（函数）： 离散映射：如mod或dayofweek， 这种类型的映射能够很好的解决热点问题，但带来了数据迁移和历史数据问题。 连续映射；如按id或gmt_create_time的连续范围做映射。这种类型的映射可以避免数据迁移，但又带来热点问题。 离散映射和连续映射这两种相辅相成的映射规则，正好解决热点和迁移这一对相互矛盾的问题。 我们之前只运用了离散映射，引入连续映射规则后，两者结合，精心设计，应该可以设计出满足避免热点和减少迁移之间任意权衡取舍的规则。 基于以上考量，分库分表规则的设计和配置，长远说来必须满足以下要求 可以动态推送修改 规则可以分层级叠加，旧规则可以在新规则下继续使用，新规则是旧规则在更宽尺度上的拓展，以此支持新旧规则的兼容，避免数据迁移 用 mod 方式时，最好选 2 的指数级倍分库分表，这样方便以后切割。 分库分表后全局ID怎么做 数据库自增 id 设置数据库 sequence 或者表自增字段步长 UUID 获取系统当前时间 snowflake 算法 snowflake twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id ，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id ，12 bit 作为序列号。 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。 41 bit：表示的是时间戳，单位是毫秒。41 bit 可以表示的数字多达 2^41 - 1，也就是可以标识 2^41 - 1 个毫秒值，换算成年就是表示69年的时间。 10 bit：记录工作机器 id，代表的是这个服务最多可以部署在 2^10台机器上哪，也就是1024台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 2^5个机房（32个机房），每个机房里可以代表 2^5 个机器（32台机器）。 12 bit：这个是用来记录同一个毫秒内产生的不同 id，12 bit 可以代表的最大正整数是 2^12 - 1 = 4096，也就是说可以用这个 12 bit 代表的数字来区分同一个毫秒内的 4096 个不同的 id。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/4-database/6-concurrent_control.html":{"url":"basic/4-database/6-concurrent_control.html","title":"并发控制","keywords":"","body":"并发控制 如果数据库中的所有事务都是串行执行的，那么它非常容易成为整个应用的性能瓶颈，虽然说没法水平扩展的节点在最后都会成为瓶颈，但是串行执行事务的数据库会加速这一过程；而并发（Concurrency）使一切事情的发生都有了可能，它能够解决一定的性能问题，但是它会带来更多诡异的错误。 引入了并发事务之后，如果不对事务的执行进行控制就会出现各种各样的问题，你可能没有享受到并发带来的性能提升就已经被各种奇怪的问题折磨的欲仙欲死了。 如何控制并发是数据库领域中非常重要的问题之一，不过到今天为止事务并发的控制已经有了很多成熟的解决方案，而这些方案的原理就是这篇文章想要介绍的内容，最为常见的三种并发控制机制： 悲观并发控制：悲观并发控制其实是最常见的并发控制机制，也就是锁 乐观并发控制：即乐观锁，乐观锁其实并不是一种真实存在的锁 多版本并发控制（MVCC）：与前两者对立的命名不同，MVCC 可以与前两者中的任意一种机制结合使用，以提高数据库的读性能 悲观并发控制 控制不同的事务对同一份数据的获取是保证数据库的一致性的最根本方法，如果我们能够让事务在同一时间对同一资源有着独占的能力，那么就可以保证操作同一资源的不同事务不会相互影响。 最简单的、应用最广的方法就是使用锁来解决，当事务需要对资源进行操作时需要先获得资源对应的锁，保证其他事务不会访问该资源后，再对资源进行各种操作；在悲观并发控制中，数据库程序对于数据被修改持悲观的态度，在数据处理的过程中都会被锁定，以此来解决竞争的问题。 读写锁 为了最大化数据库事务的并发能力，数据库中的锁被设计为两种模式，分别是 共享锁和互斥锁。当一个事务获得共享锁之后，它只可以进行读操作，所以共享锁也叫 读锁 ；而当一个事务获得一行数据的互斥锁时，就可以对该行数据进行读和写操作，所以互斥锁也叫 写锁 。 共享锁和互斥锁除了限制事务能够执行的读写操作之外，它们之间还有『共享』和『互斥』的关系，也就是多个事务可以同时获得某一行数据的共享锁，但是互斥锁与共享锁和其他的互斥锁并不兼容 如果当前事务没有办法获取该行数据对应的锁时就会陷入等待的状态，直到其他事务将当前数据对应的锁释放才可以获得锁并执行相应的操作。 两阶段锁协议 两阶段锁协议（2PL）是一种能够保证事务可串行化的协议，它将事务的获取锁和释放锁划分成了增长（Growing）和缩减（Shrinking）两个不同的阶段。 在增长阶段，一个事务可以获得锁但是不能释放锁；而在缩减阶段事务只可以释放锁，并不能获得新的锁，如果只看 2PL 的定义，那么到这里就已经介绍完了，但是它还有两个变种： Strict 2PL：事务持有的 互斥锁 必须在提交后再释放； Rigorous 2PL：事务持有的 所有锁 必须在提交后释放； 虽然 锁的使用能够为我们解决不同事务之间由于并发执行造成的问题，但是两阶段锁的使用却引入了另一个严重的问题，死锁；不同的事务等待对方已经锁定的资源就会造成死锁，我们在这里举一个简单的例子： 两个事务在刚开始时分别获取了 draven 和 beacon 资源上面的锁，然后再请求对方已经获得的锁时就会发生死锁，双方都没有办法等到锁的释放，如果没有死锁的处理机制就会无限等待下去，两个事务都没有办法完成。 预防死锁 有两种方式可以帮助我们预防死锁的出现，一种是保证事务之间的等待不会出现环，也就是事务之间的等待图应该是一张有向无环图，没有循环等待的情况或者保证一个事务中想要获得的所有资源都在事务开始时以原子的方式被锁定，所有的资源要么被锁定要么都不被锁定。 但是这种方式有两个问题，在事务一开始时很难判断哪些资源是需要锁定的，同时因为一些很晚才会用到的数据被提前锁定，数据的利用率与事务的并发率也非常的低。一种解决的办法就是按照一定的顺序为所有的数据行加锁，同时与 2PL 协议结合，在加锁阶段保证所有的数据行都是从小到大依次进行加锁的，不过这种方式依然需要事务提前知道将要加锁的数据集。 另一种预防死锁的方法就是使用抢占加事务回滚的方式预防死锁，当事务开始执行时会先获得一个时间戳，数据库程序会根据事务的时间戳决定事务应该等待还是回滚。 锁的粒度 到目前为止我们都没有对不同粒度的锁进行讨论，一直以来我们都讨论的都是数据行锁，但是在有些时候我们希望将多个节点看做一个数据单元，使用锁直接将这个数据单元、表甚至数据库锁定起来。这个目标的实现需要我们在数据库中定义不同粒度的锁： 当我们拥有了不同粒度的锁之后，如果某个事务想要锁定整个数据库或者整张表时只需要简单的锁住对应的节点就会在当前节点加上显示（explicit）锁，在所有的子节点上加隐式（implicit）锁；虽然这种不同粒度的锁能够解决父节点被加锁时，子节点不能被加锁的问题，但是我们没有办法在子节点被加锁时，立刻确定父节点不能被加锁。 在这时我们就需要引入 意向锁 来解决这个问题了，当需要给子节点加锁时，先给所有的父节点加对应的意向锁，意向锁之间是完全不会互斥的，只是用来帮助父节点快速判断是否可以对该节点进行加锁： 这里是一张引入了两种意向锁，意向共享锁 和 意向互斥锁 之后所有的锁之间的兼容关系；到这里，我们通过不同粒度的锁和意向锁加快了数据库的吞吐量。 乐观并发控制 除了悲观并发控制机制 - 锁之外，我们其实还有其他的并发控制机制，乐观并发控制（Optimistic Concurrency Control）。乐观并发控制也叫乐观锁，但是它并不是真正的锁，很多人都会误以为乐观锁是一种真正的锁，然而它只是一种并发控制的思想。 基于时间戳的协议 锁协议按照不同事务对同一数据项请求的时间依次执行，因为后面执行的事务想要获取的数据已将被前面的事务加锁，只能等待锁的释放，所以基于锁的协议执行事务的顺序与获得锁的顺序有关。在这里想要介绍的 基于时间戳的协议能够在事务执行之前先决定事务的执行顺序。 每一个事务都会具有一个全局唯一的时间戳，它即可以使用系统的时钟时间，也可以使用计数器，只要能够保证所有的时间戳都是唯一并且是随时间递增的就可以。 基于时间戳的协议能够保证事务并行执行的顺序与事务按照时间戳串行执行的效果完全相同；每一个数据项都有两个时间戳，读时间戳和写时间戳，分别代表了当前成功执行对应操作的事务的时间戳。 该协议能够保证所有冲突的读写操作都能按照时间戳的大小串行执行，在执行对应的操作时不需要关注其他的事务只需要关心数据项对应时间戳的值就可以了： 无论是读操作还是写操作都会从左到右依次比较读写时间戳的值，如果小于当前值就会直接被拒绝然后回滚，数据库系统会给回滚的事务添加一个新的时间戳并重新执行这个事务。 基于验证的协议 乐观并发控制其实本质上就是基于验证的协议，因为在多数的应用中只读的事务占了绝大多数，事务之间因为写操作造成冲突的可能非常小，也就是说大多数的事务在不需要并发控制机制也能运行的非常好，也可以保证数据库的一致性；而 并发控制机制其实向整个数据库系统添加了很多的开销，我们其实可以通过别的策略降低这部分开销。 而验证协议就是我们找到的解决办法，它根据事务的只读或者更新将所有事务的执行分为两到三个阶段： 在读阶段，数据库会执行事务中的 全部读操作和写操作，并将所有写后的值存入临时变量中，并不会真正更新数据库中的内容；在这时候会进入下一个阶段，数据库程序会检查当前的改动是否合法，也就是是否有其他事务在 RAED PHASE 期间更新了数据，如果通过测试那么直接就进入 WRITE PHASE 将所有存在临时变量中的改动全部写入数据库，没有通过测试的事务会直接被终止。 为了保证乐观并发控制能够正常运行，我们需要知道一个事务不同阶段的发生时间，包括事务开始时间、验证阶段的开始时间以及写阶段的结束时间；通过这三个时间戳，我们可以保证任意冲突的事务不会同时写入数据库，一旦由一个事务完成了验证阶段就会立即写入，其他读取了相同数据的事务就会回滚重新执行。 作为乐观的并发控制机制，它会假定所有的事务在最终都会通过验证阶段并且执行成功，而锁机制和基于时间戳排序的协议是悲观的，因为它们会在发生冲突时强制事务进行等待或者回滚，哪怕有不需要锁也能够保证事务之间不会冲突的可能。 多版本并发控制 -- MVCC 到目前为止我们介绍的 并发控制机制其实都是通过延迟或者终止相应的事务来解决事务之间的竞争条件（Race condition）来保证事务的可串行化；虽然前面的两种并发控制机制确实能够从根本上解决并发事务的可串行化的问题，但是在实际环境中数据库的事务大都是只读的，读请求是写请求的很多倍，如果写请求和读请求之前没有并发控制机制，那么最坏的情况也是读请求读到了已经写入的数据，这对很多应用完全是可以接受的。 在这种大前提下，数据库系统引入了另一种并发控制机制 - 多版本并发控制（Multiversion Concurrency Control），每一个写操作都会创建一个新版本的数据，读操作会从有限多个版本的数据中挑选一个最合适的结果直接返回；在这时，读写操作之间的冲突就不再需要被关注，而 管理和快速挑选数据的版本就成了 MVCC 需要解决的主要问题。 MVCC 并不是一个与乐观和悲观并发控制对立的东西，它能够与两者很好的结合以增加事务的并发量，在目前最流行的 SQL 数据库 MySQL 和 PostgreSQL 中都对 MVCC 进行了实现；但是由于它们分别实现了悲观锁和乐观锁，所以 MVCC 实现的方式也不同。 MVCC vs 乐观锁 MVCC 可以保证不阻塞地读到一致的数据。但是，MVCC 并没有对实现细节做约束，为此不同的数据库的语义有所不同，比如： postgres 对写操作也是乐观并发控制；在表中保存同一行数据记录的多个不同版本，每次写操作，都是创建，而回避更新；在事务提交时，按版本号检查当前事务提交的数据是否存在写冲突，则抛异常告知用户，回滚事务； innodb 则只对读无锁，写操作仍是上锁的悲观并发控制，这也意味着，innodb 中只能见到因死锁和不变性约束而回滚，而见不到因为写冲突而回滚，不像 postgres 那样对数据修改在表中创建新纪录，而是每行数据只在表中保留一份，在更新数据时上行锁，同时将旧版数据写入 undo log。表和 undo log 中行数据都记录着事务ID，在检索时，只读取来自当前已提交的事务的行数据。 可见 MVCC 中的写操作仍可以按悲观并发控制实现，而 CAS 的写操作只能是乐观并发控制。还有一个不同在于，MVCC 在语境中倾向于 “对多行数据打快照造平行宇宙”，然而 CAS 一般只是保护单行数据而已。比如 mongodb 有 CAS 的支持，但不能说这是 MVCC。 MySQL 与 MVCC MySQL 中实现的多版本两阶段锁协议（Multiversion 2PL）将 MVCC 和 2PL 的优点结合了起来，每一个版本的数据行都具有一个唯一的时间戳，当有读事务请求时，数据库程序会直接从多个版本的数据项中具有最大时间戳的返回。 更新操作就稍微有些复杂了，事务会先读取最新版本的数据计算出数据更新后的结果，然后创建一个新版本的数据，新数据的时间戳是目前数据行的最大版本 ＋1： 数据版本的删除也是根据时间戳来选择的， MySQL 会将版本最低的数据定时从数据库中清除以保证不会出现大量的遗留内容。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/4-database/8-innodb.html":{"url":"basic/4-database/8-innodb.html","title":"Innodb","keywords":"","body":"InnoDB 数据存储 MySQL 存储格式可通过 SQL：SHOW TABLE STATUS IN {dbName} 查看 与现有的大多数存储引擎一样，InnoDB 使用页作为磁盘管理的最小单位；数据在 InnoDB 存储引擎中都是按行存储的，每个 16KB 大小的页中可以存放 2-200 行的记录。 当 InnoDB 存储数据时，它可以使用不同的行格式进行存储；MySQL 5.7 版本支持以下格式的行存储方式： Antelope 是 InnoDB 最开始支持的文件格式，它包含两种行格式 Compact 和 Redundant ，它最开始并没有名字； Antelope 的名字是在新的文件格式 Barracuda 出现后才起的， Barracuda 的出现引入了两种新的行格式 Compressed 和 Dynamic ；InnoDB 对于文件格式都会向前兼容，而官方文档中也对之后会出现的新文件格式预先定义好了名字：Cheetah、Dragon、Elk 等等。 两种行记录格式 Compact 和 Redundant 在磁盘上按照以下方式存储： Compact 和 Redundant 格式最大的不同就是记录格式的第一个部分；在 Compact 中，行记录的第一部分倒序存放了一行数据中列的长度（Length），而 Redundant 中存的是每一列的偏移量（Offset），从总体上上看， Compact 行记录格式相比 Redundant 格式能够减少 20% 的存储空间。 行溢出数据 当 InnoDB 使用 Compact 或者 Redundant 格式存储极长的 VARCHAR 或者 BLOB 这类大对象时，我们并不会直接将所有的内容都存放在数据页节点中，而是将行数据中的前 768 个字节存储在数据页中，后面会通过偏移量指向溢出页。 但是当我们使用新的行记录格式 Compressed 或者 Dynamic 时都只会在行记录中保存 20 个字节的指针，实际的数据都会存放在溢出页面中。 当然在实际存储中，可能会对不同长度的 TEXT 和 BLOB 列进行优化。 想要了解更多与 InnoDB 存储引擎中记录的数据格式的相关信息，可以阅读 InnoDB Record Structure 数据页结构 页是 InnoDB 存储引擎管理数据的最小磁盘单位，而 B-Tree 节点就是实际存放表中数据的页面，我们在这里将要介绍页是如何组织和存储记录的；首先，一个 InnoDB 页有以下七个部分： 每一个页中包含了两对 header/trailer：内部的 Page Header/Page Directory 关心的是页的状态信息，而 Fil Header/Fil Trailer 关心的是记录页的头信息。 在页的头部和尾部之间就是用户记录和空闲空间了，每一个数据页中都包含 Infimum 和 Supremum 这两个虚拟的记录（可以理解为占位符）， Infimum 记录是比该页中任何主键值都要小的值， Supremum 是该页中的最大值： User Records 就是整个页面中真正用于存放行记录的部分，而 Free Space 就是空余空间了，它是一个链表的数据结构，为了保证插入和删除的效率，整个页面并不会按照主键顺序对所有记录进行排序，它会自动从左侧向右寻找空白节点进行插入，行记录在物理存储上并不是按照顺序的，它们之间的顺序是由 next_record 这一指针控制的。 B+ 树在查找对应的记录时，并不会直接从树中找出对应的行记录，它只能获取记录所在的页，将整个页加载到内存中，再通过 Page Directory 中存储的稀疏索引和 n_owned、next_record 属性取出对应的记录，不过因为这一操作是在内存中进行的，所以通常会忽略这部分查找的耗时。 索引 索引是数据库中非常非常重要的概念，它是存储引擎能够快速定位记录的秘密武器，对于提升数据库的性能、减轻数据库服务器的负担有着非常重要的作用；索引优化是对查询性能优化的最有效手段，它能够轻松地将查询的性能提高几个数量级。 InnoDB 存储引擎在绝大多数情况下使用 B+ 树建立索引，这是关系型数据库中查找最为常用和有效的索引，但是 B+ 树索引并不能找到一个给定键对应的具体值，它只能找到数据行对应的页，然后正如上一节所提到的，数据库把整个页读入到内存中，并在内存中查找具体的数据行。 B+ 树是平衡树，它查找任意节点所耗费的时间都是完全相同的，比较的次数就是 B+ 树的高度； B+ 树的叶子节点存放所有指向关键字的指针，节点内部关键字记录和节点之间都根据关键字的大小排列。当顺序递增插入的时候，只有最后一个节点会在满掉的时候引起索引分裂，此时无需移动记录，只需创建一个新的节点即可。而当非递增插入的时候，会使得旧的节点分裂，还可能伴随移动记录，以便使得新数据能够插入其中。一般建议使用一列顺序递增的 ID 来作为主键，但不必是数据库的 autoincrement 字段，只要满足顺序增加即可，如 twitter 的 snowflake 即为顺序递增的 ID 生成器。 聚集索引和辅助索引 数据库中的 B+ 树索引可以分为聚集索引（clustered index）和辅助索引（secondary index），它们之间的最大区别就是，聚集索引中存放着一条行记录的全部信息，而辅助索引中只包含索引列和一个用于查找对应行记录的『书签』。 聚集索引 InnoDB 存储引擎中的表都是使用索引组织的，也就是按照键的顺序存放；聚集索引就是按照表中主键的顺序构建一颗 B+ 树，并在叶节点中存放表中的行记录数据。 如果没有定义主键，则会使用非空的 UNIQUE键 做主键 ; 如果没有非空的 UNIQUE键 ，则系统生成一个6字节的 rowid 做主键; CREATE TABLE users( id INT NOT NULL, first_name VARCHAR(20) NOT NULL, last_name VARCHAR(20) NOT NULL, age INT NOT NULL, PRIMARY KEY(id), KEY(last_name, first_name, age) KEY(first_name) ); 如果使用上面的 SQL 在数据库中创建一张表，B+ 树就会使用 id 作为索引的键，并在叶子节点中存储一条记录中的所有信息。 图中对 B+ 树的描述与真实情况下 B+ 树中的数据结构有一些差别，不过这里想要表达的主要意思是：聚集索引叶节点中保存的是整条行记录，而不是其中的一部分。 聚集索引与表的物理存储方式有着非常密切的关系，所有正常的表应该 有且仅有一个 聚集索引（绝大多数情况下都是主键），表中的所有行记录数据都是按照 聚集索引 的顺序存放的。 当我们使用聚集索引对表中的数据进行检索时，可以直接获得聚集索引所对应的整条行记录数据所在的页，不需要进行第二次操作。 辅助索引 数据库将 所有的非聚集索引都划分为辅助索引，但是这个概念对我们理解辅助索引并没有什么帮助；辅助索引也是通过 B+ 树实现的，但是它的叶节点并不包含行记录的全部数据，仅包含索引中的所有键和一个用于查找对应行记录的『书签』，在 InnoDB 中这个书签就是当前记录的主键。 辅助索引的存在并不会影响聚集索引，因为聚集索引构成的 B+ 树是数据实际存储的形式，而辅助索引只用于加速数据的查找，所以一张表上往往有多个辅助索引以此来提升数据库的性能。 一张表一定包含一个聚集索引构成的 B+ 树以及若干辅助索引的构成的 B+ 树。 如果在表 users 中存在一个辅助索引 (first_name, age)，那么它构成的 B+ 树大致就是上图这样，按照 (first_name, age) 的字母顺序对表中的数据进行排序，当查找到主键时，再通过聚集索引获取到整条行记录。 上图展示了一个使用辅助索引查找一条表记录的过程：通过辅助索引查找到对应的主键，最后在聚集索引中使用主键获取对应的行记录，这也是通常情况下行记录的查找方式。 InnoDB 锁机制 InnoDB默认使用行锁，实现了两种标准的行锁——共享锁与排他锁； 行锁类型 锁功能 锁兼容性 加锁 释放锁 共享锁（读锁、S锁） 允许获取共享锁的亊务读数据 与共享锁兼容，与排它锁不兼容 只有 SerializaWe 隔离级别会默认为：读加共享锁；其他隔离级别下，可显示使用 select...lock in share model 为读加共享锁 在事务提交或回滚后会自动同时释放锁；除了使用 start transaction 的方式显式开启事务，InnoDB 也会自动为增删改査语句开启事务，并自动提交或回滚；(autocommit=1) 排它锁（写锁、X锁） 允许获取排它锁的事务更新或删除数据 与共享锁不兼容，与排它锁不兼容 在默认的 Reapeatable Read 隔离级别下，InnoDB 会自动为增删改操作的行加排它锁；也可显式使用 select...for update 为读加排它锁 ... 除了显式加锁的情况，其他情况下的加锁与解锁都无需人工干预 InnoDB 所有的行锁算法都是基于索引实现的，锁定的也都是索引或索引区间 当前读 & 快照读 当前读：即加锁读，读取记录的最新版本，会加锁保证其他并发事务不能修改当前记录，直至获取锁的事务释放锁；使用当前读的操作主要包括：显式加锁的读操作与插入/更新/删除等写操作，如下所示： select * from table where ? lock in share mode; select * from table where ? for update; insert into table values (…); update table set ? where ?; delete from table where ?; 注：当 Update SQL 被发给 MySQL 后， MySQL Server 会根据where条件，读取第一条满足条件的记录，然后 InnoDB 引擎会将第一条记录返回，并加锁，待 MySQL Server 收到这条加锁的记录之后，会再发起一个 Update 请求，更新这条记录。一条记录操作完成，再读取下一条记录，直至没有满足条件的记录为止。因此， Update 操作内部，就包含了当前读。同理， Delete 操作也一样。 Insert 操作会稍微有些不同，简单来说，就是 Insert 操作可能会触发 Unique Key 的冲突检查，也会进行一个当前读。 快照读：即不加锁读，读取记录的快照版本而非最新版本，通过MVCC实现； InnoDB 默认的 RR 事务隔离级别下，不显式加lock in share mode与for update的 select 操作都属于快照读，保证事务执行过程中只有第一次读之前提交的修改和自己的修改可见，其他的均不可见； 共享锁与独占锁 意向锁 InnoDB 支持多粒度的锁，允许表级锁和行级锁共存。一个类似于 LOCK TABLES ... WRITE 的语句会获得这个表的 x 锁。为了实现多粒度锁，InnoDB 使用了意向锁（简称 I 锁）。I 锁是表明一个事务稍后要获得针对一行记录的某种锁（s or x）的对应表的表级锁，有两种： 意向排它锁（简称 IX 锁）表明一个事务意图在某个表中设置某些行的 x 锁 意向共享锁（简称 IS 锁）表明一个事务意图在某个表中设置某些行的 s 锁 SELECT ... LOCK IN SHARE MODE 设置一个 IS 锁, SELECT ... FOR UPDATE 设置一个 IX 锁。意向锁的原则如下： 一个事务必须先持有该表上的 IS 或者更强的锁才能持有该表中某行的 S 锁 一个事务必须先持有该表上的 IX 锁才能持有该表中某行的 X 锁 新请求的锁只有兼容已有锁才能被允许，否则必须等待不兼容的已有锁被释放。一个不兼容的锁请求不被允许是因为它会引起死锁，错误会发生。意向锁只会阻塞全表请求（比如 LOCK TABLES ... WRITE ）。意向锁的主要目的是展示某人正在锁定表中一行，或者将要锁定一行。 更多信息参见：并发控制 Record Lock 记录锁（Record Lock）是加到索引记录上的锁，假设我们存在下面的一张表 users： CREATE TABLE users( id INT NOT NULL AUTO_INCREMENT, last_name VARCHAR(255) NOT NULL, first_name VARCHAR(255), age INT, PRIMARY KEY(id), KEY(last_name), KEY(age) ); 如果我们使用 id 或者 last_name 作为 SQL 中 WHERE 语句的过滤条件，那么 InnoDB 就可以通过索引建立的 B+ 树找到行记录并添加索引，但是如果使用 first_name 作为过滤条件时，由于 InnoDB 不知道待修改的记录具体存放的位置，也无法对将要修改哪条记录提前做出判断就会锁定整个表。 Gap Lock 记录锁是在存储引擎中最为常见的锁，除了记录锁之外，InnoDB 中还存在间隙锁（Gap Lock），间隙锁是对索引记录中的一段连续区域的锁；当使用类似 SELECT * FROM users WHERE id BETWEEN 10 AND 20 FOR UPDATE; 的 SQL 语句时，就会阻止其他事务向表中插入 id = 15 的记录，因为整个范围都被间隙锁锁定了。 间隙锁是存储引擎对于性能和并发做出的权衡，并且只用于某些事务隔离级别。 虽然间隙锁中也分为共享锁和互斥锁，不过它们之间并不是互斥的，也就是不同的事务可以同时持有一段相同范围的共享锁和互斥锁，它唯一阻止的就是其他事务向这个范围中添加新的记录。 间隙锁的缺点 间隙锁有一个比较致命的弱点，就是当锁定一个范围键值之后，即使某些不存在的键值也会被无辜的锁定，而造成在锁定的时候无法插入锁定键值范围内的任何数据。在某些场景下这可能会对性能造成很大的危害 当Query无法利用索引的时候， Innodb会放弃使用行级别锁定而改用表级别的锁定，造成并发性能的降低； 当Quuery使用的索引并不包含所有过滤条件的时候，数据检索使用到的索引键所指向的数据可能有部分并不属于该Query的结果集的行列，但是也会被锁定，因为间隙锁锁定的是一个范围，而不是具体的索引键； 当Query在使用索引定位数据的时候，如果使用的索引键一样但访问的数据行不同的时候（索引只是过滤条件的一部分），一样会被锁定 Next-Key Lock Next-Key 锁相比前两者就稍微有一些复杂，它是记录锁和记录前的间隙锁的结合，在 users 表中有以下记录： +------|-------------|--------------|-------+ | id | last_name | first_name | age | |------|-------------|--------------|-------| | 4 | stark | tony | 21 | | 1 | tom | hiddleston | 30 | | 3 | morgan | freeman | 40 | | 5 | jeff | dean | 50 | | 2 | donald | trump | 80 | +------|-------------|--------------|-------+ 如果使用 Next-Key 锁，那么 Next-Key 锁就可以在需要的时候锁定以下的范围： (-∞, 21] (21, 30] (30, 40] (40, 50] (50, 80] (80, ∞) 既然叫 Next-Key 锁，锁定的应该是当前值和后面的范围，但是实际上却不是，Next-Key 锁锁定的是当前值和前面的范围。 当我们更新一条记录，比如 SELECT * FROM users WHERE age = 30 FOR UPDATE;，InnoDB 不仅会在范围 (21, 30] 上加 Next-Key 锁，还会在这条该记录索引增长方向的范围 (30, 40] 加间隙锁，所以插入 (21, 40] 范围内的记录都会被锁定。 Next-Key 锁的作用其实是为了解决幻读的问题。 插入意向锁 插入意向锁是在插入一行记录操作之前设置的一种间隙锁，这个锁释放了一种插入方式的信号，亦即多个事务在相同的索引间隙插入时如果不是插入间隙中相同的位置就不需要互相等待。假设有索引值4、7，几个不同的事务准备插入5、6，每个锁都在获得插入行的独占锁之前用插入意向锁各自锁住了4、7之间的间隙，但是不阻塞对方因为插入行不冲突。 自增锁 自增锁是一个特殊的表级锁，事务插入自增列的时候需要获取，最简单情况下如果一个事务插入一个值到表中，任何其他事务都要等待，这样第一个事物才能获得连续的主键值。 锁选择 +——-+————-+ | id | name | +——-+————-+ | 1 | title1 | +——-+————-+ | 2 | title2 | +——-+————-+ | 3 | title3 | +——-+————-+ | 9 | title9 | +——-+————-+ | 10 | title10 | +——-+————-+ 按照原理来说，id>5 and id这个查询条件，在表中找不到满足条件的项，因此会对第一个不满足条件的项(id = 9)上加GAP锁，防止后续其他事务插入满足条件的记录。 而 GAP 锁与GAP 锁是不冲突的，那么为什么两个同时执行id>5 and id查询的事务会冲突呢？ 原因在于，MySQL Server并没有将id这个查询条件下降到InnoDB引擎层，因此InnoDB看到的查询，是id>5，正向扫描。读出的记录id=9，先加上next key锁(Lock X + GAP lock)，然后返回给 MySQL Server 进行判断。 MySQL Server 此时才会判断返回的记录是否满足id的查询条件。此处不满足，查询结束。 因此，id=9记录上，真正持有的锁是next key锁，而next key锁之间是相互冲突的，这也说明了为什么两个id>5 and id查询的事务会冲突的原因。 InnoDB 事务隔离 几种隔离级别 事务的隔离性是数据库处理数据的几大基础之一，而隔离级别其实就是提供给用户用于在性能和可靠性做出选择和权衡的配置项。 ISO 和 ANIS SQL 标准制定了四种事务隔离级别，而 InnoDB 遵循了 SQL:1992 标准中的四种隔离级别：READ UNCOMMITED、READ COMMITED、REPEATABLE READ 和 SERIALIZABLE；每个事务的隔离级别其实都比上一级多解决了一个问题： RAED UNCOMMITED：使用查询语句不会加锁，可能会读到未提交的行（Dirty Read）； 可以读取未提交记录。此隔离级别，不会使用，忽略。 READ COMMITED：只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近，所以再多次使用查询语句时，可能得到不同的结果（Non-Repeatable Read）； 快照读忽略，本文不考虑。针对当前读，RC隔离级别保证对读取到的记录加锁 (记录锁)，存在幻读现象。 REPEATABLE READ：快照读忽略，本文不考虑。针对当前读，RR隔离级别保证对读取到的记录加锁 (记录锁)，同时保证对读取的范围加锁，新的满足查询条件的记录不能够插入 (间隙锁)，不存在幻读现象。 SERIALIZABLE：从MVCC并发控制退化为基于锁的并发控制。不区别快照读与当前读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。 Serializable隔离级别下，读写冲突，因此并发度急剧下降，在MySQL/InnoDB下不建议使用。 MySQL 中默认的事务隔离级别就是 REPEATABLE READ，但是它通过 Next-Key 锁也能够在某种程度上解决幻读的问题。 接下来，我们将数据库中创建如下的表并通过个例子来展示在不同的事务隔离级别之下，会发生什么样的问题： CREATE TABLE test( id INT NOT NULL, UNIQUE(id) ); 脏读 在一个事务中，读取了其他事务未提交的数据。 当事务的隔离级别为 READ UNCOMMITED 时，我们在 SESSION 2 中插入的未提交数据在 SESSION 1 中是可以访问的。 不可重复读 在一个事务中，同一行记录被访问了两次却得到了不同的结果。 当事务的隔离级别为 READ COMMITED 时，虽然解决了脏读的问题，但是如果在 SESSION 1 先查询了一行数据，在这之后 SESSION 2 中修改了同一行数据并且提交了修改，在这时，如果 SESSION 1 中再次使用相同的查询语句，就会发现两次查询的结果不一样。 不可重复读的原因就是，在 READ COMMITED 的隔离级别下，存储引擎不会在查询记录时添加行锁，锁定 id = 3 这条记录。 幻读 在一个事务中，同一个范围内的记录被读取时，其他事务向这个范围添加了新的记录。 重新开启了两个会话 SESSION 1 和 SESSION 2，在 SESSION 1 中我们查询全表的信息，没有得到任何记录；在 SESSION 2 中向表中插入一条数据并提交；由于 REPEATABLE READ 的原因，再次查询全表的数据时，我们获得到的仍然是空集，但是在向表中插入同样的数据却出现了错误。 这种现象在数据库中就被称作幻读，虽然我们使用查询语句得到了一个空的集合，但是插入数据时却得到了错误，好像之前的查询是幻觉一样。 在标准的事务隔离级别中，幻读是由更高的隔离级别 SERIALIZABLE 解决的，但是它也可以通过 MySQL 提供的 Next-Key 锁解决： REPEATABLE READ 和 READ UNCOMMITED 其实是矛盾的，如果保证了前者就看不到已经提交的事务，如果保证了后者，就会导致两次查询的结果不同，MySQL 为我们提供了一种折中的方式，能够在 REPEATABLE READ 模式下加锁访问已经提交的数据，其本身并不能解决幻读的问题，而是通过文章前面提到的 Next-Key 锁来解决。 参考连接 『浅入浅出』MySQL 和 InnoDB 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/4-database/7-redis.html":{"url":"basic/4-database/7-redis.html","title":"Redis","keywords":"","body":"Redis 线程模型 Redis 在处理网络请求是使用单线程模型，并通过 IO 多路复用来提高并发。但是在其他模块，比如：持久化，会使用多个线程。 Redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket ，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。 文件事件处理器的结构包含 4 个部分： 多个 socket IO 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket ，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket ，根据 socket 的事件类型交给对应的事件处理器进行处理。 客户端与 redis 的一次通信过程： 为啥 redis 单线程模型也能效率这么高？ 纯内存操作 核心是基于非阻塞的 IO 多路复用机制 单线程反而避免了多线程的频繁上下文切换问题 数据结构 Redis的外围由一个键、值映射的字典构成。与其他非关系型数据库主要不同在于：Redis中值的类型不仅限于 字符串，还支持如下抽象数据类型： List：字符串列表 Set：无序不重复的字符串集合 Soret Set：有序不重复的字符串集合 HashTable：键、值都为字符串的哈希表 值的类型决定了值本身支持的操作。Redis支持不同无序、有序的列表，无序、有序的集合间的交集、并集等高级服务器端原子操作。 持久化： 使用快照，一种半持久耐用模式。不时的将数据集以异步方式从内存以RDB格式写入硬盘。 1.1版本开始使用更安全的 AOF 格式替代，一种只能追加的日志类型。将数据集修改操作记录起来。Redis 能够在后台对只可追加的记录作修改来避免无限增长的日志。 1. aof文件比rdb更新频率高，优先使用aof还原数据。 2. aof比rdb更安全也更大 3. rdb性能比aof好 4. 如果两个都配了优先加载AOF 一致性哈希算法 一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 K/n 个关键字重新映射，其中 K 是关键字的数量，n 是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。 一致哈希也可用于实现健壮缓存来减少大型 Web 应用中系统部分失效带来的负面影响 需求 在使用 n 台缓存服务器时，一种常用的负载均衡方式是，对资源 o 的请求使用 hash(o)= o mod n 来映射到某一台缓存服务器。当增加或减少一台缓存服务器时这种方式可能会改变所有资源对应的 hash 值，也就是所有的缓存都失效了，这会使得缓存服务器大量集中地向原始内容服务器更新缓存。 因此需要一致哈希算法来避免这样的问题。 一致哈希尽可能使同一个资源映射到同一台缓存服务器。这种方式要求增加一台缓存服务器时，新的服务器尽量分担存储其他所有服务器的缓存资源。减少一台缓存服务器时，其他所有服务器也可以尽量分担存储它的缓存资源。 一致哈希算法的主要思想是将每个缓存服务器与一个或多个哈希值域区间关联起来，其中区间边界通过计算缓存服务器对应的哈希值来决定。如果一个缓存服务器被移除，则它所对应的区间会被并入到邻近的区间，其他的缓存服务器不需要任何改变。 实现 一致哈希将每个对象映射到圆环边上的一个点，系统再将可用的节点机器映射到圆环的不同位置。查找某个对象对应的机器时，需要用一致哈希算法计算得到对象对应圆环边上位置，沿着圆环边上查找直到遇到某个节点机器，这台机器即为对象应该保存的位置。 当删除一台节点机器时，这台机器上保存的所有对象都要移动到下一台机器。添加一台机器到圆环边上某个点时，这个点的下一台机器需要将这个节点前对应的对象移动到新机器上。更改对象在节点机器上的分布可以通过调整节点机器的位置来实现。 实践 假设有1000w个数据项，100个存储节点，请设计一种算法合理地将他们存储在这些节点上。 看一看普通Hash算法的原理： for item in range(ITEMS): k = md5(str(item)).digest() h = unpack_from(\">I\", k)[0] # 通过取余的方式进行映射 n = h % NODES node_stat[n] += 1 普通的Hash算法均匀地将这些数据项打散到了这些节点上，并且分布最少和最多的存储节点数据项数目小于 1%。之所以分布均匀，主要是依赖 Hash 算法（实现使用的MD5算法）能够比较随机的分布。 然而，我们看看存在一个问题，由于 该算法使用节点数取余的方法，强依赖 node 的数目，因此，当是 node 数发生变化的时候，item 所对应的 node 发生剧烈变化，而发生变化的成本就是我们需要在 node 数发生变化的时候，数据需要迁移，这对存储产品来说显然是不能忍的。 一致性哈希 普通 Hash 算法的劣势，即当 node 数发生变化（增加、移除）后，数据项会被重新“打散”，导致大部分数据项不能落到原来的节点上，从而导致大量数据需要迁移。 那么，一个亟待解决的问题就变成了：当 node 数发生变化时，如何保证尽量少引起迁移呢？即当增加或者删除节点时，对于大多数 item ，保证原来分配到的某个 node ，现在仍然应该分配到那个 node ，将数据迁移量的降到最低。 for n in range(NODES): h = _hash(n) ring.append(h) ring.sort() hash2node[h] = n for item in range(ITEMS): h = _hash(item) n = bisect_left(ring, h) % NODES node_stat[hash2node[ring[n]]] += 1 虽然一致性Hash算法解决了节点变化导致的数据迁移问题，但是，数据项分布的均匀性很差。 主要是因为这 100 个节点 Hash 后，在环上分布不均匀，导致了每个节点实际占据环上的区间大小不一造成的。 改进 -- 虚节点 当我们将 node 进行哈希后，这些值并没有均匀地落在环上，因此，最终会导致，这些节点所管辖的范围并不均匀，最终导致了数据分布的不均匀。 for n in range(NODES): for v in range(VNODES): h = _hash(str(n) + str(v)) # 构造ring ring.append(h) # 记录hash所对应节点 hash2node[h] = n ring.sort() for item in range(ITEMS): h = _hash(str(item)) # 搜索ring上最近的hash n = bisect_left(ring, h) % (NODES*VNODES) node_stat[hash2node[ring[n]]] += 1 通过增加虚节点的方法，使得每个节点在环上所“管辖”更加均匀。这样就既保证了在节点变化时，尽可能小的影响数据分布的变化，而同时又保证了数据分布的均匀。也就是靠增加“节点数量”加强管辖区间的均匀。 集群 哨兵 -- Sentinel Redis-Sentinel 是 Redis 官方推荐的 高可用性( HA )解决方案，当用 Redis 做 Master-slave 的高可用方案时，假如 master 宕机了， Redis 本身(包括它的很多客户端)都没有实现自动进行主备切换，而 Redis-sentinel 本身也是一个独立运行的进程，它能监控多个 master-slave 集群，发现 master 宕机后能进行自懂切换。 它的主要功能有以下几点 不时地监控 redis 是否按照预期良好地运行; 如果发现某个 redis 节点运行出现状况，能够通知另外一个进程(例如它的客户端); 能够进行自动切换。当一个 master 节点不可用时，能够选举出 master 的多个slave (如果有超过一个 slave 的话)中的一个来作为新的 master ,其它的 slave 节点会将它所追随的 master 的地址改为被提升为 master 的 slave 的新地址。 很显然，只使用单个 sentinel 进程来监控 redis 集群是不可靠的，当 sentinel 进程宕掉后( sentinel 本身也有单点问题，single-point-of-failure)整个集群系统将无法按照预期的方式运行。所以有必要将sentinel集群，这样有几个好处： 即使有一些sentinel进程宕掉了，依然可以进行redis集群的主备切换； 如果只有一个sentinel进程，如果这个进程运行出错，或者是网络堵塞，那么将无法实现redis集群的主备切换; 如果有多个sentinel，redis的客户端可以随意地连接任意一个sentinel来获得关于redis集群中的信息。 Redis Cluster Redis Cluster 是一种服务器 Sharding 技术，3.0版本开始正式提供。 Redis Cluster中，Sharding 采用 slot(槽) 的概念，一共分成 16384 个槽，这有点儿类 pre sharding 思路。对于每个进入 Redis 的键值对，根据 key 进行散列，分配到这 16384 个 slot 中的某一个中。使用的hash算法也比较简单，就是 CRC16 后 16384 取模。要保证 16384 个槽对应的 node 都正常工作，如果某个 node 发生故障，那它负责的 slots 也就失效，整个集群将不能工作。 16384 = 2048 * 8 bit，2k 大小的 bit 数 为了增加集群的可访问性，官方推荐的方案是将 node 配置成 主从结构，即一个 master 主节点，挂 n 个 slave 从节点。这时，如果主节点失效，Redis Cluster 会根据选举算法从 slave 节点中选择一个上升为主节点，整个集群继续对外提供服务。 对客户端来说，整个 cluster 被看做是一个整体，客户端可以连接任意一个 node 进行操作，就像操作单一 Redis 实例一样，当客户端操作的 key 没有分配到该 node 上时，Redis 会返回转向指令，指向正确的 node ，这有点儿像浏览器页面的 302 redirect 跳转。 Redis Sharding 集群 Redis Sharding 是客户端 Sharding 的方案，其主要思想是采用哈希算法 将 Redis 数据的 key 进行散列，通过 hash 函数，特定的 key 会映射到特定的 Redis 节点上。这样，客户端就知道该向哪个 Redis 节点操作数据。 Jedis 的 Redis Sharding 实现具有如下特点： 采用一致性哈希算法(consistent hashing)，将key和节点name同时hashing，然后进行映射匹配，采用的算法是MURMUR_HASH。采用一致性哈希而不是采用简单类似哈希求模映射的主要原因是当增加或减少节点时，不会产生由于重新匹配造成的rehashing。一致性哈希只影响相邻节点key分配，影响量小。 为了避免一致性哈希只影响相邻节点造成节点分配压力， ShardedJedis 会对每个Redis 节点根据名字(没有，Jedis会赋予缺省名字)会 虚拟化出160个虚拟节点 进行散列。根据权重 weight ，也可虚拟化出160倍数的虚拟节点。用虚拟节点做映射匹配，可以在增加或减少 Redis 节点时，key 在各 Redis 节点移动再分配更均匀，而不是只有相邻节点受影响。 ShardedJedis 支持 keyTagPattern 模式，即抽取 key 的一部分 keyTag 做 sharding ，这样通过合理命名 key ，可以将一组相关联的key放入同一个 Redis 节点，这在避免跨节点访问相关数据时很重要。 string Redis 没有直接使用 C 语言传统的字符串表示（以空字符结尾的字符数组，以下简称 C 字符串）， 而是自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象类型， 并将 SDS 用作 Redis 的默认字符串表示。 在 Redis 里面， C 字符串只会作为字符串字面量（string literal）， 用在一些无须对字符串值进行修改的地方， 比如打印日志。 当 Redis 需要的不仅仅是一个字符串字面量， 而是一个可以被修改的字符串值时， Redis 就会使用 SDS 来表示字符串值： 比如在 Redis 的数据库里面， 包含字符串值的键值对在底层都是由 SDS 实现的。 C字符串 SDS 获取字符串长度的复杂度为 O(N) 。 获取字符串长度的复杂度为 O(1) 。 API 是不安全的，可能会造成缓冲区溢出。 API 是安全的，不会造成缓冲区溢出。 修改字符串长度 N 次必然需要执行 N 次内存重分配。 修改字符串长度 N 次最多需要执行 N 次内存重分配。 只能保存文本数据。 可以保存文本或者二进制数据。 可以使用所有 库中的函数。 可以使用一部分 库中的函数。 缓冲区溢出 因为 C 字符串不记录自身的长度， 所以 strcat 假定用户在执行这个函数时， 已经为 dest 分配了足够多的内存， 可以容纳 src 字符串中的所有内容， 而一旦这个假定不成立时， 就会产生缓冲区溢出。 举个例子， 假设程序里有两个在内存中紧邻着的 C 字符串 s1 和 s2 ， 其中 s1 保存了字符串 \"Redis\" ， 而 s2 则保存了字符串 \"MongoDB\" ， 如图所示。 如果一个程序员决定通过执行： strcat(s1, \" Cluster\"); 将 s1 的内容修改为 \"Redis Cluster\" ， 但粗心的他却忘了在执行 strcat 之前为 s1 分配足够的空间， 那么在 strcat 函数执行之后， s1 的数据将溢出到 s2 所在的空间中， 导致 s2 保存的内容被意外地修改， 如图所示。 与 C 字符串不同， SDS 的空间分配策略完全杜绝了发生缓冲区溢出的可能性： 当 SDS API 需要对 SDS 进行修改时， API 会先检查 SDS 的空间是否满足修改所需的要求， 如果不满足的话， API 会自动将 SDS 的空间扩展至执行修改所需的大小， 然后才执行实际的修改操作， 所以使用 SDS 既不需要手动修改 SDS 的空间大小， 也不会出现前面所说的缓冲区溢出问题。 减少修改字符串时带来的内存重分配次数 空间预分配：解决 append 问题 惰性空间释放：解决 strim 问题 二进制安全 C 字符串中的字符必须符合某种编码（比如 ASCII）， 并且 除了字符串的末尾之外， 字符串里面不能包含空字符， 否则最先被程序读入的空字符将被误认为是字符串结尾 —— 这些限制使得 C 字符串只能保存文本数据， 而不能保存像图片、音频、视频、压缩文件这样的二进制数据。 zset底层实现 跳跃表（skiplist）是一种有序数据结构， 它通过在每个节点中维持多个指向其他节点的指针， 从而达到快速访问节点的目的。 Redis 使用跳跃表作为有序集合键的底层实现之一： 如果一个有序集合包含的元素数量比较多， 有序集合中元素的成员（member）是比较长的字符串时 Redis 就会使用跳跃表来作为有序集合键的底层实现。 和链表、字典等数据结构被广泛地应用在 Redis 内部不同， Redis 只在两个地方用到了跳跃表， 一个是实现有序集合键， 另一个是在集群节点中用作内部数据结构， 除此之外， 跳跃表在 Redis 里面没有其他用途。 缓存穿透、缓存击穿、缓存雪崩 缓存穿透 访问一个不存在的key，缓存不起作用，请求会穿透到 DB，流量大时 DB 会挂掉。 解决方案 采用布隆过滤器，使用一个足够大的bitmap，用于存储可能访问的 key，不存在的key直接被过滤； 访问key未在DB查询到值，也将空值写进缓存，但可以设置较短过期时间。 缓存雪崩 大量的 key 设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。 解决方案 可以给缓存设置过期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。 缓存击穿 一个存在的key，在缓存过期的一刻，同时有大量的请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力骤增。 解决方案 在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。 Redis分布式锁 加锁：redis.set(String key, String value, String nxxx, String expx, int time) 解锁：通过 Lua 脚本执行 if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end 数据淘汰机制 对象过期 Redis回收过期对象的策略：定期删除+惰性删除 惰性删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key 定期删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key 内存淘汰 Redis提供了下面几种淘汰策略供用户选择，其中默认的策略为noeviction策略： noeviction：当内存使用达到阈值的时候，所有引起申请内存的命令会报错。 allkeys-lru：在主键空间中，优先移除最近未使用的key。 volatile-lru：在设置了过期时间的键空间中，优先移除最近未使用的key。 allkeys-random：在主键空间中，随机移除某个key。 volatile-random：在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：在设置了过期时间的键空间中，具有更早过期时间的key优先移除。 这里补充一下主键空间和设置了过期时间的键空间，举个例子，假设我们有一批键存储在Redis中，则有那么一个哈希表用于存储这批键及其值，如果这批键中有一部分设置了过期时间，那么这批键还会被存储到另外一个哈希表中，这个哈希表中的值对应的是键被设置的过期时间。设置了过期时间的键空间为主键空间的子集。 非精准的LRU 上面提到的LRU（Least Recently Used）策略，实际上 Redis 实现的 LRU 并不是可靠的 LRU，也就是名义上我们使用LRU算法淘汰键，但是实际上被淘汰的键并不一定是真正的最久没用的，这里涉及到一个权衡的问题，如果需要在全部键空间内搜索最优解，则必然会增加系统的开销，Redis是单线程的，也就是同一个实例在每一个时刻只能服务于一个客户端，所以耗时的操作一定要谨慎。 为了在一定成本内实现相对的LRU，早期的 Redis 版本是 基于采样的 LRU ，也就是放弃全部键空间内搜索解改为采样空间搜索最优解。自从 Redis3.0 版本之后，Redis 作者对于基于采样的 LRU 进行了一些优化，目的是在一定的成本内让结果更靠近真实的 LRU。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/4-database/10-questions.html":{"url":"basic/4-database/10-questions.html","title":"面试题","keywords":"","body":"面试题 MySQL有哪些日志，分别是什么用处？ mysql日志一般分为5种 错误日志：-log-err (记录启动，运行，停止mysql时出现的信息) 二进制日志：-log-bin （记录所有更改数据的语句，还用于复制，恢复数据库用） 查询日志：-log （记录建立的客户端连接和执行的语句） 慢查询日志: -log-slow-queries （记录所有执行超过long_query_time秒的所有查询） 更新日志: -log-update （二进制日志已经代替了老的更新日志，更新日志在MySQL5.1中不再使用） 除传统的关系型数据库之外，有哪些NoSQL数据库？ Memcached：分布式内存对象缓存系统，可以与MySQL数据库协同使用。它通过在内存中缓存数据和对象来减少读取数据库的次数，从而提高动态、数据库驱动网站的访问速度。Memcached基于一个存储键/值对的HashMap。Memcached可以用于解决数据读的性能，但是对写操作不能有提高。 Redis：基于内存亦可持久化的日志型、Key-Value数据库。和Memcached类似，但是它支持存储的value类型相对更多。同时可以实现主从同步，即分布式。 MongoDB：基于分布式文件存储的数据库。MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。他支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。 HBase：是一个分布式的、面向列的开源数据库。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。 视图由多个表连接而成，可以对视图进行插入操作么？ 若视图是由两个以上基本表导出的，则此视图不允许更新。 若视图的字段来自字段表达式或常数，则不允许对视图执行INSTER和UPDATE操作，但允许delete。 若视图的字段来自聚集函数，则此视图不允许更新。 若视图中含有GROUP by子句，则此视图不允许更新。 若视图中含有DISTINCT短语，则此视图不允许更新。. 若视图定义中有嵌套查询，并且内层查询的FROM子句中涉及的表也是导出该视图的基本表，则此视图不允许更新。. 一个不允许更新的视图上定义的视图不允许更新。 UNION 和 UNION ALL 有什么区别？ UNION 用于 合并两个或多个 SELECT 语句的结果集，并消去表中任何重复行。UNION 内部的 SELECT 语句必须拥有相同数量的列，列也必须拥有相似的数据类型。同时，每条 SELECT 语句中的列的顺序必须相同。 UNION ALL基本使用和UNION是一致的，但是UNION ALL不会消除表中的重复行。 主键和唯一键有什么区别？ 主键不能重复，不能为空，唯一键不能重复，可以为空。 建立主键的目的是让外键来引用。 一个表最多只有一个主键，但可以有很多唯一键。 MySQL中空值和NULL的区别？ 空值('')是不占用空间的，判断空字符用 = '' 或者 <> '' 来进行处理。 NULL值是未知的，且占用空间，不走索引；判断 NULL 用 IS NULL 或者 is not null ，SQL 语句函数中可以使用 ifnull ()函数来进行处理。 无法比较 NULL 和 0；它们是不等价的。 无法使用比较运算符来测试 NULL 值，比如 =, 。 NULL 值可以使用 符号进行比较，该符号与等号作用相似，但对NULL有意义。 进行 count ()统计某列的记录数的时候，如果采用的 NULL 值，会别系统自动忽略掉，但是空值是统计到其中。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"basic/cryptology.html":{"url":"basic/cryptology.html","title":"密码学","keywords":"","body":"密码学 对称加密 对称加密算法的加密和解密使用的密匙是相同的，也就是说如果通讯两方如果使用对称加密算法来加密通讯数据，那么通讯双方就需要都知道这个密匙，收到通讯数据后用这个密匙来解密数据。 这类算法在加密和解密时使用相同的密钥，或是使用两个可以简单地相互推算的密钥。事实上，这组密钥成为在两个或多个成员间的共同秘密，以便维持专属的通信联系。与非对称加密相比，要求双方获取相同的密钥是对称密钥加密的主要缺点之一。常见的对称加密算法有 DES、3DES、AES、Blowfish、IDEA、RC5、RC6。 对称加密的速度比公钥加密快很多，在很多场合都需要对称加密。 非对称加密 它需要两个密钥，一个是公开密钥，另一个是私有密钥；一个用作加密的时候，另一个则用作解密。使用其中一个密钥把明文加密后所得的密文，只能用相对应的另一个密钥才能解密得到原本的明文；甚至连最初用来加密的密钥也不能用作解密。由于加密和解密需要两个不同的密钥，故被称为非对称加密； 虽然两个密钥在数学上相关，但如果知道了其中一个，并不能凭此计算出另外一个；因此其中一个可以公开，称为 公钥，任意向外发布；不公开的密钥为 私钥 ，必须由用户自行严格秘密保管，绝不透过任何途径向任何人提供，也不会透露给要通信的另一方，即使他被信任。 公钥 & 私钥 均可以作为加密密钥 数字签名 数字签名是一种类似写在纸上的签名，但是使用了 公钥加密领域的技术实现 ，用于鉴别数字信息的方法。在网络上，我们可以使用“数字签名”来进行身份确认。数字签名是一个独一无二的数值，若公钥能通过验证，那我们就能确定对应的公钥的正确性，数字签名兼具这两种双重属性：\"可确认性\"及\"不可否认性（不需要笔迹专家验证）\"。 数字签名就是将公钥密码反过来使用。签名者将讯息用私钥加密（这是一种反用，因为通常非对称加密中私钥用于解密），然后公布公钥;验证者使用公钥将加密讯息解密并比对消息（一般签名对象为消息的散列值）。 密码散列函数 密码散列函数（英语：Cryptographic hash function），又译为加密散列函数、密码散列函数、加密散列函数，是散列函数的一种。它被认为是一种 单向函数，也就是说极其难以由散列函数输出的结果，回推输入的数据是什么。这种散列函数的输入数据，通常被称为消息（ message ），而它的输出结果，经常被称为消息摘要（ message digest ）或摘要（ digest ）。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/":{"url":"java/","title":"Java","keywords":"","body":"Java 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/1-oop.html":{"url":"java/1-oop.html","title":"OOP","keywords":"","body":"面向对象基础 面向对象三要素：封装、继承、多态 封装：封装的意义，在于明确标识出允许外部使用的所有成员函数和数据项，或者叫接口。 继承： 继承基类的方法，并做出自己的扩展； 声明某个子类兼容于某基类（或者说，接口上完全兼容于基类），外部调用者可无需关注其差别（内部机制会自动把请求派发dispatch到合适的逻辑）。 多态：基于对象所属类的不同，外部对同一个方法的调用，实际执行的逻辑不同。很显然，多态实际上是依附于继承的第二种含义的。 多态 方法签名：方法名 + 参数列表(参数类型、个数、顺序) 重写 子类重写父类方法，只有实例方法可以被重写，重写后的方法必须仍为实例方法。成员变量和静态方法都不能被重写，只能被隐藏。 重写实例方法：超类Parent中有实例方法A，子类child定义了与A 相同签名和子集返回类型 的实例方法B，子类对象ChildObj只能调用自己的实例方法B。 方法的重写（override）两同两小一大原则： 方法名相同，参数类型相同 子类返回类型小于等于父类方法返回类型 子类抛出异常小于等于父类方法抛出异常 子类访问权限大于等于父类方法访问权限 注意： 不能重写static静态方法。(形式上可以写，但本质上不是重写，属于下面要讲的隐藏) 重写方法可以改变其它的方法修饰符，如final,synchronized,native。不管被重写方法中有无final修饰的参数，重写方法都可以增加、保留、去掉这个参数的 final 修饰符(参数修饰符不属于方法签名)。 重载 在同一个类中，有多个方法名相同，参数列表不同（参数个数不同，参数类型不同），与方法的返回值无关，与权限修饰符无关。编译器通过对方法签名的识别即可静态编译出不同的方法。这也是java中重载与重写的区别之一。 重载只是一种语言特性，与多态无关，与面向对象也无关。多态是为了实现接口重用。 Java中方法是可以和类名同名的，和构造方法唯一的区别就是，构造方法没有返回值。 隐藏 隐藏与覆盖在形式上极其类似(语法规则)，但有着本质的区别：只有成员变量(不管是不是静态)和静态方法可以被隐藏。 成员变量 超类 Parent 中有成员变量 A ，子类 Child 定义了与 A 同名的成员变量 B ，子类对象 ChildObj 调用的是自己的成员变量 B。如果把子类对象 ChildObj 转换为超类对象 ParentObj ，ParentObj 调用的是超类的成员变量 A ！ 隐藏成员变量时，只要同名即可，可以更改变量类型(无论基本类型还是隐藏类型) 不能隐藏超类中的 private 成员变量，换句话说，只能隐藏可以访问的成员变量。 隐藏超类成员变量 A 时，可以降低或提高子类成员变量B的访问权限，只要A不是 private。 隐藏成员变量与是否静态无关！静态变量可以隐藏实例变量，实例变量也可以隐藏静态变量。 可以隐藏超类中的final成员变量。 静态方法 超类 Parent 有静态方法 A ，子类 Child 定义了与 A 相同签名和子集返回类型 的静态方法 B ，子类对象 ChildObj 调用的是自己的静态方法 B 。如果把子类对象 ChildObj 转换为超类对象 ParentObj ，ParentObj 调用的是超类的静态方法 A ！ 隐藏后的方法必须仍为静态方法 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/10-serilaser.html":{"url":"java/10-serilaser.html","title":"序列化","keywords":"","body":"序列化 ProtoBuffer Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 RPC 数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。 Protobuf 的优点 Protobuf 更小、更快、也更简单。你可以定义自己的数据结构，然后使用代码生成器生成的代码来读写这个数据结构。你甚至可以在无需重新部署程序的情况下更新数据结构。只需使用 Protobuf 对数据结构进行一次描述，即可利用各种不同语言或从各种不同数据流中对你的结构化数据轻松读写。 “向后”兼容性好，人们不必破坏已部署的、依靠“老”数据格式的程序就可以对数据结构进行升级。这样您的程序就可以不必担心因为消息结构的改变而造成的大规模的代码重构或者迁移的问题。因为添加新的消息中的 field 并不会引起已经发布的程序的任何改变。 Protobuf 语义更清晰，无需类似 XML 解析器的东西（因为 Protobuf 编译器会将 .proto 文件编译生成对应的数据访问类以对 Protobuf 数据进行序列化、反序列化操作）。 Protobuf 的编程模式比较友好，简单易学，同时它拥有良好的文档和示例，对于喜欢简单事物的人们而言，Protobuf 比其他的技术更加有吸引力。 Protobuf 的不足 由于文本并不适合用来描述数据结构，所以 Protobuf 也不适合用来对基于文本的标记文档（如 HTML）建模。另外，由于 XML 具有某种程度上的自解释性，它可以被人直接读取编辑，在这一点上 Protobuf 不行，它以二进制的方式存储，除非你有 .proto 定义，否则你没法直接读出 Protobuf 的任何内容。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/2-operator.html":{"url":"java/2-operator.html","title":"运算符","keywords":"","body":"运算符优先级 优先级从上到下依次递减，最上面具有最高的优先级，逗号操作符具有最低的优先级。 相同优先级中，按结合顺序计算。大多数运算是从左至右计算，只有三个优先级是从右至左结合的，它们是单目运算符、条件运算符、赋值运算符。 基本的优先级需要记住： 指针最优，单目运算优于双目运算。如正负号。 先乘除（模），后加减。 先算术运算，后移位运算，最后位运算。请特别注意：1 等价于 (1 . 逻辑运算最后计算。 优先级表 运算符 结合性 [ ] . ( ) (方法调用) 从左向右 ! ~ ++ -- +(一元运算) -(一元运算) 从右向左 * / % 从左向右 + -　 从左向右 > >>> 从左向右 >= instanceof 从左向右 == != 从左向右 & 从左向右 ^ 从左向右 | 从左向右 && 从左向右 || 从左向右 ?: 从右向左 = += -= *= /= %= &= |= ^= >= >>= 从右向左 ， 从左到右 无符号右移运算符 >>>，无符号右移的规则只记住一点：忽略了符号位扩展，0 补最高位。无符号右移规则和右移运算是一样的，只是填充时不管左边的数字是正是负都用 0 来填充，无符号右移运算只针对负数计算，因为对于正数来说这种运算没有意义。无符号右移运算符 >>> 只是对 32 位和 64 位的值有意义 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/3-exception.html":{"url":"java/3-exception.html","title":"异常","keywords":"","body":"Java异常 Java中有Error和Exception，它们都是继承自Throwable类。 二者的不同之处 Exception： 可以是可被控制(checked) 或不可控制的(unchecked)。 表示一个由程序员导致的错误。 应该在应用程序级被处理。 Error： 总是不可控制的(unchecked)。 经常用来用于表示系统错误或低层资源的错误。 如何可能的话，应该在系统级被捕捉。 异常的分类 Checked exception: 这类异常都是Exception的子类。异常的向上抛出机制进行处理，假如子类可能产生A异常，那么在父类中也必须throws A异常。可能导致的问题：代码效率低，耦合度过高。 Unchecked exception: 这类异常都是RuntimeException的子类，虽然RuntimeException同样也是Exception的子类，但是它们是非凡的，它们不能通过client code来试图解决，所以称为Unchecked exception 。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/4-generics.html":{"url":"java/4-generics.html","title":"范型","keywords":"","body":"Java泛型 开发人员在使用泛型的时候，很容易根据自己的直觉而犯一些错误。比如一个方法如果接收List作为形式参数，那么如果尝试将一个List的对象作为实际参数传进去，却发现无法通过编译。虽然从直觉上来说，Object是String的父类，这种类型转换应该是合理的。但是实际上这会产生隐含的类型转换问题，因此编译器直接就禁止这样的行为。 类型擦除 Java中的泛型基本上都是在编译器这个层次来实现的，在生成的Java字节代码中是不包含泛型中的类型信息的。使用泛型的时候加上的类型参数，会被编译器在编译的时候去掉，这个过程就称为类型擦除。如在代码中定义的List和List等类型，在编译之后都会变成List。JVM看到的只是List，而由泛型附加的类型信息对JVM来说是不可见的。Java编译器会在编译时尽可能的发现可能出错的地方，但是仍然无法避免在运行时刻出现类型转换异常的情况。 很多泛型的奇怪特性都与这个类型擦除的存在有关，包括： 泛型类并没有自己独有的Class类对象。比如并不存在List.class或是List.class，而只有List.class。 静态变量是被泛型类的所有实例所共享的。对于声明为MyClass的类，访问其中的静态变量的方法仍然是 MyClass.myStaticVar。不管是通过new MyClass还是new MyClass创建的对象，都是共享一个静态变量。 泛型的类型参数不能用在Java异常处理的catch语句中。因为异常处理是由JVM在运行时刻来进行的。由于类型信息被擦除，JVM是无法区分两个异常类型MyException和MyException的。对于JVM来说，它们都是 MyException类型的。也就无法执行与异常对应的catch语句。 类型擦除的基本过程也比较简单，首先是找到用来替换类型参数的具体类。这个具体类一般是Object。如果指定了类型参数的上界的话，则使用这个上界。把代码中的类型参数都替换成具体的类。同时去掉出现的类型声明，即去掉<>的内容。比如T get()方法声明就变成了Object get()；List就变成了List。接下来就可能需要生成一些桥接方法（bridge method）。这是由于擦除了类型之后的类可能缺少某些必须的方法。比如考虑下面的代码： class MyString implements Comparable { public int compareTo(String str) { return 0; } } 当类型信息被擦除之后，上述类的声明变成了class MyString implements Comparable。但是这样的话，类MyString就会有编译错误，因为没有实现接口Comparable声明的int compareTo(Object)方法。这个时候就由编译器来动态生成这个方法。 通配符 在使用泛型类的时候，既可以指定一个具体的类型，如List就声明了具体的类型是String；也可以用通配符?来表示未知类型，如List就声明了List中包含的元素类型是未知的。 通配符所代表的其实是一组类型，但具体的类型是未知的。List所声明的就是所有类型都是可以的。但是List并不等同于List。List实际上确定了List中包含的是Object及其子类，在使用的时候都可以通过Object来进行引用。而List则其中所包含的元素类型是不确定。其中可能包含的是String，也可能是 Integer。如果它包含了String的话，往里面添加Integer类型的元素就是错误的。正因为类型未知，就不能通过new ArrayList()的方法来创建一个新的ArrayList对象。因为编译器无法知道具体的类型是什么。但是对于 List中的元素确总是可以用Object来引用的，因为虽然类型未知，但肯定是Object及其子类。考虑下面的代码： public void wildcard(List list) { list.add(1);//编译错误 } 如上所示，试图对一个带通配符的泛型类进行操作的时候，总是会出现编译错误。其原因在于通配符所表示的类型是未知的。 因为对于List中的元素只能用Object来引用，在有些情况下不是很方便。在这些情况下，可以使用上下界来限制未知类型的范围。 如 List说明List中可能包含的元素类型是Number及其子类。而List则说明List中包含的是Number及其父类。当引入了上界之后，在使用类型的时候就可以使用上界类中定义的方法。 类型系统 在Java中，大家比较熟悉的是通过继承机制而产生的类型体系结构。比如String继承自Object。根据Liskov替换原则，子类是可以替换父类的。当需要Object类的引用的时候，如果传入一个String对象是没有任何问题的。但是反过来的话，即用父类的引用替换子类引用的时候，就需要进行强制类型转换。编译器并不能保证运行时刻这种转换一定是合法的。这种自动的子类替换父类的类型转换机制，对于数组也是适用的。 String[]可以替换Object[]。但是泛型的引入，对于这个类型系统产生了一定的影响。正如前面提到的List是不能替换掉List的。 引入泛型之后的类型系统增加了两个维度：一个是类型参数自身的继承体系结构，另外一个是泛型类或接口自身的继承体系结构。第一个指的是对于 List和List这样的情况，类型参数String是继承自Object的。而第二种指的是 List接口继承自Collection接口。对于这个类型系统，有如下的一些规则： 相同类型参数的泛型类的关系取决于泛型类自身的继承体系结构。即List是Collection 的子类型，List可以替换Collection。这种情况也适用于带有上下界的类型声明。 当泛型类的类型声明中使用了通配符的时候，其子类型可以在两个维度上分别展开。如对Collection来说，其子类型可以在Collection这个维度上展开，即List和Set等；也可以在Number这个层次上展开，即Collection和Collection等。如此循环下去，ArrayList和 HashSet等也都算是Collection的子类型。 如果泛型类中包含多个类型参数，则对于每个类型参数分别应用上面的规则。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/5-object.html":{"url":"java/5-object.html","title":"Object","keywords":"","body":"Object getClass 返回该对象运行时的 class 对象，返回的 Class 对象是由所表示的类的静态同步方法锁定的对象。 hashCode 返回该对象的 hashcode，该方法对hash表提供支持，例如 HashMap。 对于该方法有几点需要注意： 在运行中的Java应用，如果用在 equals 中进行比较的信息没有改变，那么不论何时调用都需要返回一致的int值。这个hash值在应用的两次执行中不需要保持一致。 如果两个对象根据 equals 方法认为是相等的，那么这两个对象也应该返回相等的 hashcode。 不要求两个不相等的对象，在调用 hashCode 方法返回的结果是必须是不同的。然而，程序员应该了解不同的对象产生不同的 hashcode 能够提升哈希表的效率。 Object的hashcode对不同的对象，尽可能返回不同的 hashcode 。这通常通过将对象的内部地址转换为整数来实现，但Java编程语言不需要此实现技术。 Arrays.hashCode Arrays.hashCode 是一个数组的浅哈希码实现，深哈希可以使用 deepHashCode。并且当数组长度为1时，Arrays.hashCode(object) = object.hashCode 不一定成立 31 不论是String、Arrays在计算多个元素的哈希值的时候，都会有31这个数字。主要有以下两个原因： 31是一个不大不小的质数，是作为 hashCode 乘子的优选质数之一。 另外一些相近的质数，比如37、41、43等等，也都是不错的选择。那么为啥偏偏选中了31呢？请看第二个原因。 31可以被 JVM 优化，31 * i = (i 。 上面两个原因中，第一个需要解释一下，第二个比较简单，就不说了。一般在设计哈希算法时，会选择一个特殊的质数。至于为啥选择质数，我想应该是可以降低哈希算法的冲突率。 在 Effective Java 中有一段相关的解释： 选择数字31是因为它是一个奇质数，如果选择一个偶数会在乘法运算中产生溢出，导致数值信息丢失，因为乘二相当于移位运算。选择质数的优势并不是特别的明显，但这是一个传统。同时，数字31有一个很好的特性，即乘法运算可以被移位和减法运算取代，来获取更好的性能：31 * i == (i ，现代的 Java 虚拟机可以自动的完成这个优化。 equals 判定两个对象是否相等。equals和hashCode需要同时被overwrite clone 创建一个该对象的副本，并且对于对象 x 应当满足以下表达式： x.clone() != x x.clone().getClass() == x.getClass() x.clone().equals(x) toString wait 当前线程等待知道其他线程调用该对象的 notify 或者 notifyAll方法。当前线程必须拥有该对象的 monitor。线程释放该对象monitor的拥有权，并且等待到别的线程通知等待在该对象monitor上的线程苏醒。然后线程重新拥有monitor并继续执行。在某些jdk版本中，中断和虚假唤醒是存在的，所以wait方法需要放在循环中。 synchronized (obj) { while () obj.wait(); ... // Perform action appropriate to condition } 该方法只能被拥有该对象monitor的线程调用。 虚假唤醒（spurious wakeup） 虚假唤醒就是一些obj.wait()会在除了obj.notify()和obj.notifyAll()的其他情况被唤醒，而此时是不应该唤醒的。 注意 Lock 的 Conditon.await 也有虚假唤醒的问题 解决的办法是基于while来反复判断进入正常操作的临界条件是否满足 同时也可以使用同步数据结构：BlokingQueue 解释 虚假唤醒（spurious wakeup）是一个表象，即在多处理器的系统下发出 wait 的程序有可能在没有 notify 唤醒的情形下苏醒继续执行。 以运行在 Linux 的 hotspot 虚拟机上的 java 程序为例， wait 方法在 jvm 执行时实质是调用了底层 pthread_cond_wait/pthread_cond_timedwait 函数，挂起等待条件变量来达到线程间同步通信的效果，而底层 wait 函数在设计之初为了不减慢条件变量操作的效率并没有去保证每次唤醒都是由 notify 触发，而是把这个任务交由上层应用去实现，即使用者需要定义一个循环去判断是否条件真能满足程序继续运行的需求，当然这样的实现也可以避免因为设计缺陷导致程序异常唤醒的问题。 notify 唤醒一个等待在该对象monitor上的线程。如果有多个线程等待，则会随机选择一个线程唤醒。线程等待是通过调用wait方法。 唤醒的线程不会立即执行，直到当前线程放弃对象上的锁。唤醒的线程也会以通常的方式和竞争该对象锁的线程进行竞争。也就是说，唤醒的线程在对该对象的加锁中没有任何优先级。 该方法只能被拥有该对象monitor的线程调用。线程拥有monitor有下面三种方式： 执行该对象的 synchronized 方法 执行以该对象作为同步语句的synchronized方法体 对于class对象，可以执行该对象的static synchronized方法 在同一时间只能有一个线程能够拥有该对象monitor finalize 当 GC 认为该对象已经没有任何引用的时候，该方法被GC收集器调用。子类可以 overwrite 该方法来关闭系统资源或者其他清理任务。 finalize 的一般契约是，如果 Java 虚拟机确定不再有任何方法可以通过任何尚未死亡的线程访问此对象，除非由于某个操作，它将被调用通过最终确定准备完成的其他一些对象或类来完成。 finalize 方法可以采取任何操作，包括使该对象再次可用于其他线程；但是，finalize 的通常目的是在对象被不可撤销地丢弃之前执行清理操作。例如，表示输入/输出连接的对象的 finalize 方法可能会执行显式 I/O 事务，以在永久丢弃对象之前断开连接。 类 Object 的 finalize 方法不执行任何特殊操作;它只是正常返回。 Object 的子类可以覆盖此定义。 Java 编程语言不保证哪个线程将为任何给定对象调用 finalize 方法。但是，可以保证，调用 finalize 时，调用 finalize 的线程不会持有任何用户可见的同步锁。如果 finalize 方法抛出未捕获的异常，则忽略该异常并终止该对象的终止。在为对象调用 finalize 方法之后，在 Java 虚拟机再次确定不再有任何方法可以通过任何尚未死亡的线程访问此对象之前，不会采取进一步操作，包括可能的操作通过准备完成的其他对象或类，此时可以丢弃该对象。 对于任何给定对象，Java 虚拟机永远不会多次调用 finalize 方法。 finalize 方法抛出的任何异常都会导致暂停此对象的终结，但会被忽略。 缺陷 一些与 finalize 相关的方法，由于一些致命的缺陷，已经被废弃了，如 System.runFinalizersOnExit() 方法、Runtime.runFinalizersOnExit()方法。 System.gc() 与 System.runFinalization() 方法增加了finalize方法执行的机会，但不可盲目依赖它们。 Java 语言规范并不保证 finalize 方法会被及时地执行、而且根本不会保证它们会被执行。 finalize 方法可能会带来性能问题。因为JVM通常在单独的低优先级线程中完成finalize的执行。 对象再生问题： finalize 方法中，可将待回收对象赋值给GC Roots可达的对象引用，从而达到对象再生的目的。 finalize 方法至多由GC执行一次(用户当然可以手动调用对象的 finalize 方法，但并不影响GC对 finalize 的行为)。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/6-StringBuilder.html":{"url":"java/6-StringBuilder.html","title":"StringBuilder","keywords":"","body":"StringBuilder StringBuilder类也封装了一个字符数组，定义如下： char[] value; 与String不同，它不是final的，可以修改。另外，与String不同，字符数组中不一定所有位置都已经被使用，它有一个实例变量，表示数组中已经使用的字符个数，定义如下： int count; StringBuilder继承自AbstractStringBuilder，它的默认构造方法是： public StringBuilder() { super(16); } 调用父类的构造方法，父类对应的构造方法是： AbstractStringBuilder(int capacity) { value = new char[capacity]; } 也就是说，new StringBuilder()这句代码，内部会创建一个长度为16的字符数组，count的默认值为0。 append的实现 public AbstractStringBuilder append(String str) { if (str == null) str = \"null\"; int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this; } append会直接拷贝字符到内部的字符数组中，如果字符数组长度不够，会进行扩展，实际使用的长度用count体现。具体来说，ensureCapacityInternal(count+len)会确保数组的长度足以容纳新添加的字符，str.getChars会拷贝新添加的字符到字符数组中，count+=len会增加实际使用的长度。 ensureCapacityInternal的代码如下： private void ensureCapacityInternal(int minimumCapacity) { if (minimumCapacity - value.length > 0) expandCapacity(minimumCapacity); } 如果字符数组的长度小于需要的长度，则调用expandCapacity进行扩展，expandCapacity的代码是： void expandCapacity(int minimumCapacity) { int newCapacity = value.length * 2 + 2; if (newCapacity - minimumCapacity 扩展的逻辑是，分配一个足够长度的新数组，然后将原内容拷贝到这个新数组中，最后让内部的字符数组指向这个新数组，这个逻辑主要靠下面这句代码实现： value = Arrays.copyOf(value, newCapacity); toString实现 字符串构建完后，我们来看toString代码： public String toString() { return new String(value, 0, count); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/7-proxy.html":{"url":"java/7-proxy.html","title":"代理","keywords":"","body":"代理 Java动态代理与CGLIB 我们常说的代理分为静态代理和动态代理。 静态代理：代码中显式指定代理 动态代理：类比静态代理，可以发现，代理类不需要实现原接口了，而是实现InvocationHandler。 静态代理 因为需要对一些函数进行二次处理，或是某些函数不让外界知道时，可以使用代理模式，通过访问第三方，间接访问原函数的方式，达到以上目的。 弊端 如果要想为多个类进行代理，则需要建立多个代理类，维护难度加大。 仔细想想，为什么静态代理会有这些问题，是因为代理在编译期就已经决定，如果代理发生在运行期，这些问题解决起来就比较简单，所以动态代理的存在就很有必要了。 动态代理 当动态生成的代理类调用方法时，会触发 invoke 方法，在 invoke 方法中可以对被代理类的方法进行增强。 // 1. 首先实现一个InvocationHandler，方法调用会被转发到该类的invoke()方法。 class LogInvocationHandler implements InvocationHandler{ ... private Hello hello; public LogInvocationHandler(Hello hello) { this.hello = hello; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { if(\"sayHello\".equals(method.getName())) { logger.info(\"You said: \" + Arrays.toString(args)); } return method.invoke(hello, args); } } // 2. 然后在需要使用Hello的时候，通过JDK动态代理获取Hello的代理对象。 Hello hello = (Hello)Proxy.newProxyInstance( getClass().getClassLoader(), // 1. 类加载器 new Class[] {Hello.class}, // 2. 代理需要实现的接口，可以有多个 new LogInvocationHandler(new HelloImp()));// 3. 方法调用的实际处理者 System.out.println(hello.sayHello(\"I love you!\")); 通过动态代理可以很明显的看到它的好处，在使用静态代理时，如果不同接口的某些类想使用代理模式来实现相同的功能，将要实现多个代理类，但在动态代理中，只需要一个代理类就好了。 除了省去了编写代理类的工作量，动态代理实现了可以在原始类和接口还未知的时候，就确定代理类的代理行为，当代理类与原始类脱离直接联系后，就可以很灵活地重用于不同的应用场景中。 继承了Proxy类，实现了代理的接口，由于java不能多继承，这里已经继承了Proxy类了，不能再继承其他的类，所以JDK的动态代理不支持对实现类的代理，只支持接口的代理。 提供了一个使用InvocationHandler作为参数的构造方法。 生成静态代码块来初始化接口中方法的Method对象，以及Object类的equals、hashCode、toString方法 弊端 代理类和委托类需要都实现同一个接口。也就是说只有实现了某个接口的类可以使用Java动态代理机制。但是，事实上使用中并不是遇到的所有类都会给你实现一个接口。因此，对于没有实现接口的类，就不能使用该机制。 动态代理与静态代理的区别 Proxy类的代码被固定下来，不会因为业务的逐渐庞大而庞大； 代理对象是在程序运行时产生的，而不是编译期； 可以实现AOP编程，这是静态代理无法实现的； 解耦，如果用在web业务下，可以实现数据层和业务层的分离。 动态代理的优势就是实现无侵入式的代码扩展。 静态代理这个模式本身有个大问题，如果类方法数量越来越多的时候，代理类的代码量是十分庞大的。所以引入动态代理来解决此类问题 CGLib cglib 是针对类来实现代理的，他的 原理是对指定的目标类生成一个子类，并覆盖其中方法实现增强，但因为采用的是继承，所以不能对 final 修饰的类进行代理。同样的，final 方法是不能重载的，所以也不能通过CGLIB代理，遇到这种情况不会抛异常，而是会跳过 final 方法只代理其他方法。 CGLIB 代理主要通过对字节码的操作，为对象引入间接级别，以控制对象的访问。 CGLIB 底层使用了ASM（一个短小精悍的字节码操作框架）来操作字节码生成新的类。 CGLIB和Java动态代理的区别 Java 动态代理只能够对接口进行代理，不能对普通的类进行代理（因为所有生成的代理类的父类为 Proxy，Java 类继承机制不允许多重继承）；CGLIB能够代理普通类； Java 动态代理使用 Java 原生的反射 API 进行操作，在生成类上比较高效；CGLIB 使用 ASM 框架直接对字节码进行操作，在类的执行过程中比较高效 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/17-questions.html":{"url":"java/17-questions.html","title":"面试题","keywords":"","body":"面试题 如何用数组实现队列？ 用数组实现队列时要注意 溢出 现象，这时我们可以采用循环数组的方式来解决，即将数组收尾相接。使用front指针指向队列首位，tail指针指向队列末位。 内部类访问局部变量的时候，为什么变量必须加上final修饰？ 因为生命周期不同。局部变量在方法结束后就会被销毁，但内部类对象并不一定，这样就会导致内部类引用了一个不存在的变量。 所以编译器会在内部类中生成一个局部变量的拷贝，这个拷贝的生命周期和内部类对象相同，就不会出现上述问题。 但这样就导致了其中一个变量被修改，两个变量值可能不同的问题。为了解决这个问题，编译器就要求局部变量需要被final修饰，以保证两个变量值相同。 在JDK8之后，编译器不要求内部类访问的局部变量必须被final修饰，但局部变量值不能被修改（无论是方法中还是内部类中），否则会报编译错误。利用javap查看编译后的字节码可以发现，编译器已经加上了final。 long s = 499999999 * 499999999 在上面的代码中，s的值是多少？ 根据代码的计算结果，s的值应该是-1371654655，这是由于Java中右侧值的计算默认是int类型。 NIO相关，Channels、Buffers、Selectors NIO(Non-blocking IO)为所有的原始类型提供(Buffer)缓存支持，字符集编码解码解决方案。 Channel ：一个新的原始I\\/O 抽象。 支持锁和内存映射文件的文件访问接口。提供多路(non-bloking) 非阻塞式的高伸缩性网络I\\/O 。 IO NIO 面向流 面向缓冲 阻塞IO 非阻塞IO 无 选择器 流与缓冲 Java NIO和IO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。 Java NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。 阻塞与非阻塞IO Java IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。 Java NIO的非阻塞模式，是线程向某通道发送请求读取数据，仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，当然它不会保持线程阻塞。所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。所以一个单独的线程现在可以管理多个输入和输出通道。 选择器（Selectors） Java NIO 的 选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。 反射的用途 Java反射机制可以让我们在编译期(Compile Time)之外的运行期(Runtime)检查类，接口，变量以及方法的信息。反射还可以让我们在运行期实例化对象，调用方法，通过调用get/set方法获取变量的值。同时我们也可以通过反射来获取泛型信息，以及注解。还有更高级的应用--动态代理和动态类加载（ClassLoader.loadclass()）。 下面列举一些比较重要的方法： getFields：获取所有 public 的变量。 getDeclaredFields：获取所有包括 private , protected 权限的变量。 setAccessible：设置为 true 可以跳过Java权限检查，从而访问private权限的变量。 getAnnotations：获取注解，可以用在类和方法上。 获取方法的泛型参数： method = Myclass.class.getMethod(\"setStringList\", List.class); Type[] genericParameterTypes = method.getGenericParameterTypes(); for(Type genericParameterType : genericParameterTypes){ if(genericParameterType instanceof ParameterizedType){ ParameterizedType aType = (ParameterizedType) genericParameterType; Type[] parameterArgTypes = aType.getActualTypeArguments(); for(Type parameterArgType : parameterArgTypes){ Class parameterArgClass = (Class) parameterArgType; System.out.println(\"parameterArgClass = \" + parameterArgClass); } } } 动态代理： //Main.java public static void main(String[] args) { HelloWorld helloWorld=new HelloWorldImpl(); InvocationHandler handler=new HelloWorldHandler(helloWorld); //创建动态代理对象 HelloWorld proxy=(HelloWorld)Proxy.newProxyInstance( helloWorld.getClass().getClassLoader(), helloWorld.getClass().getInterfaces(), handler); proxy.sayHelloWorld(); } //HelloWorldHandler.java public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { Object result = null; //调用之前 doBefore(); //调用原始对象的方法 result=method.invoke(obj, args); //调用之后 doAfter(); return result; } 通过反射获取方法注解的参数： Class aClass = TheClass.class; Annotation[] annotations = aClass.getAnnotations(); for(Annotation annotation : annotations){ if(annotation instanceof MyAnnotation){ MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println(\"name: \" + myAnnotation.name()); System.out.println(\"value: \" + myAnnotation.value()); } } Java注解的继承 有@Inherited 没有@Inherited 子类的类上能否继承到父类的类上的注解？ 否 能 子类实现了父类上的抽象方法 否 否 子类继承了父类上的方法 能 能 子类覆盖了父类上的方法 否 否 通过测试结果来看，@Inherited 只是可控制对类名上注解是否可以被继承。不能控制方法上的注解是否可以被继承。 非静态内部类能定义静态方法吗？ public class OuterClass{ private static float f = 1.0f; class InnerClass{ public static float func(){return f;} } } 以上代码会出现编译错误，因为只有静态内部类才能定义静态方法。 Lock 和 Synchronized 有什么区别？ 使用方法的区别 Synchronized：在需要同步的对象中加入此控制，synchronized可以加在方法上，也可以加在特定代码块中，括号中表示需要锁的对象。 Lock：需要显示指定起始位置和终止位置。一般使用ReentrantLock类做为锁，多个线程中必须要使用一个ReentrantLock类做为对象才能保证锁的生效。且在加锁和解锁处需要通过lock()和unlock()显示指出。所以一般会在finally块中写unlock()以防死锁。 性能的区别 synchronized是托管给JVM执行的，而lock是java写的控制锁的代码。在Java1.5中，synchronize是性能低效的。因为这是一个重量级操作，需要调用操作接口，导致有可能加锁消耗的系统时间比加锁以外的操作还多。相比之下使用Java提供的Lock对象，性能更高一些。但是到了Java1.6，发生了变化。synchronize在语义上很清晰，可以进行很多优化，有适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在Java1.6上synchronize的性能并不比Lock差。 Synchronized：采用的是CPU悲观锁机制，即线程获得的是独占锁。独占锁意味着 其他线程只能依靠阻塞来等待线程释放锁。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。 Lock：用的是乐观锁方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁实现的机制就是CAS操作。我们可以进一步研究ReentrantLock的源代码，会发现其中比较重要的获得锁的一个方法是compareAndSetState。这里其实就是调用的CPU提供的特殊指令。 ReentrantLock：具有更好的可伸缩性：比如时间锁等候、可中断锁等候、无块结构锁、多个条件变量或者锁投票。 float 变量如何与 0 比较？ folat类型的还有double类型的，这些小数类型在趋近于0的时候直接等于0的可能性很小，一般都是无限趋近于0，因此不能用==来判断。应该用|x-0|来判断，这里|x-0|表示绝对值，err表示限定误差。 //用程序表示就是 fabs(x) 如何新建非静态内部类？ 内部类在声明的时候必须是 Outer.Inner a，就像int a 一样，至于静态内部类和非静态内部类new的时候有点区别： Outer.Inner a = new Outer().new Inner()（非静态，先有Outer对象才能 new 内部类） Outer.Inner a = new Outer.Inner()（静态内部类） Java标识符命名规则 可以包含：字母、数字、$、_(下划线)，不可用数字开头，不能是 Java 的关键字和保留字。 你知道哪些JDK中用到的设计模式？ 装饰模式：java.io 单例模式：Runtime类 简单工厂模式：Integer.valueOf方法 享元模式：String常量池、Integer.valueOf(int i)、Character.valueOf(char c) 迭代器模式：Iterator 职责链模式：ClassLoader的双亲委派模型 解释器模式：正则表达式java.util.regex.Pattern ConcurrentHashMap如何保证线程安全 JDK 1.7及以前： ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。它使用了多个锁来控制对hash表的不同部分进行的修改。ConcurrentHashMap内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的hash table，它们有自己的锁。只要多个修改操作发生在不同的段上，它们就可以并发进行。 详细参考： http:\\/\\/www.cnblogs.com\\/ITtangtang\\/p\\/3948786.html http:\\/\\/qifuguang.me\\/2015\\/09\\/10\\/[Java并发包学习八]深度剖析ConcurrentHashMap\\/ JDK 1.8： Segment虽保留，但已经简化属性，仅仅是为了兼容旧版本。 插入时使用CAS算法：unsafe.compareAndSwapInt(this, valueOffset, expect, update)。 CAS(Compare And Swap)意思是如果valueOffset位置包含的值与expect值相同，则更新valueOffset位置的值为update，并返回true，否则不更新，返回false。插入时不允许key或value为null 与Java8的HashMap有相通之处，底层依然由“数组”+链表+红黑树； 底层结构存放的是TreeBin对象，而不是TreeNode对象； CAS作为知名无锁算法，那ConcurrentHashMap就没用锁了么？当然不是，当hash值与链表的头结点相同还是会synchronized上锁，锁链表。 i++在多线程环境下是否存在问题，怎么解决？ 虽然递增操作++i是一种紧凑的语法，使其看上去只是一个操作，但这个操作并非原子的，因而它并不会作为一个不可分割的操作来执行。实际上，它包含了三个独立的操作：读取count的值，将值加1，然后将计算结果写入count。这是一个“读取 - 修改 - 写入”的操作序列，并且其结果状态依赖于之前的状态。所以在多线程环境下存在问题。 要解决自增操作在多线程环境下线程不安全的问题，可以选择使用Java提供的原子类，如AtomicInteger或者使用synchronized同步方法。 new与newInstance()的区别 new是一个关键字，它是调用new指令创建一个对象，然后调用构造方法来初始化这个对象，可以使用带参数的构造器 newInstance()是Class的一个方法，在这个过程中，是先取了这个类的不带参数的构造器Constructor，然后调用构造器的newInstance方法来创建对象。 Class.newInstance不能带参数，如果要带参数需要取得对应的构造器，然后调用该构造器的Constructor.newInstance(Object ... initargs)方法 你了解哪些JDK1.8的新特性？ 接口的默认方法和静态方法，JDK8允许我们给接口添加一个非抽象的方法实现，只需要使用default关键字即可。也可以定义被static修饰的静态方法。 对HashMap进行了改进，当单个桶的元素个数大于6时就会将实现改为红黑树实现，以避免构造重复的hashCode的攻击 多并发进行了优化。如ConcurrentHashMap实现由分段加锁、锁分离改为CAS实现。 JDK8拓宽了注解的应用场景，注解几乎可以使用在任何元素上，并且允许在同一个地方多次使用同一个注解 Lambda表达式 你用过哪些JVM参数？ Xms 堆最小值 Xmx 堆最大值 Xmn: 新生代容量 XX:SurvivorRatio 新生代中Eden与Surivor空间比例 Xss 栈容量 XX:PermSize 方法区初始容量 XX:MaxPermSize 方法区最大容量 XX:+PrintGCDetails 收集器日志参数 如何打破 ClassLoader 双亲委托？ 重写loadClass()方法。 hashCode() && equals() hashcode() 返回该对象的哈希码值，支持该方法是为哈希表提供一些优点，例如，java.util.Hashtable 提供的哈希表。 在 Java 应用程序执行期间，在同一对象上多次调用 hashCode 方法时，必须一致地返回相同的整数，前提是对象上 equals 比较中所用的信息没有被修改（equals默认返回对象地址是否相等）。如果根据 equals(Object)方法，两个对象是相等的，那么在两个对象中的每个对象上调用 hashCode 方法都必须生成相同的整数结果。 以下情况不是必需的：如果根据 equals(java.lang.Object) 方法，两个对象不相等，那么在两个对象中的任一对象上调用 hashCode 方法必定会生成不同的整数结果。但是，程序员应该知道，为不相等的对象生成不同整数结果可以提高哈希表的性能。 实际上，由 Object 类定义的 hashCode 方法确实会针对不同的对象返回不同的整数。（这一般是通过将该对象的内部地址转换成一个整数来实现的，但是 JavaTM 编程语言不需要这种实现技巧I。） hashCode的存在主要是用于查找的快捷性，如 Hashtable，HashMap等，hashCode 是用来在散列存储结构中确定对象的存储地址的； 如果两个对象相同，就是适用于 equals(java.lang.Object) 方法，那么这两个对象的 hashCode 一定要相同； 如果对象的 equals 方法被重写，那么对象的 hashCode 也尽量重写，并且产生 hashCode 使用的对象，一定要和 equals 方法中使用的一致，否则就会违反上面提到的第2点； 两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object) 方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在同一个篮子里”。 Thread.sleep() & Thread.yield() sleep()和yield()都会释放CPU。 sleep()使当前线程进入停滞状态，所以执行sleep()的线程在指定的时间内肯定不会执行；yield()只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。 sleep()可使优先级低的线程得到执行的机会，当然也可以让同优先级和高优先级的线程有执行的机会；yield()只能使同优先级的线程有执行的机会。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/collection/":{"url":"java/collection/","title":"集合","keywords":"","body":" 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/collection/1-collection.html":{"url":"java/collection/1-collection.html","title":"集合","keywords":"","body":"集合框架 Java集合框架提供了数据持有对象的方式，提供了对数据集合的操作。Java集合框架位于java.util包下，主要有三个大类：Collection、Map接口以及对集合进行操作的工具类。 Collection List ArrayList：线程不同步。默认初始容量为10，当数组大小不足时增长率为当前长度的50%。 Vector：线程同步。默认初始容量为10，当数组大小不足时增长率为当前长度的100%。它的同步是通过Iterator方法加synchronized实现的。 Stack：线程同步。继承自Vector，添加了几个方法来完成栈的功能。 LinkedList：线程不同步。双端队列形式。 Set：Set是一种不包含重复元素的Collection，Set最多只有一个null元素。 HashSet：线程不同步，内部使用HashMap进行数据存储，提供的方法基本都是调用HashMap的方法，所以两者本质是一样的。集合元素可以为NULL。 NavigableSet：添加了搜索功能，可以对给定元素进行搜索：小于、小于等于、大于、大于等于，放回一个符合条件的最接近给定元素的 key。 TreeSet：线程不同步，内部使用NavigableMap操作。默认元素“自然顺序”排列，可以通过Comparator改变排序。 EnumSet：线程不同步。内部使用Enum数组实现，速度比HashSet快。只能存储在构造函数传入的枚举类的枚举值。 Map HashMap：线程不同步。根据key的hashcode进行存储，内部使用静态内部类Node的数组进行存储，默认初始大小为16，每次扩大一倍。当发生Hash冲突时，采用拉链法（链表）。可以接受为null的键值(key)和值(value)。JDK 1.8中：当单个桶中元素个数大于等于8时，链表实现改为红黑树实现；当元素个数小于6时，变回链表实现。由此来防止hashCode攻击。 LinkedHashMap：保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的. 也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比HashMap慢，不过有种情况例外，当HashMap容量很大，实际数据较少时，遍历起来可能会比LinkedHashMap慢，因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和他的容量有关。 TreeMap：线程不同步，基于 红黑树*- （Red-Black tree）的NavigableMap 实现，能够把它保存的记录根据键排序,默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。** HashTable：线程安全，HashMap的迭代器(Iterator)是fail-fast迭代器。HashTable不能存储NULL的key和value。 ConcurrentHashmap：支持并发操作的 Hash 表，ConcurrentHashmap 具有和 HashTable 同样的功能，并且具有相应的方法。即使所有操作都是线程安全的，但是并不需要进行加锁。 工具类 Collections、Arrays：集合类的一个工具类\\/帮助类，其中提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作。 Comparable、Comparator：一般是用于对象的比较来实现排序，两者略有区别。 类设计者没有考虑到比较问题而没有实现Comparable接口。这是我们就可以通过使用Comparator，这种情况下，我们是不需要改变对象的。 一个集合中，我们可能需要有多重的排序标准，这时候如果使用Comparable就有些捉襟见肘了，可以自己继承Comparator提供多种标准的比较器进行排序。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/collection/2-HashMap.html":{"url":"java/collection/2-HashMap.html","title":"HashMap","keywords":"","body":"HashMap 在get和put的过程中，计算下标时，先对hashCode进行hash操作，然后再通过hash值进一步计算下标，如下图所示： 在对hashCode()计算hash时具体实现是这样的： static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); } 可以看到这个函数大概的作用就是：高16bit不变，低16bit和高16bit做了一个异或。 在设计hash函数时，因为目前的table长度n为2的幂，而计算下标的时候，是这样实现的(使用&位操作，而非%求余)。设计者认为这方法很容易发生碰撞。为什么这么说呢？不妨思考一下，在n - 1为15(0x1111)时，其实散列真正生效的只是低4bit的有效位，当然容易碰撞了。 因此，设计者想了一个顾全大局的方法(综合考虑了速度、作用、质量)，就是把高16bit和低16bit异或了一下。设计者还解释到因为现在大多数的hashCode的分布已经很不错了，就算是发生了碰撞也用O(logn)的tree去做了。仅仅异或一下，既减少了系统的开销，也不会造成的因为高位没有参与下标的计算(table长度比较小时)，从而引起的碰撞。 如果还是产生了频繁的碰撞，会发生什么问题呢？作者注释说，他们使用树来处理频繁的碰撞(we use trees to handle large sets of collisions in bins)，在JEP-180中，描述了这个问题： Improve the performance of java.util.HashMap under high hash-collision conditions by using balanced trees rather than linked lists to store map entries. Implement the same improvement in the LinkedHashMap class. 之前已经提过，在获取HashMap的元素时，基本分两步： 首先根据hashCode()做hash，然后确定bucket的index； 如果bucket的节点的key不是我们需要的，则通过keys.equals()在链中找。 在Java 8之前的实现中是用链表解决冲突的，在产生碰撞的情况下，进行get时，两步的时间复杂度是O(1)+O(n)。因此，当碰撞很厉害的时候n很大，O(n)的速度显然是影响速度的。因此在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，这样复杂度就变成了O(1)+O(logn)了，这样在n很大的时候，能够比较理想的解决这个问题，在Java 8：HashMap的性能提升一文中有性能测试的结果。 Resize 当put时，如果发现目前的bucket占用程度已经超过了Load Factor所希望的比例，那么就会发生resize。在resize的过程，简单的说就是把bucket扩充为2倍，之后重新计算index，把节点再放到新的bucket中。resize的注释是这样描述的： Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table. 大致意思就是说，当超过限制的时候会resize，然而又因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。例如我们从16扩展为32时，具体的变化如下所示： 因此元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。 并发问题 疫苗：JAVA HASHMAP的死循环 在 HashMap Resize的过程中由于本身并不是线程安全，有可能出现死锁的问题。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/collection/3-Concurrenthashmap.html":{"url":"java/collection/3-Concurrenthashmap.html","title":"Concurrenthashmap","keywords":"","body":"ConcurrentHashmap JDK1.7 ConcurrentHashMap的锁分段技术：假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术。首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 ConcurrentHashMap不允许Key或者Value的值为NULL。ConcurrentMaps中不允许空值的主要原因是，在非并发映射中几乎不能容忍的模糊性是无法容纳的。主要的一点是如果map.get（key）返回null，则无法检测密钥是否显式映射为null而密钥未映射。 在非并发映射中，您可以通过map.contains（key）进行检查，但在并发映射中，映射可能在调用之间发生了变化。 Segment类 Put 将一个HashEntry放入到该Segment中，使用自旋机制，减少了加锁的可能性。 final V put(K key, int hash, V value, boolean onlyIfAbsent) { HashEntry node = tryLock() ? null : scanAndLockForPut(key, hash, value); //如果加锁失败，则调用该方法 V oldValue; try { HashEntry[] tab = table; int index = (tab.length - 1) & hash; //同hashMap相同的哈希定位方式 HashEntry first = entryAt(tab, index); for (HashEntry e = first;;) { if (e != null) { //若不为null，则持续查找，知道找到key和hash值相同的节点，将其value更新 K k; if ((k = e.key) == key || (e.hash == hash && key.equals(k))) { oldValue = e.value; if (!onlyIfAbsent) { e.value = value; ++modCount; } break; } e = e.next; } else { //若头结点为null if (node != null) //在遍历key对应节点链时没有找到相应的节点 node.setNext(first); //当前修改并不需要让其他线程知道，在锁退出时修改自然会 //更新到内存中,可提升性能 else node = new HashEntry(hash, key, value, first); int c = count + 1; if (c > threshold && tab.length scanAndLockForPut 该操作持续查找key对应的节点链中是否已存在该节点，如果没有找到已存在的节点，则预创建一个新节点，并且尝试n次，直到尝试次数超出限制，才真正进入等待状态，即所谓的 自旋等待。 private HashEntry scanAndLockForPut(K key, int hash, V value) { //根据hash值找到segment中的HashEntry节点 HashEntry first = entryForHash(this, hash); //首先获取头结点 HashEntry e = first; HashEntry node = null; int retries = -1; // negative while locating node while (!tryLock()) { //持续遍历该哈希链 HashEntry f; // to recheck first below if (retries (hash, key, value, null); retries = 0; } else if (key.equals(e.key)) retries = 0; else e = e.next; } else if (++retries > MAX_SCAN_RETRIES) { //尝试次数超出限制，则进行自旋等待 lock(); break; } /*当在自旋过程中发现节点链的链头发生了变化，则更新节点链的链头， 并重置retries值为－1，重新为尝试获取锁而自旋遍历*/ else if ((retries & 1) == 0 && (f = entryForHash(this, hash)) != first) { e = first = f; // re-traverse if entry changed retries = -1; } } return node; } remove 用于移除某个节点，返回移除的节点值。 final V remove(Object key, int hash, Object value) { if (!tryLock()) scanAndLock(key, hash); V oldValue = null; try { HashEntry[] tab = table; int index = (tab.length - 1) & hash; //根据这种哈希定位方式来定位对应的HashEntry HashEntry e = entryAt(tab, index); HashEntry pred = null; while (e != null) { K k; HashEntry next = e.next; if ((k = e.key) == key || (e.hash == hash && key.equals(k))) { V v = e.value; if (value == null || value == v || value.equals(v)) { if (pred == null) setEntryAt(tab, index, next); else pred.setNext(next); ++modCount; --count; oldValue = v; } break; } pred = e; e = next; } } finally { unlock(); } return oldValue; } Clear 要首先对整个segment加锁，然后将每一个HashEntry都设置为null。 final void clear() { lock(); try { HashEntry[] tab = table; for (int i = 0; i Put public V put(K key, V value) { Segment s; if (value == null) throw new NullPointerException(); int hash = hash(key); //求出key的hash值 int j = (hash >>> segmentShift) & segmentMask; //求出key在segments数组中的哪一个segment中 if ((s = (Segment)UNSAFE.getObject (segments, (j Get public V get(Object key) { Segment s; HashEntry[] tab; int h = hash(key); //找出对应的segment的位置 long u = (((h >>> segmentShift) & segmentMask) )UNSAFE.getObjectVolatile(segments, u)) != null && (tab = s.table) != null) { //使用Unsafe获取对应的Segmen for (HashEntry e = (HashEntry) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) & h)) Size 求出所有的HashEntry的数目，先尝试的遍历查找、计算2遍，如果两遍遍历过程中整个Map没有发生修改（即两次所有Segment实例中modCount值的和一致），则可以认为整个查找、计算过程中Map没有发生改变。否则,需要对所有segment实例进行加锁、计算、解锁，然后返回。 public int size() { final Segment[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn't retry try { for (;;) { if (retries++ == RETRIES_BEFORE_LOCK) { for (int j = 0; j seg = segmentAt(segments, j); if (seg != null) { sum += seg.modCount; int c = seg.count; if (c RETRIES_BEFORE_LOCK) { for (int j = 0; j JDK1.8 在JDK1.8中对ConcurrentHashmap做了两个改进： 取消segments字段，直接采用transient volatile HashEntry[] table保存数据，采用table数组元素作为锁，从而实现了对每一行数据进行加锁，进一步减少并发冲突的概率。 将原先 table数组＋单向链表 的数据结构，变更为 table数组＋单向链表＋红黑树 的结构。对于hash表来说，最核心的能力在于将key hash之后能均匀的分布在数组中。如果hash之后散列的很均匀，那么table数组中的每个队列长度主要为0或者1。但实际情况并非总是如此理想，虽然ConcurrentHashMap类默认的加载因子为0.75，但是在数据量过大或者运气不佳的情况下，还是会存在一些队列长度过长的情况，如果还是采用单向列表方式，那么查询某个节点的时间复杂度为O(n)；因此，对于个数超过8(默认值)的列表，jdk1.8中采用了红黑树的结构，那么查询的时间复杂度可以降低到O(logN)，可以改进性能。 Put final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); // 得到 hash 值 int hash = spread(key.hashCode()); // 用于记录相应链表的长度 int binCount = 0; for (Node[] tab = table;;) { Node f; int n, i, fh; // 如果数组\"空\"，进行数组初始化 if (tab == null || (n = tab.length) == 0) // 初始化数组，后面会详细介绍 tab = initTable(); // 找该 hash 值对应的数组下标，得到第一个节点 f else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) { // 如果数组该位置为空， // 用一次 CAS 操作将这个新值放入其中即可，这个 put 操作差不多就结束了，可以拉到最后面了 // 如果 CAS 失败，那就是有并发操作，进到下一个循环就好了 if (casTabAt(tab, i, null, new Node(hash, key, value, null))) break; // no lock when adding to empty bin } // hash 居然可以等于 MOVED，这个需要到后面才能看明白，不过从名字上也能猜到，肯定是因为在扩容 else if ((fh = f.hash) == MOVED) // 帮助数据迁移，这个等到看完数据迁移部分的介绍后，再理解这个就很简单了 tab = helpTransfer(tab, f); else { // 到这里就是说，f 是该位置的头结点，而且不为空 V oldVal = null; // 获取数组该位置的头结点的监视器锁 synchronized (f) { if (tabAt(tab, i) == f) { if (fh >= 0) { // 头结点的 hash 值大于 0，说明是链表 // 用于累加，记录链表的长度 binCount = 1; // 遍历链表 for (Node e = f;; ++binCount) { K ek; // 如果发现了\"相等\"的 key，判断是否要进行值覆盖，然后也就可以 break 了 if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } // 到了链表的最末端，将这个新值放到链表的最后面 Node pred = e; if ((e = e.next) == null) { pred.next = new Node(hash, key, value, null); break; } } } else if (f instanceof TreeBin) { // 红黑树 Node p; binCount = 2; // 调用红黑树的插值方法插入新节点 if ((p = ((TreeBin)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { // 判断是否要将链表转换为红黑树，临界值和 HashMap 一样，也是 8 if (binCount >= TREEIFY_THRESHOLD) // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换， // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树 // 具体源码我们就不看了，扩容部分后面说 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } // addCount(1L, binCount); return null; } Get 计算 hash 值 根据 hash 值找到数组对应位置: (n - 1) & h 根据该位置处结点性质进行相应查找 如果该位置为 null，那么直接返回 null 就可以了 如果该位置处的节点刚好就是我们需要的，返回该节点的值即可 如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树，后面我们再介绍 find 方法 如果以上 3 条都不满足，那就是链表，进行遍历比对即可 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/collection/4-BlockQueue.html":{"url":"java/collection/4-BlockQueue.html","title":"BlockQueue","keywords":"","body":"BlockingQueue BlockingQueue 支持当获取队列元素但是队列为空时，会阻塞等待队列中有元素再返回；也支持添加元素时，如果队列已满，那么等到队列可以放入新元素时再放入。 其提供了4种类型的方法： Throws exception Special value Blocks Times out Insert add(e) offer(e) put(e) offer(e, time, unit) Remove remove() poll() take() poll(time, unit) Examine element() peek() not applicable not applicable BlockingQueue不接受 null 元素。所有实现应当抛出 NullPointerException 在所有的 add,put以及offer方法上。null被用来标记poll失败。 在任意时刻，当有界BlockingQueue 队列元素放满之后，所有的元素都将在放入的时候阻塞。无界BlockingQueue 没有任何容量限制，容量大小始终是Integer.MAX_VALUE。 BlockingQueue的实现是用于 生产者-消费者 的队列，同时也支持 Collection 接口。所以可通过remove(x)来移除队列里的一个元素。通常情况下，这样的操作效率不是很好，只在诸如队列消息被取消的情况下才会偶尔使用。 BlockingQueue 的实现都是线程安全的。所有 queue 的方法都需要通过内部锁机制或者其他形式来进行并发控制来实现其原子操作。然而，Collection 接口的方法，比如：addAll, containsAll, retainAll 以及 removeAll 都没有必要进行原子操作，除非实现类有特别说明。所以对于addAll(c)有可能在添加部分c元素后抛出异常。 BlockingQueue 本质上不支持任何的 close 或者 shutdown 操作，来表明不会有新的元素添加。如果需要这些特性，得实现类来支持。 ArrayBlockingQueue ArrayBlockingQueue 是底层由数组存储的有界队列。遵循FIFO，所以在队首的元素是在队列中等待时间最长的，而在队尾的则是最短时间的元素。新元素被插入到队尾，队列的取出 操作队首元素。 这是一个经典的有界缓存，由一个长度确定的数组持有所有由生产者插入、由消费者取出的元素。一旦创建，整个队列的容量将不会改变。尝试向一个已满的队列 put 将会导致调用被阻塞，同样的向一个空队列 take 也会阻塞。 该队列支持队等待的生产者和消费者实施可选的公平策略。默认情况下，是非公平策略。可以通过构造函数来指定是否进行公平策略。一般情况下公平策略会减小吞吐量，但是也会降低可变性以及防止饥饿效应。 实现 ArrayBlockingQueue 内部使用了 ReentrantLock 以及两个 Condition 来实现。 /** Main lock guarding all access */ final ReentrantLock lock; /** Condition for waiting takes */ private final Condition notEmpty; /** Condition for waiting puts */ private final Condition notFull; PUT 方法也很简单，就是 Condition 的应用。 public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { //队列已满，wait 在 condition 上 while (count == items.length) notFull.await(); enqueue(e); } finally { lock.unlock(); } } take 方法也同样的。 public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { //队列为空，wait 在 condition 上 while (count == 0) notEmpty.await(); return dequeue(); } finally { lock.unlock(); } } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/concurrent/":{"url":"java/concurrent/","title":"并发","keywords":"","body":" 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/concurrent/1-thread.html":{"url":"java/concurrent/1-thread.html","title":"线程","keywords":"","body":"Java线程 线程定义 线程（英语：thread）是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。在Unix System V及SunOS中也被称为轻量进程（lightweight processes），但轻量进程更多指内核线程（kernel thread），而把用户线程（user thread）称为线程。 线程是独立调度和分派的基本单位。线程可以操作系统内核调度的内核线程，如Win32线程；由用户进程自行调度的用户线程，如Linux平台的POSIX Thread；或者由内核与用户进程，如Windows 7的线程，进行混合调度。 同一进程中的多条线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等。但同一进程中的多个线程有各自的调用栈（call stack），自己的寄存器环境（register context），自己的线程本地存储（thread-local storage）。 一个进程可以有很多线程，每条线程并行执行不同的任务。 线程实现 Java中的线程都是调用的原生系统的本地函数，Java线程模型是基于操作系统原生线程模型实现的，实现线程有三种方式：内核线程实现、用户线程实现、混合线程实现。 内核线程实现 直接由操作系统内核支持的线程，通过内核来完成进程切换。每个内核线程就是一个内核的分身，这样操作系统就可以同时处理多件事情，支持多线程的内核被称为多线程内核。 程序一般不直接使用内核线程，而是使用一种高级接口——轻量级进程，轻量级进程就是我们通常意义上的线程，可以获得内核线程的支持，与内核线程构成1:1的线程模型。 由于得到内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即时有一个轻量级进程在系统调用中阻塞，也不会影响整个进程，但也有其局限性：由于是基于内核线程实现的，各种操作，如创建、销毁及同步，都需要进行系统调用。而系统调用代价较高，需要在内核态和用户态来回切换。 用户线程实现 从广义上说，一个线程不是内核线程，就是用户线程，所以轻量级进程也属于用户线程。狭义的用户线程是指完全建立在用户空间上的，系统内核不能感知到其存在。 用户线程的创建、同步、销毁和调度都是在用户空间实现的，因此相对较快，代价相对较低。这种用户线程和进程是N:1的线程模型。 由于用户线程没有内核的支持，线程的创建、切换和调度是需要自己实现的，而且由于操作系统只把CPU资源分配到进程，那诸如“阻塞如何处理”、“多处理器系统中如何将线程映射到其他处理器”这类问题解决起来异常复杂。 混合实现 这种实现模式将内核线程与用户线程一起使用，在这种方式下既存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间，因此用户线程的创建、切换等操作依旧低廉。而操作系统提供的轻量级进程则作为用户线程和内核线程的桥梁，这样就可以使用内核提供的线程调度及处理器映射。这种实现下，用户线程和轻量级进程是M:N的模式。 Java线程调度 线程调度分为协同式和抢占式。 协同式调度：线程的执行时间由线程自己控制，这种的实现很简单，但是很可能造成很严重的后果。 抢占式调度：由操作系统分配线程执行的时间，线程切换的决定权在操作系统。 有时候我们需要为某些线程多分配时间，这时我们就需要用到线程优先级的方法，Java提供了10种优先级。Java优先级是在操作系统的原生线程优先级上实现的，所以对于同一个优先级，不同的操作系统可能有不同的表现，也就是说 Java线程优先级不是可靠的。 Java线程状态切换 Java线程模型定义了 6 种状态，在任意一个时间点，一个线程有且只有其中一个状态： 新建（New）：新建的Thread，尚未开始。 运行（Runable）：包含操作系统线程状态中的Running、Ready，也就是处于正在执行或正在等待CPU分配时间的状态。 无限期等待（Waiting）：处于这种状态的线程不会被分配CPU时间，等待其他线程唤醒。 限期等待（Timed Waiting）：处于这种状态的线程不会被分配CPU时间，在一定时间后会由系统自动唤醒。 阻塞（Blocked）：在等待获得排他锁。 结束（Terminated）：已终止的线程。 线程安全 多线程访问同一代码，不会产生不确定的结果。 Java 线程池 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/concurrent/2-volatile.html":{"url":"java/concurrent/2-volatile.html","title":"Volatile","keywords":"","body":"Volatile原理 计算机内存模型 计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码： i = i + 1; 当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后 CPU 执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。 这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核 CPU 中，每条线程可能运行于不同的 CPU 中，因此 每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。比如同时有两个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？ 可能出现这种情况：初始时，两个线程分别读取i的值存入各自所在的 CPU 的高速缓存当中，然后 线程1 进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。 为了解决缓存不一致性问题，通常来说有以下两种解决方法： 通过在总线加LOCK#锁的方式 通过 缓存一致性协议 这两种方式都是硬件层面上提供的方式。 在早期的 CPU 当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为 CPU 和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他 CPU 对其他部件访问（如内存），从而使得只能有一个 CPU 能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。 所以就出现了缓存一致性协议。最出名的就是 Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 　Java内存模型 在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。 Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。 在Java中，执行下面这个语句： i = 10; 执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。那么Java语言本身对 原子性、可见性以及有序性提供了哪些保证呢？ 原子性 即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i：请分析以下哪些操作是原子性操作： x = 10; //语句1 y = x; //语句2 x++; //语句3 x = x + 1; //语句4 咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。 语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。 也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。 从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 可见性 可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 对于可见性，Java提供了volatile关键字来保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 有序性 即程序执行的顺序按照代码的先后顺序执行。 指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 下面就来具体介绍下happens-before原则（先行发生原则）： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。 第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。 第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 第四条规则实际上就是体现happens-before原则具备传递性。 深入剖析Volatile关键字 Volatile的语义 一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义： 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 　- 禁止进行指令重排序。 先看一段代码，假如线程1先执行，线程2后执行： //线程1 boolean stop = false; while(!stop){ doSomething(); } //线程2 stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。 那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。但是用volatile修饰之后就变得不一样了： 　- 使用volatile关键字会强制将修改的值立即写入主存； 使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。 那么线程1读取到的就是最新的正确的值。 Volatile与原子性 从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？ 下面看一个例子： public class Test { public volatile int inc = 0; public void increase() { inc++; } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。 这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。 在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现： 假如某个时刻变量inc的值为10， 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了； 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。 那么两个线程分别进行了一次自增操作后，inc只增加了1。 解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。解决的方法也就是对提供原子性的自增操作即可。 在Java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。 Volatile与有序性 在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。volatile关键字禁止指令重排序有两层意思： 当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见，在其后面的操作肯定还没有进行； 在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 可能上面说的比较绕，举个简单的例子： //x、y为非volatile变量 //flag为volatile变量 x = 2; //语句1 y = 0; //语句2 flag = true; //语句3 x = 4; //语句4 y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 Volatile的原理和实现机制 前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。下面这段话摘自《深入理解Java虚拟机》： 观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令 lock前缀指令实际上相当于一个 内存屏障（也成内存栅栏），内存屏障会提供3个功能： 它 确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 它会 强制将对缓存的修改操作立即写入主存； 如果是写操作，它会导致其他CPU中对应的缓存行无效。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/concurrent/3-synchronized.html":{"url":"java/concurrent/3-synchronized.html","title":"Synchronized","keywords":"","body":"Synchronized原理 在多线程并发编程中Synchronized一直是元老级角色，很多人都会称呼它为重量级锁，但是随着Java SE1.6对Synchronized进行了各种优化之后，有些情况下它并不那么重了，本文详细介绍了Java SE1.6中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁，以及锁的存储结构和升级过程。 CAS(Compare and Swap)，用于在硬件层面上提供原子性操作。在 Intel 处理器中，比较并交换通过指令cmpxchg实现。比较是否和给定的数值一致，如果一致则修改，不一致则不修改。 基础 Java中的每一个对象都可以作为锁。 对于同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前对象的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。那么锁存在哪里呢？锁里面会存储什么信息呢？ 同步的原理 JVM规范规定JVM基于进入和退出 Monitor 对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。 monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 的所有权，即尝试获得对象的锁。 Java对象头 锁存在Java对象头里。如果对象是数组类型，则虚拟机用3个Word（字宽）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，一字宽等于四字节，即32bit。 长度 内容 说明 32/64bit Mark Word 存储对象的hashCode或锁信息等 32/64bit Class Metadata Address 存储到对象类型数据的指针 32/64bit Array length 数组的长度（如果当前对象是数组） Java对象头里的Mark Word里默认存储对象的HashCode，分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下： 25 bit 4bit 1bit是否是偏向锁 2bit锁标志位 无锁状态 对象的hashCode 对象分代年龄 0 01 在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据： 锁的升级 Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。\\ 线程对锁的竞争 当多个线程同时请求某个对象监视器时，对象监视器会设置几种状态用来区分请求的线程： Contention List：所有请求锁的线程将被首先放置到该竞争队列 Entry List：Contention List中那些有资格成为候选人的线程被移到Entry List Wait Set：那些调用wait方法被阻塞的线程被放置到Wait Set OnDeck：任何时刻最多只能有一个线程正在竞争锁，该线程称为OnDeck Owner：获得锁的线程称为Owner !Owner：释放锁的线程 新请求锁的线程将首先被加入到ConetentionList中，当某个拥有锁的线程（Owner状态）调用unlock之后，如果发现EntryList为空则从ContentionList中移动线程到EntryList，下面说明下ContentionList和EntryList的实现方式： ContentionList ContentionList并不是一个真正的Queue，而只是一个虚拟队列，原因在于ContentionList是由Node及其next指针逻辑构成，并不存在一个Queue的数据结构。ContentionList是一个后进先出（LIFO）的队列，每次新加入Node时都会在队头进行，通过CAS改变第一个节点的的指针为新增节点，同时设置新增节点的next指向后续节点，而取得操作则发生在队尾。显然，该结构其实是个Lock-Free的队列。 因为只有Owner线程才能从队尾取元素，也即线程出列操作无争用，当然也就避免了CAS的ABA问题。 EntryList EntryList与ContentionList逻辑上同属等待队列，ContentionList会被线程并发访问，为了降低对ContentionList队尾的争用，而建立EntryList。Owner线程在unlock时会从ContentionList中迁移线程到EntryList，并会指定EntryList中的某个线程（一般为Head）为Ready（OnDeck）线程。Owner线程并不是把锁传递给OnDeck线程，只是把竞争锁的权利交给OnDeck，OnDeck线程需要重新竞争锁。这样做虽然牺牲了一定的公平性，但极大的提高了整体吞吐量，在Hotspot中把OnDeck的选择行为称之为“竞争切换”。 OnDeck线程获得锁后即变为owner线程，无法获得锁则会依然留在EntryList中，考虑到公平性，在EntryList中的位置不发生变化（依然在队头）。如果Owner线程被wait方法阻塞，则转移到WaitSet队列；如果在某个时刻被notify/notifyAll唤醒，则再次转移到EntryList。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/concurrent/4-AQS.html":{"url":"java/concurrent/4-AQS.html","title":"AQS","keywords":"","body":"AQS AQS 提供一个框架，用于实现依赖于先进先出（FIFO）等待队列 的阻塞锁和相关同步器（信号量，事件等）。对于大多数依赖单个原子 int 值表示状态的同步器，该类可以作为十分有用的基类。子类必须定义所有的protected方法（包括tryAcquire、tryRelease），来改变这个状态，并且定义哪些状态代表来对象被使用和被释放。鉴于这些，该类中其他的方法用来实现队列和阻塞的机制。子类可以维护其他状态字段，但是只有使用 getState 、setState以及 compareAndSetState 来原子的操作状态值。 子类需要定义非 public 的内部工具类用于实现其内部类的同步属性。AbstractQueuedSynchronizer 类不实现任何同步接口，相反，它定义了诸如acquireInterruptibly之类的方法，可以被具体的锁和相关的同步器适当地调用，以实现它们的公共方法。 该类支持默认的独占模式和共享模式。当一个线程处在独占模式下，其他试图 acquire 的线程都无法成功。共享模式可以同时被多个线程 acquire成功。在具体的应用场景中该类无法理解这些区别，当共享模式 acquire 成功之后，下一个线程（如果有一个存在）必须判定是否能够acquire。线程等待在不同的模式里但是会共享同一个FIFO队列。通常来说，子类只需要支持其中一种模式，但是如果都支持，可以参照ReadWriteLock。子类不需要定义不支持模式的方法。 该类定义AbstractQueuedSynchronizer.ConditionObject内部类，可以被子类使用的 Condition 实现，来支持独占模式 isHeldExclusively 判定当前线程的同步是否是独占模式，可用通过release方法与 getState 方法来完全释放当前对象，在将保存的状态值调用acquire，最终将此对象恢复到其先前获取的状态。AbstractQueuedSynchronizer没有方法来创建 Condition，所以如果无法满足这个约束，则不要使用它。AbstractQueuedSynchronizer.ConditionObject 的行为与具体的同步器实现有关。 该类为内部队列提供检查，检测和监视方法，以及 在condition objects上的类似方法。 这些方法可以根据需要使用 AbstractQueuedSynchronizer 用于它们的同步机制。该类的序列化仅存储 atomic int 的状态值，因此反序列化对象的线程队列为空。 使用 为了使用该类去创建一个同步器，需要重新定义以下方法，并使用 getState, setState, compareAndSetState 方法来改变同步状态。 tryAcquire tryRelease tryAcquireShared tryReleaseShared isHeldExclusively 上述所有方法默认实现都会抛出 UnsupportedOperationException。这个方法的具体实现必须保证内部的线程安全，并且应该快速并且不会阻塞。所有其他方法均为 final，因为他们不能独立变化。 You may also find the inherited methods from AbstractOwnableSynchronizer useful to keep track of the thread owning an exclusive synchronizer. You are encouraged to use them -- this enables monitoring and diagnostic tools to assist users in determining which threads hold locks. 也许你发现一些继承自 AbstractOwnableSynchronizer 的方法非常有助于线程保持拥有其独占同步器。同时我们也鼓励使用他们，有助于监控和诊断工具判定哪些线程持有来锁。 ReentrantLock 公平锁相比与非公平锁在 tryAcquire中会多判定一个 hasQueuedPredecessors，如果为 false（队列头为当前线程--已获取锁 or 队列为空）并且成功修改状态值，则可以认为获取锁成功，这样才是重入，不然加到队尾就会有麻烦。 ReentrantLock 中通过两个子类 FairSync 和 NoFairSync 继承 AQS 来实现锁。在Lock方法中，直接调用 AQS 的 acquire，acquire会调用 NoFairSync 中的tryAcquire来尝试让当前线程直接获取锁。如果失败则会创建链表节点，将当前线程加入队列，并park。当release方法被调用后，会寻找队列下一个节点进行 unpark，这样他就有机会在acquireQueued中获取锁。 公平和非公平就体现在 tryAcquire 方法中，FairSync会判定当前线程是否已获取锁 or 队列为空，在这样的情况下才会尝试获取锁。而NoFairSync会直接来获取锁。 Condition Condition 因子将 Object monitor 方法（wait, notify and notifyAll）拆分为不同的对象，通过将它们与 Lock 相结合来实现每个对象具有多个等待集的效果。任何 Lock 可以替代 synchronized 关键字的地方，都可以用Condition 来替换Object monitor 方法。 Conditions（也称为 条件队列 或者 条件变量）提供了一种方法 -- 让线程暂停执行，直到其他线程基于某种条件唤醒。在多个线程中访问一些共享的状态信息，是需要进行保护的，所以 Lock 与 Condition 有某种形式的关联。Condition提供的关键属性是它以原子方式释放关联的锁并挂起当前线程，就像Object.wait一样。 Condition 本质上是绑定到 Lock。可以通过 Lock.newCondition() 来获取一个 Condition 实例。 Condition 的实现可以提供相比于 Object monitor方法不一样的行为和语义，比如：被通知调起的顺序、在通知时不需要持有锁。如果实现类提供了不一样的语义，必须在文档中进行说明。 Condition 实例只是普通的对象，可以用在同步语句中，并且有他们自己的 Object monitor的wait和 notification 方法。获取 Condition 对象的 Object monitor 或者使用其 monitor 方法，与Lock 中使用 Condition 的 wait 或者 signal 方法没有任何关系。为了避免混淆，不建议使用 Condition 的 Object monitor 方法，除非在它自己的实现里。 实现类需要注意 虚假唤醒（spurious wakeup）：开发者最好将条件 wait 方法放在循环中 Condition 有3中 wait 形式（interruptible, non-interruptible, and timed），在不同平台的底层实现可能不同。因此，不需要对三种 wait 定义一致的语义，也不需要支持中断形式的线程暂停。 AbstractQueuedSynchronizer.ConditionObject /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; 在 ConditionObject 的内部维护了一个队列：条件队列，与 AbstractQueuedSynchronizer 里的 等待队列 不同。 基本上，把这张图看懂，你也就知道 condition 的处理流程了。所以，我先简单解释下这图，然后再具体地解释代码实现。 条件队列和等待队列的节点，都是 Node 的实例，因为条件队列的节点是需要转移到等待队列中去的； 我们知道一个 ReentrantLock 实例可以通过多次调用 newCondition() 来产生多个 Condition 实例，这里对应 condition1 和 condition2。注意，ConditionObject 只有两个属性 firstWaiter 和 lastWaiter； 每个 condition 有一个关联的条件队列，如线程 1 调用 condition1.await() 方法即可将当前线程 1 包装成 Node 后加入到条件队列中，然后阻塞在这里，不继续往下执行，条件队列是一个单向链表； 调用condition1.signal() 触发一次唤醒，此时唤醒的是队头，会将condition1 对应的条件队列的 firstWaiter（队头） 移到等待队列的队尾，等待获取锁，获取锁后 await 方法才能返回，继续往下执行。 上面的 2->3->4 描述了一个最简单的流程，没有考虑中断、signalAll、还有带有超时参数的 await 方法等，不过把这里弄懂是这节的主要目的。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/concurrent/7-CountDownLatch.html":{"url":"java/concurrent/7-CountDownLatch.html","title":"CountDownLatch","keywords":"","body":"CountDownLatch CountDownLatch 是可以使一个或者多个线程等待其他线程完成某些操作的同步器。CountDownLatch 通过一个给定的数字 count 进行初始化。调用 await 方法的线程会一直阻塞到其他线程调用 countDown 将 count 变为0，这时所有的线程都将释放，并且后续的 await 方法调用都会立即返回。count 值不能重置。如果你需要重置 count 请考虑使用 CyclicBarrier。 CountDownLatch 是一个能力很强的同步工具，可以用在多种途径。CountDownLatch 最重要的属性是其不要求 调用 countDown 的线程等待到 count 为0，只是要求所有 await 调用线程等待。 CountDownLatch 内部使用的是 AQS，AQS 里面的 state 是一个整数值，这边用一个 int count 参数其实初始化就是设置了这个值，所有调用了 await 方法的等待线程会挂起，然后有其他一些线程会做 state = state - 1 操作，当 state 减到 0 的同时，那个将 state 减为 0 的线程会负责唤醒 所有调用了 await 方法的线程。 countDown() 方法每次调用都会将 state 减 1，直到 state 的值为 0；而 await 是一个阻塞方法，当 state 减为 0 的时候，await 方法才会返回。await 可以被多个线程调用，读者这个时候脑子里要有个图：所有调用了 await 方法的线程阻塞在 AQS 的阻塞队列中，等待条件满足（state == 0），将线程从队列中一个个唤醒过来。 await() 方法，它代表线程阻塞，等待 state 的值减为 0。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/concurrent/5-threadlocal.html":{"url":"java/concurrent/5-threadlocal.html","title":"Threadlocal","keywords":"","body":"Threadlocal原理 ThreadLocal 为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。当使用 ThreadLocal 维护变量时，ThreadLocal 为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。 每个线程中都保有一个ThreadLocalMap的成员变量，ThreadLocalMap内部采用WeakReference数组保存，数组的key即为ThreadLocal内部的Hash值。 内存泄漏 ThreadLocalMap 使用 ThreadLocal 的弱引用作为 key ，如果一个 ThreadLocal 没有外部强引用来引用它，那么系统 GC 的时候，这个 ThreadLocal 势必会被回收，这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry ，就没有办法访问这些 key 为 null 的 Entry 的 value，如果当前线程再迟迟不结束的话，这些 key 为 null 的 Entry 的 value 就会一直存在一条强引用链：Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value 永远无法回收，造成内存泄漏。 static class Entry extends WeakReference> { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal k, Object v) { super(k); value = v; } } 其实，ThreadLocalMap 的设计中已经考虑到这种情况，也加上了一些防护措施：在 ThreadLocal 的 get(),set(),remove()的时候都会清除线程 ThreadLocalMap 里所有 key 为 null 的 value 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/concurrent/6-interrupt.html":{"url":"java/concurrent/6-interrupt.html","title":"线程中断","keywords":"","body":"线程中断 中断不是类似 linux 里面的命令 kill -9 pid，不是说我们中断某个线程，这个线程就停止运行了。中断代表线程状态，每个线程都关联了一个中断状态，是一个 true 或 false 的 boolean 值，初始值为 false。 关于中断状态，我们需要重点关注 Thread 类中的以下几个方法： // Thread 类中的实例方法，持有线程实例引用即可检测线程中断状态 public boolean isInterrupted() {} // Thread 中的静态方法，检测调用这个方法的线程是否已经中断 // 注意：这个方法返回中断状态的同时，会将此线程的中断状态重置为 false // 所以，如果我们连续调用两次这个方法的话，第二次的返回值肯定就是 false 了 public static boolean interrupted() {} // Thread 类中的实例方法，用于设置一个线程的中断状态为 true public void interrupt() {} 我们说中断一个线程，其实就是设置了线程的 interrupted status 为 true，至于说被中断的线程怎么处理这个状态，那是那个线程自己的事。如以下代码： while (!Thread.interrupted()) { doWork(); System.out.println(\"我做完一件事了，准备做下一件，如果没有其他线程中断我的话\"); } 这种代码就是会响应中断的，它会在干活的时候先判断下中断状态，不过，除了 JDK 源码外，其他用中断的场景还是比较少的，毕竟 JDK 源码非常讲究。 当然，中断除了是线程状态外，还有其他含义，否则也不需要专门搞一个这个概念出来了。如果线程处于以下三种情况，那么当线程被中断的时候，能自动感知到： 来自 Object 类的 wait()、wait(long)、wait(long, int)，来自 Thread 类的join()、join(long)、join(long, int)、sleep(long)、sleep(long, int) 这几个方法的相同之处是，方法上都有: throws InterruptedException 如果线程阻塞在这些方法上（我们知道，这些方法会让当前线程阻塞），这个时候如果其他线程对这个线程进行了中断，那么这个线程会从这些方法中立即返回，抛出 InterruptedException 异常，同时重置中断状态为 false。 实现了 InterruptibleChannel 接口的类中的一些 I/O 阻塞操作，如 DatagramChannel 中的 connect 方法和 receive 方法等 如果线程阻塞在这里，中断线程会导致这些方法抛出 ClosedByInterruptException 并重置中断状态。 Selector 中的 select 方法 一旦中断，方法立即返回 对于以上 3 种情况是最特殊的，因为他们能自动感知到中断（这里说自动，当然也是基于底层实现），并且在做出相应的操作后都会重置中断状态为 false。 那是不是只有以上 3 种方法能自动感知到中断呢？不是的，如果线程阻塞在 LockSupport.park(Object obj) 方法，也叫挂起，这个时候的中断也会导致线程唤醒，但是唤醒后不会重置中断状态，所以唤醒后去检测中断状态将是 true。 InterruptedException 概述 它是一个特殊的异常，不是说 JVM 对其有特殊的处理，而是它的使用场景比较特殊。通常，我们可以看到，像 Object 中的 wait() 方法，ReentrantLock 中的 lockInterruptibly() 方法，Thread 中的 sleep() 方法等等，这些方法都带有 throws InterruptedException，我们通常称这些方法为阻塞方法（blocking method）。 阻塞方法一个很明显的特征是，它们需要花费比较长的时间（不是绝对的，只是说明时间不可控），还有它们的方法结束返回往往依赖于外部条件，如 wait 方法依赖于其他线程的 notify，lock 方法依赖于其他线程的 unlock 等等。 当我们看到方法上带有 throws InterruptedException 时，我们就要知道，这个方法应该是阻塞方法，我们如果希望它能早点返回的话，我们往往可以通过中断来实现。 除了几个特殊类（如 Object，Thread等）外，感知中断并提前返回是通过轮询中断状态来实现的。我们自己需要写可中断的方法的时候，就是通过在合适的时机（通常在循环的开始处）去判断线程的中断状态，然后做相应的操作（通常是方法直接返回或者抛出异常）。当然，我们也要看到，如果我们一次循环花的时间比较长的话，那么就需要比较长的时间才能感知到线程中断了。 处理中断 一旦中断发生，我们接收到了这个信息，然后怎么去处理中断呢？本小节将简单分析这个问题。 我们经常会这么写代码： try { Thread.sleep(10000); } catch (InterruptedException e) { // ignore } // go on 当 sleep 结束继续往下执行的时候，我们往往都不知道这块代码是真的 sleep 了 10 秒，还是只休眠了 1 秒就被中断了。这个代码的问题在于，我们将这个异常信息吞掉了。（对于 sleep 方法，我相信大部分情况下，我们都不在意是否是中断了，这里是举例） AQS 的做法很值得我们借鉴，我们知道 ReentrantLock 有两种 lock 方法： public void lock() { sync.lock(); } public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } 前面我们提到过，lock() 方法不响应中断。如果 thread1 调用了 lock() 方法，过了很久还没抢到锁，这个时候 thread2 对其进行了中断，thread1 是不响应这个请求的，它会继续抢锁，当然它不会把“被中断”这个信息扔掉。我们可以看以下代码： public final void acquire(int arg) { if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 我们看到，这里也没做任何特殊处理，就是记录下来中断状态。 // 这样，如果外层方法需要去检测的时候，至少我们没有把这个信息丢了 selfInterrupt();// Thread.currentThread().interrupt(); } 而对于 lockInterruptibly() 方法，因为其方法上面有throws InterruptedException ，这个信号告诉我们，如果我们要取消线程抢锁，直接中断这个线程即可，它会立即返回，抛出 InterruptedException 异常。 在并发包中，有非常多的这种处理中断的例子，提供两个方法，分别为响应中断和不响应中断，对于不响应中断的方法，记录中断而不是丢失这个信息。如 Condition 中的两个方法就是这样的： void await() throws InterruptedException; void awaitUninterruptibly(); 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/gc/":{"url":"java/gc/","title":"GC","keywords":"","body":" 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/gc/11-jvm-gc.html":{"url":"java/gc/11-jvm-gc.html","title":"Java 虚拟机垃圾收集","keywords":"","body":"JVM垃圾回收 本片文章均指 HotSpot 的GC Java堆中存放着大量的Java对象实例，在垃圾收集器回收内存前，第一件事情就是确定哪些对象是“活着的”，哪些是可以回收的。 引用计数算法 引用计数算法是判断对象是否存活的基本算法：给每个对象添加一个引用计数器，没当一个地方引用它的时候，计数器值加1；当引用失效后，计数器值减1。但是这种方法有一个致命的缺陷，当两个对象相互引用时会导致这两个都无法被回收。 根搜索算法 在主流的商用语言中（Java、C#...）都是使用根搜索算法来判断对象是否存活。对于程序来说，根对象总是可以访问的。从这些根对象开始，任何可以被触及的对象都被认为是\"活着的\"的对象。无法触及的对象被认为是垃圾，需要被回收。 Java虚拟机的根对象集合根据实现不同而不同，但是总会包含以下几个方面： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中的类静态属性引用的变量。 方法区中的常量引用的变量。 本地方法JNI的引用对象。 区分活动对象和垃圾的两个基本方法是引用计数和根搜索。 引用计数是通过为堆中每个对象保存一个计数来区分活动对象和垃圾。根搜索算法实际上是追踪从根结点开始的引用图。 引用对象 引用对象封装了指向其他对象的连接：被指向的对象称为引用目标。Reference有三个直接子类SoftReference、WeakReference、PhantomReference分别代表：软引用、弱引用、虚引用。强引用在Java中是普遍存在的，类似Object o = new Object();这类引用就是强引用，强引用和以上引用的区别在于：强引用禁止引用目标被垃圾收集器收集，而其他引用不禁止。 当使用软引用、弱引用、虚引用时，并且对可触及性状态的改变有兴趣，可以把引用对象和引用队列关联起来。 对象有六种可触及状态变化： 强可触及：对象可以从根节点不通过任何引用对象搜索到。垃圾收集器不会回收这个对象的内存空间。 软可触及：对象可以从根节点通过一个或多个(未被清除的)软引用对象触及，垃圾收集器在要发生内存溢出前将这些对象列入回收范围中进行回收，如果该软引用对象和引用队列相关联，它会把该软引用对象加入队列。 SoftReference可以用来创建内存中缓存，JVM的实现需要在抛出OutOfMemoryError之前清除软引用，但在其他的情况下可以选择清理的时间或者是否清除它们。 弱可触及：对象可以从根节点开始通过一个或多个(未被清除的)弱引用对象触及，垃圾收集器在一次GC的时候会回收所有的弱引用对象，如果该弱引用对象和引用队列相关联，它会把该弱引用对象加入队列。 可复活的：对象既不是强可触及、软可触及、也不是弱可触及，但仍然可能通过执行某些终结方法复活到这几个状态之一。 Java类可以通过重写finalize方法复活准备回收的对象，但finalize方法只是在对象第一次回收时会调用。 虚可触及：垃圾收集器不会清除一个虚引用，所有的虚引用都必须由程序明确的清除。 同时也不能通过虚引用来取得一个对象的实例。 不可触及：不可触及对象已经准备好回收了。 若一个对象的引用类型有多个，那到底如何判断它的可达性呢？其实规则如下： 单条引用链的可达性以最弱的一个引用类型来决定； 多条引用链的可达性以最强的一个引用类型来决定； 垃圾回收算法 标记--清除算法 首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，标记的方法使用根搜索算法。主要有两个缺点： 效率问题，标记和清除的效率都不高。 空间问题，标记清除后会产生大量不连续的内存碎片。 复制回收算法 将可用内存分为大小相等的两份，在同一时刻只使用其中的一份。当这一份内存使用完了，就将还存活的对象复制到另一份上，然后将这一份上的内存清空。复制算法能有效避免内存碎片，但是算法需要将内存一分为二，导致内存使用率大大降低。 标记--整理算法 复制算法在对象存活率较高的情况下会复制很多的对象，效率会很低。标记--整理算法就解决了这样的问题，标记过程和标记--清除算法一样，但后续是将所有存活的对象都移动到内存的一端，然后清理掉端外界的对象。 分代回收(HotSpot) 在JVM中不同的对象拥有不同的生命周期，因此对于不同生命周期的对象也可以采用不同的垃圾回收方法，以提高效率，这就是分代回收算法的核心思想。 在不进行对象存活时间区分的情况下，每次垃圾回收都是对整个堆空间进行回收，花费的时间相对会长。同时，因为每次回收都需要遍历所有存活对象，但实际上，对于生命周期长的对象而言，这种遍历是没有效果的，因为可能进行了很多次遍历，但是他们依旧存在。因此，分代垃圾回收采用分治的思想，进行代的划分，把不同生命周期的对象放在不同代上，不同代上采用最适合它的垃圾回收方式进行回收。 JVM中的共划分为三个代：新生代（Young Generation）、老年代（Old Generation）和永久代（Permanent Generation）。其中永久代主要存放的是Java类的类信息，与垃圾收集要收集的Java对象关系不大。 新生代：所有新生成的对象首先都是放在新生代的，新生代采用复制回收算法。新生代的目标就是尽可能快速的收集掉那些生命周期短的对象。新生代分三个区。一个Eden区，两个Survivor区(一般而言)。大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当这个Survivor区满时，此区的存活对象将被复制到另外一个Survivor区，当这个Survivor去也满了的时候，从第一个Survivor区复制过来的并且此时还存活的对象，将被复制“年老区(Tenured)”。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来 对象，和从前一个Survivor复制过来的对象，而复制到年老区的只有从第一个Survivor去过来的对象。而且，Survivor区总有一个是空的。 在HotSpot虚拟机内部默认Eden和Survivor的大小比例是8:1， 也就是每次新生代中可用内存为整个新生代的90%，这大大提高了复制回收算法的效率。 老年代：在新生代中经历了N次垃圾回收后仍然存活的对象，就会被放到老年代中，老年代采用标记整理回收算法。因此，可以认为老年代中存放的都是一些生命周期较长的对象。 永久代：HotSpot 的方法区实现，用于存储类信息、常量池、静态变量、JIT编译后的代码等数据 HotSpot 各版本永久代变化 在Java 6中，方法区中包含的数据，除了JIT编译生成的代码存放在native memory的CodeCache区域，其他都存放在永久代； 在Java 7中，Symbol 的存储从 PermGen 移动到了 native memory ，并且把静态变量从instanceKlass末尾（位于PermGen内）移动到了java.lang.Class对象的末尾（位于普通Java heap内）； 在Java 8中，永久代被彻底移除，取而代之的是另一块与堆不相连的本地内存——元空间（Metaspace）,‑XX:MaxPermSize 参数失去了意义，取而代之的是-XX:MaxMetaspaceSize。 移除永久代 Java 8 彻底将永久代 (PermGen) 移除出了 HotSpot JVM，将其原有的数据迁移至 Java Heap 或 Metaspace。 在 HotSpot JVM 中，永久代中用于存放类和方法的元数据以及常量池，比如Class和Method。每当一个类初次被加载的时候，它的元数据都会放到永久代中。 永久代是有大小限制的，因此如果加载的类太多，很有可能导致永久代内存溢出，即万恶的 java.lang.OutOfMemoryError: PermGen ，为此我们不得不对虚拟机做调优。 那么，Java 8 中 PermGen 为什么被移出 HotSpot JVM 了？ 由于 · 内存经常会溢出，引发恼人的 java.lang.OutOfMemoryError: PermGen，因此 JVM 的开发者希望这一块内存可以更灵活地被管理，不要再经常出现这样的 OOM 移除 PermGen 可以促进HotSpot JVM 与 JRockit VM 的融合，因为 JRockit 没有永久代。 根据上面的各种原因，PermGen 最终被移除，方法区移至 Metaspace，字符串常量移至 Java Heap。 元空间 首先，Metaspace（元空间）是哪一块区域？官方的解释是： In JDK 8, classes metadata is now stored in the native heap and this space is called Metaspace. 也就是说，JDK 8 开始把类的元数据放到本地堆内存(native heap)中，这一块区域就叫 Metaspace，中文名叫元空间。 垃圾回收触发条件 由于对象进行了分代处理，因此垃圾回收区域、时间也不一样。GC有两种类型：Scavenge GC和Full GC。对于一个拥有终结方法的对象，在垃圾收集器释放对象前必须执行终结方法。但是当垃圾收集器第二次收集这个对象时便不会再次调用终结方法。 Scavenge GC 一般情况下，当新对象生成，并且在 Eden 申请空间失败时，就会触发 Scavenge GC，对 Eden 区域进行 GC ，清除非存活对象，并且把尚且存活的对象移动到 Survivor 区，然后整理 Survivor 的两个区。这种方式的 GC是对新生代的 Eden 区进行，不会影响到老年代。因为大部分对象都是从 Eden 区开始的，同时 Eden 区不会分配的很大，所以 Eden 区的 GC 会频繁进行。 Full GC 对整个堆进行整理，包括 Young 、 Tenured 和 Perm 。Full GC因为需要对整个对进行回收，所以比 Scavenge GC 要慢，因此应该尽可能减少 Full GC 的次数。在对 JVM 调优的过程中，很大一部分工作就是对于 FullGC 的调节。有如下原因可能导致Full GC： 老年代（Tenured）被写满 永久代（Perm）被写满 System.gc()被显示调用 堆外内存 GC Native Memory Tracking DirectBuffer 的引用是直接分配在堆得 Old 区的，因此其回收时机是在 FullGC 时。因此，需要避免频繁的分配 DirectBuffer ，这样很容易导致 Native Memory 溢出。 DirectByteBuffer 申请的直接内存，不再GC范围之内，无法自动回收。JDK提供了一种机制，可以为堆内存对象注册一个钩子函数(其实就是实现 Runnable 接口的子类)，当堆内存对象被GC回收的时候，会回调run方法，我们可以在这个方法中执行释放 DirectByteBuffer 引用的直接内存，即在run方法中调用 Unsafe 的 freeMemory 方法。注册是通过sun.misc.Cleaner类来实现的。 垃圾收集器 垃圾收集器是内存回收的具体实现，下图展示了7种用于不同分代的收集器，两个收集器之间有连线表示可以搭配使用。下面的这些收集器没有“最好的”这一说，每种收集器都有最适合的使用场景。 Serial收集器 Serial收集器是最基本的收集器，这是一个单线程收集器，它“单线程”的意义不仅仅是说明它只用一个线程去完成垃圾收集工作，更重要的是在它进行垃圾收集工作时，必须暂停其他工作线程，直到它收集完成。Sun将这件事称之为”Stop the world“。 没有一个收集器能完全不停顿，只是停顿的时间长短。 虽然Serial收集器的缺点很明显，但是它仍然是JVM在Client模式下的默认新生代收集器。它有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比较），Serial收集器由于没有线程交互的开销，专心只做垃圾收集自然也获得最高的效率。在用户桌面场景下，分配给JVM的内存不会太多，停顿时间完全可以在几十到一百多毫秒之间，只要收集不频繁，这是完全可以接受的。 ParNew收集器 ParNew是Serial的多线程版本，在回收算法、对象分配原则上都是一致的。ParNew收集器是许多运行在Server模式下的默认新生代垃圾收集器，其主要在于除了Serial收集器，目前只有ParNew收集器能够与CMS收集器配合工作。 Parallel Scavenge收集器（1.8默认新生代） Parallel Scavenge收集器是一个新生代垃圾收集器，其使用的算法是复制算法，也是并行的多线程收集器。 Parallel Scavenge 收集器更关注可控制的吞吐量，吞吐量等于运行用户代码的时间/(运行用户代码的时间+垃圾收集时间)。直观上，只要最大的垃圾收集停顿时间越小，吞吐量是越高的，但是GC停顿时间的缩短是以牺牲吞吐量和新生代空间作为代价的。比如原来10秒收集一次，每次停顿100毫秒，现在变成5秒收集一次，每次停顿70毫秒。停顿时间下降的同时，吞吐量也下降了。 停顿时间越短就越适合需要与用户交互的程序；而高吞吐量则可以最高效的利用CPU的时间，尽快的完成计算任务，主要适用于后台运算。 Serial Old收集器 Serial Old收集器是Serial收集器的老年代版本，也是一个单线程收集器，采用“标记-整理算法”进行回收。其运行过程与Serial收集器一样。 Parallel Old收集器（1.8默认老年代） Parallel Old收集器是Parallel Scavenge收集器的老年代版本，使用多线程和标记-整理算法进行垃圾回收。其通常与Parallel Scavenge收集器配合使用，“吞吐量优先”收集器是这个组合的特点，在注重吞吐量和CPU资源敏感的场合，都可以使用这个组合。 CMS 收集器 CMS（Concurrent Mark Sweep）收集器是一种以获取最短停顿时间为目标的收集器，CMS收集器采用标记--清除算法，运行在老年代。主要包含以下几个步骤： 初始标记 并发标记 重新标记 并发清除 其中初始标记和重新标记仍然需要“Stop the world”。初始标记仅仅标记GC Root能直接关联的对象，并发标记就是进行GC Root Tracing过程，而重新标记则是为了修正并发标记期间，因用户程序继续运行而导致标记变动的那部分对象的标记记录。 由于整个过程中最耗时的并发标记和并发清除，收集线程和用户线程一起工作，所以总体上来说，CMS收集器回收过程是与用户线程并发执行的。虽然CMS优点是并发收集、低停顿，很大程度上已经是一个不错的垃圾收集器，但是还是有三个显著的缺点： CMS收集器对CPU资源很敏感。在并发阶段，虽然它不会导致用户线程停顿，但是会因为占用一部分线程（CPU资源）而导致应用程序变慢。 CMS收集器不能处理浮动垃圾。所谓的“浮动垃圾”，就是在并发标记阶段，由于用户程序在运行，那么自然就会有新的垃圾产生，这部分垃圾被标记过后，CMS无法在当次集中处理它们，只好在下一次GC的时候处理，这部分未处理的垃圾就称为“浮动垃圾”。也是由于在垃圾收集阶段程序还需要运行，即还需要预留足够的内存空间供用户使用，因此CMS收集器不能像其他收集器那样等到老年代几乎填满才进行收集，需要预留一部分空间提供并发收集时程序运作使用。要是CMS预留的内存空间不能满足程序的要求，这是JVM就会启动预备方案：临时启动Serial Old收集器来收集老年代，这样停顿的时间就会很长。 由于CMS使用标记--清除算法，所以在收集之后会产生大量内存碎片。当内存碎片过多时，将会给分配大对象带来困难，这是就会进行Full GC。 G1收集器 G1收集器与CMS相比有很大的改进： G1收集器采用标记--整理算法实现。 可以非常精确地控制停顿。 G1收集器可以实现在基本不牺牲吞吐量的情况下完成低停顿的内存回收，这是由于它极力的避免全区域的回收，G1收集器将Java堆（包括新生代和老年代）划分为多个区域（Region），并在后台维护一个优先列表，每次根据允许的时间，优先回收垃圾最多的区域 。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/gc/12-jvm-object-life-cycle.html":{"url":"java/gc/12-jvm-object-life-cycle.html","title":"Java 虚拟机对象生命周期","keywords":"","body":"对象的生命周期 一旦一个类被装载、连接和初始化，它就随时可以被使用。程序可以访问它的静态字段，调用它的静态方法，或者创建它的实例。作为Java程序员有必要了解Java对象的生命周期。 类实例化 在Java程序中，类可以被明确或隐含地实例化。明确的实例化类有四种途径： 明确调用new。 调用Class或者java.lang.reflect.Constructor对象的newInstance方法。 调用任何现有对象的clone。 通过java.io.ObjectInputStream.getObject()反序列化。 隐含的实例化： 可能是保存命令行参数的String对象。 对于Java虚拟机装载的每个类，都会暗中实例化一个Class对象来代表这个类型 当Java虚拟机装载了在常量池中包含CONSTANT_String_info入口的类的时候，它会创建新的String对象来表示这些常量字符串。 执行包含字符串连接操作符的表达式会产生新的对象。 Java编译器为它编译的每个类至少生成一个实例初始化方法。在Java class文件中，这个方法被称为。针对源代码中每个类的构造方法，Java编译器都会产生一个()方法。如果累没有明确的声明任何构造方法，编译器会默认产生一个无参数的构造方法，它仅仅调用父类的无参构造方法。 一个()中可能包含三种代码：调用另一个()、实现对任何实例变量的初始化、构造方法体的代码。 如果构造方法明确的调用了同一个类中的另一个构造方法(this())，那么它对应的()由两部分组成： 一个同类的()的调用。 实现了对应构造方法的方法体的字节码。 在它对应的()方法中不会有父类的()，但不代表不会调用父类的()，因为this()中也会调用父类() 如果构造方法不是通过一个this()调用开始的，而且这个对象不是Object，()则有三部分组成： 一个父类的()调用。如果这个类是Object,则没有这个部分 任意实例变量初始化方法的字节码。 实现了对应构造方法的方法体的字节码。 如果构造方法明确的调用父类的构造方法super()开始，它的()会调用对应父类的()。比如，如果一个构造方法明确的调用super(int,String)开始，对应的()会从调用父类的(int,String)方法开始。如果构造方法没有明确地从this()或super()开始，对应的()默认会调用父类的无参()。 垃圾收集和对象的终结 程序可以明确或隐含的为对象分配内存，但不能明确的释放内存。一个对象不再为程序引用，虚拟机必须回事那部分内存。 卸载类 在很多方面，Java虚拟机中类的生命周期和对象的生命周期很相似。当程序不再使用某个类的时候，可以选择卸载它们。 类的垃圾收集和卸载值所以在Java虚拟机中很重要，是因为Java程序可以在运行时通过用户自定义的类装载器装载类型来动态的扩展程序。所有被装载的类型都在方法区占据内存空间。 Java虚拟机通过判断类是否在被引用来进行垃圾收集。判断动态装载的类的Class实例在正常的垃圾收集过程中是否可触及有两种方式： 如果程序保持非Class实例的明确引用。 如果在堆中还存在一个可触及的对象，在方法区中它的类型数据指向一个Class实例。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/jvm/":{"url":"java/jvm/","title":"Java 虚拟机","keywords":"","body":" 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/jvm/1-jvm-class-load-init.html":{"url":"java/jvm/1-jvm-class-load-init.html","title":"类加载","keywords":"","body":"JVM类加载三步走 简介 Java虚拟机通过装载、连接和初始化一个类型，使该类型可以被正在运行的Java程序使用。 装载：把二进制形式的Java类型读入Java虚拟机中。 连接：把装载的二进制形式的类型数据合并到虚拟机的运行时状态中去。 验证：确保Java类型数据格式正确并且适合于Java虚拟机使用。 准备：负责为该类型分配它所需内存。 解析：把常量池中的符号引用转换为直接引用。(可推迟到运行中的程序真正使用某个符号引用时再解析) 初始化：为类变量赋适当的初始值 所有Java虚拟机实现必须在每个类或接口首次主动使用时初始化。以下六种情况符合主动使用的要求： 当创建某个类的新实例时(new、反射、克隆、序列化) 调用某个类的静态方法 使用某个类或接口的静态字段，或对该字段赋值(用final修饰的静态字段除外，它被初始化为一个编译时常量表达式) 当调用Java API的某些反射方法时。 初始化某个类的子类时。 当虚拟机启动时被标明为启动类的类。 除以上六种情况，所有其他使用Java类型的方式都是被动的，它们不会导致Java类型的初始化。 对于接口来说，只有在某个接口声明的非常量字段被使用时，该接口才会初始化，而不会因为事先这个接口的子接口或类要初始化而被初始化。 父类需要在子类初始化之前被初始化，所以这些类应该被装载了。当实现了接口的类被初始化的时候，不需要初始化父接口。然而，当实现了父接口的子类(或者是扩展了父接口的子接口)被装载时，父接口也要被装载。(只是被装载，没有初始化) 装载 通过该类型的全限定名，产生一个代表该类型的二进制数据流。 解析这个二进制数据流为方法去内的内部数据结构。 创建一个表示该类型的java.lang.Class类的实例。 Java虚拟机在识别Java class文件，产生了类型的二进制数据后，Java虚拟机必须把这些二进制数据解析为与实现相关的内部数据结构。装载的最终产品就是Class实例，它称为Java程序与内部数据结构之间的接口。要访问关于该类型的信息(存储在内部数据结构中)，程序就要调用该类型对应的Class实例的方法。这样一个过程，就是把一个类型的二进制数据解析为方法区中的内部数据结构，并在堆上建立一个Class对象的过程，这被称为\"创建\"类型。 验证 确认装载后的类型符合Java语言的语义，并且不会危及虚拟机的完整性。 装载时验证：检查二进制数据以确保数据全部是预期格式、确保除Object之外的每个类都有父类、确保该类的所有父类都已经被装载。 正式验证阶段：检查final类不能有子类、确保final方法不被覆盖、确保在类型和超类型之间没有不兼容的方法声明(比如拥有两个名字相同的方法，参数在数量、顺序、类型上都相同，但返回类型不同)。 符号引用的验证：当虚拟机搜寻一个呗符号引用的元素(类型、字段或方法)时，必须首先确认该元素存在。如果虚拟机发现元素存在，则必须进一步检查引用类型有访问该元素的权限。 准备 当Java虚拟机装载一个类，并执行了一些验证之后，类就可以进入准备阶段。在准备阶段，Java虚拟机为类变量分配内存，设置默认初始值。但在到到初始化阶段之前，类变量都没有被初始化为真正的初始值。 boolean在内部常常被实现为一个int，会被默认初始化为0。 解析 类型经过连接的前两个阶段--验证和准备--之后，就可以进入第三个阶段--解析。解析的过程就是在类型的常量池总寻找类、接口、字段和方法的符号引用，把这些符号引用替换为直接引用的过程。 类或接口的解析：判断所要转化成的直接引用是对数组类型，还是普通的对象类型的引用，从而进行不同的解析。 字段解析：对字段进行解析时，会先在本类中查找是否包含有简单名称和字段描述符都与目标相匹配的字段，如果有，则查找结束；如果没有，则会按照继承关系从上往下递归搜索该类所实现的各个接口和它们的父接口，还没有，则按照继承关系从上往下递归搜索其父类，直至查找结束， 初始化 为类变量赋予“正确”的初始值。这里的“正确”的初始值是指程序员希望这个类变量所具备的初始值。所有的类变量(即静态量)初始化语句和类型的静态初始化器都被Java编译器收集在一起，放到一个特殊的方法中。 对于类来说，这个方法被称作类初始化方法；对于接口来说，它被称为接口初始化方法。在类和接口的class文件中，这个方法被称为。 初始化类的步骤： 如果存在直接父类，且直接父类没有被初始化，先初始化直接父类。 如果类存在一个类初始化方法，执行此方法。 这个步骤是递归执行的，即第一个初始化的类一定是Object。初始化接口并不需要初始化它的父接口。 Java虚拟机必须确保初始化过程被正确地同步。 如果多个线程需要初始化一个类，仅仅允许一个线程来进行初始化，其他线程需等待。 这个特性可以用来写单例模式。 ()方法 对于静态变量和静态初始化语句来说：执行的顺序和它们在类或接口中出现的顺序有关。 并非所有的类都需要在它们的class文件中拥有()方法， 如果类没有声明任何类变量，也没有静态初始化语句，那么它就不会有()方法。如果类声明了类变量，但没有明确的使用类变量初始化语句或者静态代码块来初始化它们，也不会有()方法。如果类仅包含静态final常量的类变量初始化语句，而且这些类变量初始化语句采用编译时常量表达式，类也不会有()方法。只有那些需要执行Java代码来赋值的类才会有() final常量：Java虚拟机在使用它们的任何类的常量池或字节码中直接存放的是它们表示的常量值。 主动使用和被动使用 主动使用有六种情况，在前面已经写过。 使用一个非常量的静态字段只有当类或接口的确声明了这个字段时才是主动使用。 比如：类中声明的字段可能被子类引用；接口中声明的字段可能被子接口或实现了这个接口的类引用。对于子类、子接口或实现了接口的类来说，这是被动使用--不会触发它们的初始化。只有当字段的确是被类或接口声明的时候才是主动使用。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/jvm/2-jvm-class-loader.html":{"url":"java/jvm/2-jvm-class-loader.html","title":"类加载器","keywords":"","body":"类加载器 简介 Java类加载器是Java运行时环境（Java Runtime Environment）的一部分，负责动态加载Java类到Java虚拟机的内存空间中。类通常是按需加载，即第一次使用该类时才加载。 由于有了类加载器，Java运行时系统不需要知道文件与文件系统。每个Java类必须由某个类加载器装入到内存。 类装载器子系统涉及Java虚拟机的其他几个组成部分，以及几个来自java.lang库的类。比如，用户自定义的类装载器只是普通的Java对象，它的类必须派生自java.lang.ClassLoader。ClassLoader中定义的方法为程序提供了访问类装载器机制的接口。此外，对于每个被装载的类型，Java虚拟机都会为他创建一个java.lang.Class类的实例来代表该类型。和所有其他对象一样，用户自定义的类装载器以及Class类的实例都放在内存中的堆区，而装载的类型信息都位于方法区。 类装载器子系统除了要定位和导入二进制class文件外，还必须负责验证被导入类的正确性，为变量分配初始化内存，以及帮助解析符号引用。这些动作必须严格按一下顺序完成： 装载--查找并装载类型的二进制数据。 链接--执行验证、准备以及解析(可选) 验证：确保被导入类型的正确性 准备：为类变量分配内存，并将其初始化为默认值。 解析：把类型中的符号引用转换为直接引用。 初始化--把类变量初始化为正确的初始值。 使用 卸载：类加载器加载的每个类和类加载器本身都被没有引用 分类 在Java虚拟机中存在多个类装载器，Java应用程序可以使用两种类装载器： 启动(bootstrap)类装载器：此装载器是Java虚拟机实现的一部分。由原生代码（如C语言）编写，不继承自java.lang.ClassLoader。负责加载核心Java库，存储在/jre/lib目录中。（如果Java虚拟机在已有操作系统中实现为C程序，那么启动类加载器就是此C程序的一部分） 启动类装载器通常使用某种默认的方式从本地磁盘中加载类，包括Java API。 用户自定义类装载器：（包含但不止，扩展类加载器以及系统类加载器） ，继承自Java中的java.lang.ClassLoader类，Java应用程序能在运行时安装用户自定义类装载器，这种累装载器使用自定义的方式来装载类。用户定义的类装载器能用Java编写，能够被编译为Class文件，能被虚拟机装载，还能像其他对象一样实例化。它们实际上只是运行中的Java程序可执行代码的一部分。一般JVM都会提供一些基本实现。应用程序的开发人员也可以根据需要编写自己的类加载器。JVM中最常使用的是系统类加载器（system），它用来启动Java应用程序的加载。 通过java.lang.ClassLoader.getSystemClassLoader() 可以获取到该类加载器对象。该类由sun.misc.Launcher$AppClassLoader实现。 全盘负责双亲委托机制 全盘负责是指当一个ClassLoader装载一个类的时，除非显式地使用另一个ClassLoader，该类所依赖及引用的类也由这个ClassLoader载入；“双亲委托机制”是指先委托父装载器寻找目标类，只有在找不到的情况下才从自己的类路径中查找并装载目标类。这一点是从安全角度考虑的，试想如果有人编写了一个恶意的基础类（如java.lang.String）并装载到JVM中将会引起多么可怕的后果。但是由于有了“全盘负责委托机制”，java.lang.String永远是由根装载器来装载的，这样就避免了上述事件的发生。 类加载器需要完成的最终功能是定义一个Java类，即把Java字节代码转换成JVM中的java.lang.Class类的对象。但是类加载的过程并不是这么简单。Java类加载器有两个比较重要的特征： 层次组织结构指的是每个类加载器都有一个父类加载器，通过getParent()方法可以获取到。类加载器通过这种父亲-后代的方式组织在一起，形成树状层次结构。 代理模式则指的是一个类加载器既可以自己完成Java类的定义工作，也可以代理给其它的类加载器来完成。由于代理模式的存在，启动一个类的加载过程的类加载器和最终定义这个类的类加载器可能并不是一个。前者称为初始类加载器，而后者称为定义类加载器。 两者的关联在于：在每个类被装载的时候，Java虚拟机都会监视这个类，看它到底是被启动类装载器还是被用户自定义类装载器装载。当被装载的类引用了另外一个类的时候，虚拟机就会使用装载第一个类的类装载器装载被引用的类。 注意：JVM加载类A，并使用A的ClassLoader去加载B，但B的类加载器并不一定和A的类加载器一致，这是因为有双亲委托机制的存在。 一般的类加载器在尝试自己去加载某个Java类之前，会 首先代理给其父类加载器。当父类加载器找不到的时候，才会尝试自己加载。这个逻辑是封装在java.lang.ClassLoader类的loadClass()方法中的。一般来说，父类优先的策略就足够好了。在某些情况下，可能需要采取相反的策略，即先尝试自己加载，找不到的时候再代理给父类加载器。这种做法在Java的Web容器中比较常见，也是Servlet规范推荐的做法。 比如，Apache Tomcat为每个Web应用都提供一个独立的类加载器，使用的就是自己优先加载的策略。IBM WebSphere Application Server则允许Web应用选择类加载器使用的策略。 假设 类加载器B2被要求装载类MyClass，在parent delegation模型下，类加载器B2首先请求类加载器B代为装载，类加载器B再请求系统类装载器去装载MyClass，系统类装载器也会继续请求它的Parent扩展类加载器去装载MyClass，以此类推直到引导类装载器。若引导类装载器能成功装载，则将MyClass所对应的Class对象的reference逐层返回到类加载器B2，若引导类装载器不能成功装载，下层的扩展类装载器将尝试装载，并以此类推直到类装载器B2如果也不能成功装载，则装载失败。 需要指出的是，Class Loader是对象，它的父子关系和类的父子关系没有任何关系。一对父子loader可能实例化自同一个 Class，也可能不是，甚至父loader实例化自子类，子loader实例化自父类。 defineClass vs findClass vs loadClass loadclass：判断是否已加载，使用双亲委派模型，请求父加载器，都为空，使用 findclass findclass：根据名称或位置加载 .class 字节码,然后使用 defineClass defineclass：解析定义 .class 字节流，返回 class 对象 运行时包 类加载器的一个重要用途是 在JVM中为相同名称的Java类创建隔离空间。在JVM中，判断两个类是否相同，不仅是根据该类的二进制名称，还需要根据两个类的定义类加载器。 只有两者完全一样，才认为两个类的是相同的。 在允许两个类型之间对包内可见的成员进行访问前，虚拟机不但要确定这个两个类型属于同一个包，还必须确认它们属于同一个运行时包－它们必须有同一个类装载器装载的。 这样，java.lang.Virus和来自核心的java.lang的类不属于同一个运行时包，java.lang.Virus就不能访问JAVA API的java.lang包中的包内可见的成员。 Class.getClassLoader vs Thread.getContextClassLoader 每个 Class 会使用自己的 ClassLoader 去加载其他的 Class 。如果 ClassA.class 引用了 ClassB.class ，那么 ClassB 需要能被 ClassA 的 ClassLoader 或者其 父ClassLoader 找到。 Thread.getContextClassLoader 是当前线程使用的 ClassLoader。对象可以通过 ClassLoaderC 加载，并且传递到 Classload 是 ClassLoaderD 的线程里。在某些情况下，对象需要使用 Thread.currentThread().getContextClassLoader() 来加载 ClassLoaderC 不能获取的资源 Tomcat & ClassLoader 事实上，tomcat之所以造了一堆自己的classloader，大致是出于下面三类目的： 对于各个 webapp 中的 class 和 lib ，需要相互隔离，不能出现一个应用中加载的类库会影响另一个应用的情况；而对于许多应用，需要有共享的lib以便不浪费资源，举个例子，如果 webapp1 和 webapp2 都用到了 log4j ，可以将 log4j 提到 tomcat/lib 中，表示所有应用共享此类库，试想如果 log4j 很大，并且 20 个应用都分别加载，那实在是没有必要的。 与 jvm 一样的安全性问题。使用单独的 classloader 去装载 tomcat 自身的类库，以免其他恶意或无意的破坏； 热部署，相信大家一定为 tomcat 修改文件不用重启就自动重新装载类库而惊叹吧。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/jvm/3-dispatcher.html":{"url":"java/jvm/3-dispatcher.html","title":"Java分派机制","keywords":"","body":"Java分派机制 在Java中，符合“编译时可知，运行时不可变”这个要求的方法主要是静态方法和私有方法。这两种方法都不能通过继承或别的方法重写，因此它们适合在类加载时进行解析。 Java虚拟机中有四种方法调用指令： invokestatic：调用静态方法。 invokespecial：调用实例构造器方法，私有方法和super。 invokeinterface：调用接口方法。 invokevirtual：调用以上指令不能调用的方法（虚方法）。 只要能被invokestatic和invokespecial指令调用的方法，都可以在解析阶段确定唯一的调用版本，符合这个条件的有：静态方法、私有方法、实例构造器、父类方法，他们在类加载的时候就会把符号引用解析为改方法的直接引用。这些方法被称为非虚方法，反之其他方法称为虚方法（final方法除外）。 虽然final方法是使用invokevirtual指令来调用的，但是由于它无法被覆盖，多态的选择是唯一的，所以是一种非虚方法。 静态分派 对于类字段的访问也是采用静态分派 People man = new Man() 静态分派主要针对重载，方法调用时如何选择。在上面的代码中，People被称为变量的引用类型，Man被称为变量的实际类型。静态类型是在编译时可知的，而动态类型是在运行时可知的，编译器不能知道一个变量的实际类型是什么。 编译器在重载时候通过参数的静态类型而不是实际类型作为判断依据。并且静态类型在编译时是可知的，所以编译器根据重载的参数的静态类型进行方法选择。 在某些情况下有多个重载，那编译器如何选择呢？ 编译器会选择\"最合适\"的函数版本，那么怎么判断\"最合适“呢？越接近传入参数的类型，越容易被调用。 动态分派 动态分派主要针对重写，使用invokevirtual指令调用。invokevirtual指令多态查找过程： 找到操作数栈顶的第一个元素所指向的对象的实际类型，记为C。 如果在类型C中找到与常量中的描述符合简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束；如果权限校验不通过，返回java.lang.IllegalAccessError异常。 否则，按照继承关系从下往上一次对C的各个父类进行第2步的搜索和验证过程。 如果始终没有找到合适的方法，则抛出 java.lang.AbstractMethodError异常。 虚拟机动态分派的实现 由于动态分派是非常繁琐的动作，而且动态分派的方法版本选择需要考虑运行时在类的方法元数据中搜索合适的目标方法，因此在虚拟机的实现中基于性能的考虑，在方法区中建立一个虚方法表（invokeinterface有接口方法表），来提高性能。 虚方法表中存放各个方法的实际入口地址。如果某个方法在子类没有重写，那么子类的虚方法表里的入口和父类入口一致，如果子类重写了这个方法，那么子类方法表中的地址会被替换为子类实现版本的入口地址。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/jvm/4-jvm-architecture.html":{"url":"java/jvm/4-jvm-architecture.html","title":"虚拟机架构","keywords":"","body":"JVM架构 Java虚拟机简介 “Java虚拟机”可能指如下三个不同的东西 抽象规范 一个具体的实现 一个运行中的虚拟机实例 每个Java程序都运行在某个具体的Java虚拟机实现的实例上。一个Java虚拟机的实例负责运行一个Java程序。当启动一个Java程序的时候，一个虚拟机的实例也就诞生了。当该程序关闭退出时，这个虚拟机实例也就随之消亡。 线程介绍 在Java虚拟机内部有两种线程： 守护线程：通常是由虚拟机自己使用，比如GC线程。但是，Java程序也可以把它自己创建的任何线程标记为守护线程（public final void setDaemon(boolean on)来设置，但必须在start()方法之前调用）。 非守护线程：main方法执行的线程，我们通常也称为用户线程。 只要有任何的非守护线程在运行，Java程序也会继续运行。当该程序中所有的非守护线程都终止时，虚拟机实例将自动退出（守护线程随JVM一同结束工作）。 守护线程中不适合进行IO、计算等操作，因为守护线程是在所有的非守护线程退出后结束，这样并不能判断守护线程是否完成了相应的操作，如果非守护线程退出后，还有大量的数据没来得及读写，这将造成很严重的后果。 web服务器中的Servlet，容器启动时后台初始化一个服务线程，即调度线程，负责处理http请求，然后每个请求过来调度线程从线程池中取出一个工作者线程来处理该请求，从而实现并发控制的目的。 Java虚拟机体系结构 每个Java虚拟机都有一个类装载器子系统，他根据给定的全限定名来装在类型。同样，每个Java虚拟机都有一个执行引擎，它负责执行那些包含在被装载类的方法中的指令。当Java虚拟机运行一个程序时，它需要内存来存储很多东西，例如：字节码，从已装载的class文件中得到的其他信息，程序创建的对象，传递给方法的参数，返回值，局部变量，以及运算的中间结果等等，Java虚拟机把这些东西都组织到几个“运行时数据区”中，以便管理。 每个Java虚拟机实例都有一个方法区以及一个堆， 他们是由 该虚拟机实例中所有线程共享的。 当虚拟机装载一个class文件时，它会从这个class文件包含的二进制数据中解析类型信息。然后把这些类型信息放到方法区中。 当程序运行的时候，虚拟机会把所有该程序在运行时创建的对象都放到堆中。 每个新线程都会得到它自己的PC寄存器(程序计数器)以及一个Java栈。 如果线程正在执行的是一个Java方法(非Native方法)。那么PC寄存器的值将总指向下一条将被执行的指令，而 它的Java栈则总是存储该线程中Java方法调用的转台--包括它的局部变量、被调用时传进来的参数、返回值以及运算的中间结果等等。 Native方法调用的状态，则是以某种依赖于具体实现的方式存储在本地方法栈中，也可能是在寄存器或者其他某些与特定实现相关的内存区中。 Java栈是由很多的栈帧(stack frame)或者说帧(frame)组成的，一个栈帧包含一个Java方法调用状态。 当现场调用一个Java方法的时候，虚拟机压入一个新的栈帧到该线程的Java栈中：当该方法返回时，这个栈帧被从Java栈中弹出并抛弃 Java虚拟机没有指令寄存器，其指令集使用Java栈来存储中间数据。这样设计的原因是为了保持Java虚拟机的指令集尽量紧凑、同时也便于Java虚拟机在那些只有很少通用寄存器的平台上实现。另外，Java虚拟机这种基于栈的体系结构，也有助于运行时某些虚拟机实现的动态编译器和即时编译器的代码优化。 这些内存区域是私有的，任何线程都不能访问另外一个线程的PC寄存器或Java栈。 图中是一个虚拟机实例的快照，它有三个线程正在执行。线程1和线程2都正在执行Java方法，而线程3在执行Native方法。 数据类型 数据类型分为两种： 基本类型：基本类型的变量持有原始值。 引用类型：引用类型的变量持有引用值。引用值是指对某个对象的引用，而不是该对象本身。 基本类型: Java语言中的所有基本类型都是Java虚拟机中的基本类型。但boolean有点特别，虽然Java虚拟机也把boolean看做基本类型，但指令集对boolean只有很有限的支持。 当编译器把Java源码编译成字节码时，它会用int或byte来表示boolean。在Java虚拟机中false是由整数'0'表示，所有的非零整数都表示true，涉及boolean值的操作则会用int。另外boolean数组是当做byte数组来访问的， 但是在“堆”区，它也可以被表示为位域。 Java虚拟机的基本类型的值域在任何地方都是一致的， 比如：不管底层主机平台是什么，一个long在任何虚拟机中总是一个64位二进制补码表示的又复活整数。 Java虚拟机中有一个值在内部使用的基本类型returnAddress，Java程序员不能使用这个类型。这个基本类型是用来实现Java程序中的finally子句。 引用类型： Java虚拟机中有三种引用类型，它们的值都是对动态创建对象的引用： 类类型：类实例(对象)的引用。 接口类型：是对实现了该接口的某个类实例的引用。 数组类型：数组对象的引用，在Java虚拟机中数组是个真正的对象。 还有一个特殊的引用值--NULL，它表示引用变量没有引用任何对象。 Java虚拟机规范定义了每一种数据类型的取值范围，但没有定义它们的位宽。存储这些类型的值所需的占位宽度，是由具体的虚拟机实现的设计者决定的。 类装载器 Java类加载器是Java运行时环境（Java Runtime Environment）的一部分，负责动态加载Java类到Java虚拟机的内存空间中。类通常是按需加载，即第一次使用该类时才加载。 由于有了类加载器，Java运行时系统不需要知道文件与文件系统。每个Java类必须由某个类加载器装入到内存。 类装载器子系统涉及Java虚拟机的其他几个组成部分，以及几个来自java.lang库的类。比如，用户自定义的类装载器只是普通的Java对象，它的类必须派生自java.lang.ClassLoader。ClassLoader中定义的方法为程序提供了访问类装载器机制的接口。此外，对于每个被装载的类型，Java虚拟机都会为他创建一个java.lang.Class类的实例来代表该类型。和所有其他对象一样，用户自定义的类装载器以及Class类的实例都放在内存中的堆区，而装载的类型信息都位于方法区。 类装载器子系统除了要定位和导入二进制class文件外，还必须负责验证被导入类的正确性，为变量分配初始化内存，以及帮助解析符号引用。这些动作必须严格按一下顺序完成： 装载--查找并装载类型的二进制数据。 链接--执行验证、准备以及解析(可选) 验证 确保被导入类型的正确性 准备 为类变量分配内存，并将其初始化为默认值。 解析 把类型中的符号引用转换为直接引用。 初始化--把类变量初始化为正确的初始值。 方法法区 方法区（method area）只是JVM规范中定义的一个概念，用于存储类信息、常量池、静态变量、JIT编译后的代码等数据，具体放在哪里，不同的实现可以放在不同的地方。 在Java虚拟机中，关于被装载类型的信息存储在逻辑上一个被称为方法区的内存中。 当虚拟机装载某个类型市，它使用类装载器定位相应的class文件，然后读入这个class文件--一个线性二进制数据流，然后把他传输到虚拟机中。紧接着虚拟机提取其中的类型信息，并将这些信息存储到方法区。该类型的类(静态)变量同样也是存储在方法区内。 当虚拟机运行Java程序时，它会查找使用存储在方法区中的类型信息。 由于所有线程都共享方法区，因此他们对方法区数据的访问必须设计为线程安全的。 方法区的大小不必是固定的，虚拟机可以根据应用需要动态调整。同样，方法区也不必是连续的，方法区可以在一个堆中自由分配。方法区也可以被垃圾收集--这里涉及到类的卸载。 方法区中包含的信息： 类型信息：对每个装载的类型，虚拟机都会在方法区存储一下信息 这个类型的全限定名 这个类型的直接父类的全限定名 这个类型是类类型还是接口类型 这个类型的访问修饰符 任何直接父接口的全限定名的有序列表 常量池：虚拟机必须为每个被装载的类型维护一个常量池。常量池就是该类型所用常量的一个有序集合，包直接常量(string,integer...)和对其他类型、字段和方法的符号引用。池中的数据项通过索引访问。 字段信息。 方法信息。 类变量。 编译时常量。 指向ClassLoader类的引用。 指向Class类的引用。 方法表：为了提高访问效率，虚拟机对每个装载的非抽象类都生成一个方法表，把它作为类信息的一部分，它主要存储了所有它的实例可能被调用的实例方法的直接引用，包括从父类继承的 实例 方法。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/jvm/5-memory-model.html":{"url":"java/jvm/5-memory-model.html","title":"内存模型","keywords":"","body":"JVM 内存模型 HotSpot 内存模型 -- JDK8 Heap: Java 堆是可供各线程共享的运行时内存区域，是 Java 虚拟机所管理的内存区域中最大的一块。此区域非常重要，几乎所有的对象实例和数组实例都要在 Java 堆上分配，但随着 JIT 编译器及逃逸分析技术的发展，也可能会被优化为栈上分配 Internd String: 字符串字面量常量池 Calss Meta Data: 每一个类的结构信息，比如 字段 和 方法数据、构造函数和普通方法的字节码内容，还包括一些初始化的时候用到的特殊方法。 Runtime Constant Pool: 运行时常量池是 class 文件中每一个类或接口的 常量池表(Constant Pool)的运行时表示形式，是方法区的一部分。它包括了若干种不同的常量。常量池表存放编译器生成的 各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。运行时常量池具有动态性，运行期间也可以将新的量放到运行时常量池中，典型的应用是 String 类的 intern 方法 Code Cache: JIT 编译缓存的本地代码 PC Register: CPU内部的寄存器中就包含一个程序计数器，存放程序执行的下一条指令地址。 JVM Stacks: Java 虚拟机栈也是线程私有的，每一条线程都拥有自己私有的Java 虚拟机栈，它与线程同时创建。它描述了 Java 方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。 Native Stacks: 本地方法栈和 Java 虚拟机栈的作用相似，Java 虚拟机栈执行的是字节码，而本地方法栈执行的是 native 方法。本地方法栈使用传统的栈（C Stack）来支持 native 方法。 JDK 1.7开始，字符串常量和符号引用等就被移出永久代： 符号引用迁移至系统堆内存(Native Heap) 字符串字面量迁移至Java堆(Java Heap) 在 JVM 规范中，并不存在这么多分区，只包含 5 大分区： Metahod Area Heap JVM Stack PC Register Native Stack 在 HotSpot 中，方法区涵盖了除 Heap,JVM Stack,PC Register,Native Stack 之外的其他区域。 参考链接 JEP 122: Remove the Permanent Generation Java JVM Run-time Data Areas - Javapapers JVM Internals 深入探究 JVM | Java 的内存区域解析 The Java Virtual Machine The Java HotSpot Performance Engine Architecture 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"java/jvm/6-string-constant-pool.html":{"url":"java/jvm/6-string-constant-pool.html","title":"String 常量池","keywords":"","body":"String 常量池 在 JAVA 语言中有 8 中基本类型和一种比较特殊的类型 String 。这些类型为了使他们在运行过程中速度更快，更节省内存，都提供了一种常量池的概念。常量池就类似一个 JAVA 系统级别提供的缓存。 String 类型的常量池比较特殊。它的主要使用方法有两种： 直接使用双引号声明出来的 String 对象会直接存储在常量池中 如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方法。 intern 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中 intern /** * Returns a canonical representation for the string object. * * A pool of strings, initially empty, is maintained privately by the * class {@code String}. * * When the intern method is invoked, if the pool already contains a * string equal to this {@code String} object as determined by * the {@link #equals(Object)} method, then the string from the pool is * returned. Otherwise, this {@code String} object is added to the * pool and a reference to this {@code String} object is returned. * * It follows that for any two strings {@code s} and {@code t}, * {@code s.intern() == t.intern()} is {@code true} * if and only if {@code s.equals(t)} is {@code true}. * * All literal strings and string-valued constant expressions are * interned. String literals are defined in section 3.10.5 of the * The Java&trade; Language Specification. * * @return a string that has the same contents as this string, but is * guaranteed to be from a pool of unique strings. */ public native String intern(); JAVA 使用 jni 调用 c++ 实现的 StringTable 的 intern 方法, StringTable 跟 Java 中的 HashMap 的实现是差不多的, 只是 不能自动扩容。默认大小是 1009 。 要注意的是， String 的 String Pool 是一个固定大小的 Hashtable ，默认值大小长度是 1009 ，如果放进 String Pool 的 String 非常多，就会造成 Hash 冲突严重，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用 String.intern 时性能会大幅下降。 在 JDK6 中 StringTable 是固定的，就是 1009 的长度，所以如果常量池中的字符串过多就会导致效率下降很快。在 jdk7 中， StringTable 的长度可以通过一个参数指定： -XX:StringTableSize=99991 在 JDK6 以及以前的版本中，字符串的常量池是放在堆的 Perm 区。在 JDK7 的版本中，字符串常量池已经从 Perm 区移到正常的 Java Heap 区域 public static void main(String[] args) { String s = new String(\"1\"); s.intern(); String s2 = \"1\"; System.out.println(s == s2); String s3 = new String(\"1\") + new String(\"1\"); s3.intern(); String s4 = \"11\"; System.out.println(s3 == s4); } 上述代码的执行结果： JDK6: false false JDK7: false true public static void main(String[] args) { String s = new String(\"1\"); String s2 = \"1\"; s.intern(); System.out.println(s == s2); String s3 = new String(\"1\") + new String(\"1\"); String s4 = \"11\"; s3.intern(); System.out.println(s3 == s4); } 上述代码的执行结果： JDK6: false false JDK7: false false 由于 JDK7 将字符串常量池移动到 Heap 中，导致上述版本差异，下面具体来分析下。 JDK6 图中绿色线条代表 string 对象的内容指向，黑色线条代表地址指向 在 jdk6 中上述的所有打印都是 false ，因为 jdk6 中的常量池是放在 Perm 区中的， Perm 区和正常的 JAVA Heap 区域是完全分开的。上面说过如果是使用引号声明的字符串都是会直接在字符串常量池中生成，而 new 出来的 String 对象是放在 JAVA Heap 区域。所以拿一个 JAVA Heap 区域的对象地址和字符串常量池的对象地址进行比较肯定是不相同的，即使调用 String.intern 方法也是没有任何关系的。 JDK7 因为字符串常量池移动到 JAVA Heap 区域后，再来解释为什么会有上述的打印结果。 在第一段代码中，先看 s3 和 s4 字符串。String s3 = new String(\"1\") + new String(\"1\");，这句代码中现在生成了 2个 最终对象，是字符串常量池中的 “1” 和 JAVA Heap 中的 s3 引用指向的对象。中间还有 2个 匿名的 new String(\"1\") 我们不去讨论它们。此时 s3 引用对象内容是 ”11” ，但此时常量池中是没有 “11” 对象的。 接下来 s3.intern(); 这一句代码，是将 s3 中的 “11” 字符串放入 String 常量池中，因为此时常量池中不存在 “11” 字符串，因此常规做法是跟 jdk6 图中表示的那样，在常量池中生成一个 “11” 的对象，关键点是 jdk7 中常量池不在 Perm 区域了，这块做了调整。常量池中不需要再存储一份对象，可以直接存储堆中的引用。这份引用指向 s3 引用的对象。 也就是说引用地址是相同的。 最后 String s4 = \"11\"; 这句代码中 ”11” 是显示声明的，因此会直接去常量池中创建，创建的时候发现已经有这个对象了，此时也就是指向 s3 引用对象的一个引用。所以 s4 引用就指向和 s3 一样了。因此最后的比较 s3 == s4 是 true 。 再看 s 和 s2 对象。 String s = new String(\"1\"); 第一句代码，生成了2个对象。常量池中的 “1” 和 JAVA Heap 中的字符串对象。s.intern(); 这一句是 s 对象去常量池中寻找后发现 “1” 已经在常量池里了。 接下来 String s2 = \"1\"; 这句代码是生成一个 s2 的引用指向常量池中的 “1” 对象。 结果就是 s 和 s2 的引用地址明显不同。 接下来是第二段代码： 第一段代码和第二段代码的改变就是 s3.intern(); 的顺序是放在 String s4 = \"11\"; 后了。这样，首先执行 String s4 = \"11\"; 声明 s4 的时候常量池中是不存在 “11” 对象的，执行完毕后， “11“ 对象是 s4 声明产生的新对象。然后再执行 s3.intern(); 时，常量池中 “11” 对象已经存在了，因此 s3 和 s4 的引用是不同的。 第二段代码中的 s 和 s2 代码中，s.intern();，这一句往后放也不会有什么影响了，因为对象池中在执行第一句代码String s = new String(\"1\"); 的时候已经生成 “1” 对象了。下边的 s2 声明都是直接从常量池中取地址引用的。 s 和 s2 的引用地址是不会相等的。 小结 从上述的例子代码可以看出 jdk7 版本对 intern 操作和常量池都做了一定的修改。主要包括2点： 将 String 常量池 从 Perm 区移动到了 Java Heap 区 String#intern 方法时，如果存在堆中的对象，会直接保存对象的引用，而不会重新创建对象。 使用范例 static final int MAX = 1000 * 10000; static final String[] arr = new String[MAX]; public static void main(String[] args) throws Exception { Integer[] DB_DATA = new Integer[10]; Random random = new Random(10 * 10000); for (int i = 0; i 运行的参数是：-Xmx2g -Xms2g -Xmn1500M 上述代码是一个演示代码，其中有两条语句不一样，一条是使用 intern，一条是未使用 intern。 通过上述结果，我们发现不使用 intern 的代码生成了 1000w 个字符串，占用了大约 640m 空间。 使用了 intern 的代码生成了 1345 个字符串，占用总空间 133k 左右。其实通过观察程序中只是用到了 10 个字符串，所以准确计算后应该是正好相差 100w 倍。虽然例子有些极端，但确实能准确反应出 intern 使用后产生的巨大空间节省。 细心的同学会发现使用了 intern 方法后时间上有了一些增长。这是因为程序中每次都是用了 new String 后，然后又进行 intern 操作的耗时时间，这一点如果在内存空间充足的情况下确实是无法避免的，但我们平时使用时，内存空间肯定不是无限大的，不使用 intern 占用空间导致 jvm 垃圾回收的时间是要远远大于这点时间的。 毕竟这里使用了 1000w 次 intern 才多出来1秒钟多的时间。 不当使用 fastjson 中对所有的 json 的 key 使用了 intern 方法，缓存到了字符串常量池中，这样每次读取的时候就会非常快，大大减少时间和空间。而且 json 的 key 通常都是不变的。这个地方没有考虑到大量的 json key 如果是变化的，那就会给字符串常量池带来很大的负担。 这个问题 fastjson 在1.1.24版本中已经将这个漏洞修复了。程序加入了一个最大的缓存大小，超过这个大小后就不会再往字符串常量池中放了。 参考文档 深入解析String#intern 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"fromwork/":{"url":"fromwork/","title":"框架","keywords":"","body":"框架 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"fromwork/1-netty.html":{"url":"fromwork/1-netty.html","title":"Netty","keywords":"","body":"Netty Netty 是一个 异步 事件驱动 的网络应用框架，用于快速开发高性能、可扩展协议的服务器和客户端 Reactor 无论是 C++ 还是 Java 编写的网络框架，大多数都是基于 Reactor 模式进行设计和开发，Reactor 模式基于事件驱动，特别适合处理海量的 I/O 事件。 反应器设计模式-维基百科 -- 反应器设计模式(Reactor pattern)是一种为处理服务请求并发 提交到一个或者多个服务处理程序的事件设计模式。当请求抵达后，服务处理程序使用解多路分配策略，然后同步地派发这些请求至相关的请求处理程序。 单线程模型 Reactor 单线程模型，指的是所有的 IO 操作都在同一个 NIO 线程上面完成，NIO 线程的职责如下： 作为 NIO 服务端，接收客户端的 TCP 连接； 作为 NIO 客户端，向服务端发起 TCP 连接； 读取通信对端的请求或者应答消息； 向通信对端发送消息请求或者应答消息。 由于 Reactor 模式使用的是异步非阻塞 IO，所有的 IO 操作都不会导致阻塞，理论上一个线程可以独立处理所有 IO 相关的操作。从架构层面看，一个 NIO 线程确实可以完成其承担的职责。例如，通过 Acceptor 类接收客户端的 TCP 连接请求消息，链路建立成功之后，通过 Dispatch 将对应的 ByteBuffer 派发到指定的 Handler 上进行消息解码。用户线程可以通过消息编码通过 NIO 线程将消息发送给客户端。 对于一些小容量应用场景，可以使用单线程模型。但是 对于高负载、大并发的应用场景却不合适。 多线程模型 Rector 多线程模型与单线程模型最大的区别就是有一组 NIO 线程处理 IO 操作，它的原理图如下： Reactor 多线程模型的特点： 有专门一个 NIO 线程 Acceptor 线程用于监听服务端，接收客户端的 TCP 连接请求； 网络 IO 操作 - 读、写等由一个 NIO 线程池负责，线程池可以采用标准的 JDK 线程池实现，它包含一个任务队列和 N 个可用的线程，由这些 NIO 线程负责消息的读取、解码、编码和发送； 1 个 NIO 线程可以同时处理 N 条链路，但是 1 个链路只对应 1 个 NIO 线程，防止发生并发操作问题。 主从多线程模型 主从 Reactor 线程模型的特点是：服务端用于接收客户端连接的不再是个 1 个单独的 NIO 线程，而是一个独立的 NIO 线程池。 Acceptor 接收到客户端 TCP 连接请求处理完成后（可能包含接入认证等），将新创建的 SocketChannel 注册到 IO 线程池（sub reactor 线程池）的某个 IO 线程上，由它负责 SocketChannel 的读写和编解码工作。 Acceptor 线程池仅仅只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端 subReactor 线程池的 IO 线程上，由 IO 线程负责后续的 IO 操作。 它的工作流程总结如下： 从主线程池中随机选择一个 Reactor 线程作为 Acceptor 线程，用于绑定监听端口，接收客户端连接； Acceptor 线程接收客户端连接请求之后创建新的 SocketChannel ，将其注册到主线程池的其它 Reactor 线程上，由其负责接入认证、IP 黑白名单过滤、握手等操作； 步骤 2 完成之后，业务层的链路正式建立，将 SocketChannel 从主线程池的 Reactor 线程的多路复用器上摘除，重新注册到 Sub 线程池的线程上，用于处理 I/O 的读写操作。 Netty 的优势 多路复用，并在 NIO 的基础上进行更高层次的抽象 事件机制 功能强大，预置了多种编解码功能，支持多种主流协议 定制能力强，可以通过ChannelHandler对通信框架进行灵活的扩展 Netty 为什么性能好？ 纯异步：Reactor 线程模型 IO 多路复用 GC 优化：更少的分配内存、池化（Pooling）、复用、选择性的使用 sun.misc.Unsafe 更多的硬件相关优化（mechanical sympathy） 内存泄漏检测 \"Zero Copy\" Zero Copy Netty 的 Zero-copy 体现在如下几个个方面: Netty 提供了 CompositeByteBuf 类, 它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf , 避免了各个 ByteBuf 之间的拷贝. 通过 wrap 操作, 我们可以将 byte[] 数组、ByteBuf 、 ByteBuffer 等包装成一个 Netty ByteBuf 对象, 进而避免了拷贝操作. ByteBuf 支持 slice 操作, 因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf, 避免了内存的拷贝. 通过 FileRegion 包装的 FileChannel.tranferTo 实现文件传输, 可以直接将文件缓冲区的数据发送到目标 Channel , 避免了传统通过循环 write 方式导致的内存拷贝问题. 源码 ByteBuf ByteBuf 扩容采用先倍增后步进的方式 DirectBuffer vs HeapBuffer 在执行网络IO或者文件IO时，如果是使用 DirectBuffer 就会少一次内存拷贝。如果是非 DirectBuffer ，JDK 会先创建一个 DirectBuffer ，再去执行真正的写操作。这是因为，当我们把一个地址通过 JNI 传递给底层的C库的时候，有一个基本的要求，就是这个地址上的内容不能失效。然而，在 GC 管理下的对象是会在 Java 堆中移动的。也就是说，有可能我把一个地址传给底层的 write ，但是这段内存却因为 GC 整理内存而失效了。所以我必须要把待发送的数据放到一个 GC 管不着的地方。这就是调用 native 方法之前，数据一定要在堆外内存的原因。 Netty 启动以及链接建立过程 Epool 触发 NioChannel：是水平触发 EpollChannel：是边缘触发，Netty 自己触发 Epoll Event JDK NIO BUG 正常情况下，selector.select() 操作是阻塞的，只有被监听的 fd 有读写操作时，才被唤醒 但是，在这个 bug 中，没有任何 fd 有读写请求，但是 select() 操作依旧被唤醒 很显然，这种情况下，selectedKeys() 返回的是个空数组 然后按照逻辑执行到 while(true) 处，循环执行，导致死循环。 Netty 解决方案： long currentTimeNanos = System.nanoTime(); for (;;) { // 1.定时任务截止事时间快到了，中断本次轮询 ... // 2.轮询过程中发现有任务加入，中断本次轮询 ... // 3.阻塞式select操作 selector.select(timeoutMillis); // 4.解决jdk的nio bug long time = System.nanoTime(); if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) >= currentTimeNanos) { selectCnt = 1; } else if (SELECTOR_AUTO_REBUILD_THRESHOLD > 0 && selectCnt >= SELECTOR_AUTO_REBUILD_THRESHOLD) { rebuildSelector(); selector = this.selector; selector.selectNow(); selectCnt = 1; break; } currentTimeNanos = time; ... } netty 会在每次进行 selector.select(timeoutMillis) 之前记录一下开始时间 currentTimeNanos ，在 select 之后记录一下结束时间，判断 select 操作是否至少持续了 timeoutMillis 秒。如果持续的时间大于等于 timeoutMillis ，说明就是一次有效的轮询，重置 selectCnt 标志，否则，表明该阻塞方法并没有阻塞这么长时间，可能触发了 jdk 的空轮询 bug ，当空轮询的次数超过一个阀值的时候，默认是 512 ，就开始重建 selector 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"fromwork/mybatis/1-question.html":{"url":"fromwork/mybatis/1-question.html","title":"面试题","keywords":"","body":"面试题 #{}和${}的区别是什么？ #{}是预编译处理，${}是字符串替换。 Mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值； Mybatis在处理${}时，就是把${}替换成变量的值。 使用#{}可以有效的防止SQL注入，提高系统安全性。 通常一个Xml映射文件，都会写一个Dao接口与之对应，请问，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？ Dao接口，就是人们常说的Mapper接口，接口的全限名，就是映射文件中的namespace的值，接口的方法名，就是映射文件中MappedStatement的id值，接口方法内的参数，就是传递给sql的参数。Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MappedStatement，举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到namespace为com.mybatis3.mappers.StudentDao下面id = findStudentById的MappedStatement。在Mybatis中，每一个、、、标签，都会被解析为一个MappedStatement对象。 Dao接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。 Dao接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Dao接口生成代理proxy对象，代理对象proxy会拦截接口方法，转而执行MappedStatement所代表的sql，然后将sql执行结果返回。 参考连接 Mybatis 的常见面试题 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"fromwork/mybatis/2-cache.html":{"url":"fromwork/mybatis/2-cache.html","title":"缓存","keywords":"","body":"Mybatis 缓存机制 Mybatis 的缓存均缓存查询操作结果。按照作用域范围，可以分为： - **一级缓存**： `SqlSession` 级别的缓存 - **二级缓存**： `namespace` 级别的缓存 一级缓存 Mybatis 默认开启了一级缓存， 一级缓存有两个级别可以设置：分别是 SESSION 或者 STATEMENT 默认是 SESSION 级别，即在一个 MyBatis会话中执行的所有语句，都会共享这一个缓存。一种是 STATEMENT 级别，可以理解为缓存只对当前执行的这一个 Statement 有效。 STATEMENT 级别相当于关闭一级缓存 基本原理 在一级缓存中，当 sqlSession 执行写操作（执行插入、更新、删除），清空 SqlSession 中的一级缓存。 总结 MyBatis 一级缓存的生命周期和SqlSession一致。 MyBatis 一级缓存内部设计简单，只是一个没有容量限定的HashMap，在缓存的功能性上有所欠缺。 MyBatis 的一级缓存最大范围是SqlSession内部，有多个SqlSession或者分布式的环境下，数据库写操作会引起脏数据，建议设定缓存级别为Statement。 二级缓存 如果多个 SqlSession 之间需要共享缓存，则需要使用到二级缓存。开启二级缓存后，会使用 CachingExecutor 装饰 Executor ，进入一级缓存的查询流程前，先在C achingExecutor 进行二级缓存的查询，具体的工作流程如下所示。 二级缓存开启后，同一个namespace下的所有操作语句，都影响着同一个Cache，即二级缓存被多个SqlSession共享，是一个全局的变量。当开启缓存后，数据的查询执行的流程就是 二级缓存 -> 一级缓存 -> 数据库。 总结 MyBatis 的二级缓存相对于一级缓存来说，实现了 SqlSession 之间缓存数据的共享，同时粒度更加的细，能够到 namespace 级别，通过 Cache 接口实现类不同的组合，对Cache的可控性也更强。 MyBatis 在多表查询时，极大可能会出现脏数据，有设计上的缺陷，安全使用二级缓存的条件比较苛刻。 在分布式环境下，由于默认的 MyBatis Cache 实现都是基于本地的，分布式环境下必然会出现读取到脏数据，需要使用集中式缓存将 MyBatis 的 Cache 接口实现，有一定的开发成本，直接使用 Redis、Memcached 等分布式缓存可能成本更低，安全性也更高。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"fromwork/mybatis/3-proxy.html":{"url":"fromwork/mybatis/3-proxy.html","title":"代理","keywords":"","body":"Mybatis 动态代理 获取代理类流程 获取Mapper代理类的时序图如下： 重点说下MapperProxy类，声明如下： public class MapperProxy implements InvocationHandler, Serializable 获取到 MapperProxy 之后，根据调用不同的方法，会将最终的参数传递给 SqlSession。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"fromwork/spring/":{"url":"fromwork/spring/","title":"Spring","keywords":"","body":"Spring Spring Framework 是一个开源的Java／Java EE全功能栈（full-stack）的应用程序框架，其提供了一个简易的开发方式，这种开发方式，将避免那些可能致使底层代码变得繁杂混乱的大量的属性文件和帮助类。 Spring中包含的关键特性 强大的基于JavaBeans的采用 控制反转 （Inversion of Control，IoC）原则的配置管理，使得应用程序的组建更加快捷简易。 一个可用于 Java EE 等运行环境的核心 Bean 工厂。 数据库事务的一般化抽象层，允许声明式（Declarative）事务管理器，简化事务的划分使之与底层无关。 内建的针对 JTA 和单个 JDBC 数据源的一般化策略，使 Spring 的事务支持不要求Java EE环境，这与一般的JTA或者EJB CMT相反。 JDBC 抽象层提供了有针对性的异常等级（不再从SQL异常中提取原始代码），简化了错误处理，大大减少了程序员的编码量。再次利用JDBC时，你无需再写出另一个'终止'（finally）模块。并且面向JDBC的异常与Spring通用数据访问对象（Data Access Object）异常等级相一致。 以资源容器，DAO实现和事务策略等形式与 Hibernate，JDO 和 MyBatis、SQL Maps 集成。利用众多的翻转控制方便特性来全面支持，解决了许多典型的 Hibernate 集成问题。所有这些全部遵从 Spring 通用事务处理和通用数据访问对象异常等级规范。 灵活的基于核心 Spring 功能的 MVC 网页应用程序框架。开发者通过策略接口将拥有对该框架的高度控制，因而该框架将适应于多种呈现（View）技术，例如 JSP、FreeMarker、Velocity、Thymeleaf 等。值得注意的是，Spring 中间层可以轻易地结合于任何基于 MVC 框架的网页层，例如 Struts、WebWork 或 Tapestry。 提供诸如事务管理等服务的AOP框架。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"fromwork/spring/1-ioc.html":{"url":"fromwork/spring/1-ioc.html","title":"IOC","keywords":"","body":"IOC Ioc—Inversion of Control，即“控制反转”，不是什么技术，而是一种设计思想。在Java 开发中，Ioc意味着将你设计好的对象交给容器控制，而不是传统的在你的对象内部直接控制。如何理解好Ioc呢？理解好Ioc的关键是要明确“谁控制谁，控制什么，为何是反转（有反转就应该有正转了），哪些方面反转了”，那我们来深入分析一下： 　　- 谁控制谁，控制什么：传统Java SE程序设计，我们直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；而IoC是有专门一个容器来创建这些对象，即由Ioc容器来控制对 象的创建；谁控制谁？当然是IoC 容器控制了对象；控制什么？那就是主要控制了外部资源获取（不只是对象包括比如文件等）。 　　- 为何是反转，哪些方面反转了：有反转就有正转，传统应用程序是由我们自己在对象中主动控制去直接获取依赖对象，也就是正转；而反转则是由容器来帮忙创建及注入依赖对象；为何是反转？因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转；哪些方面反转了？依赖对象的获取被反转了。 IoC能做什么 　　IoC 不是一种技术，只是一种思想，一个重要的面向对象编程的法则，它能指导我们如何设计出松耦合、更优良的程序。传统应用程序都是由我们在类内部主动创建依赖对象，从而导致类与类之间高耦合，难于测试；有了IoC容器后，把创建和查找依赖对象的控制权交给了容器，由容器进行注入组合对象，所以对象与对象之间是 松散耦合，这样也方便测试，利于功能复用，更重要的是使得程序的整个体系结构变得非常灵活。 IoC和DI DI—Dependency Injection，即“依赖注入”：组件之间依赖关系由容器在运行期决定，形象的说，即由容器动态的将某个依赖关系注入到组件之中。依赖注入的目的并非为软件系统带来更多功能，而是为了提升组件重用的频率，并为系统搭建一个灵活、可扩展的平台。通过依赖注入机制，我们只需要通过简单的配置，而无需任何代码就可指定目标需要的资源，完成自身的业务逻辑，而不需要关心具体的资源来自何处，由谁实现。 理解DI的关键是：“谁依赖谁，为什么需要依赖，谁注入谁，注入了什么”，那我们来深入分析一下： 　　- 谁依赖于谁：当然是应用程序依赖于IoC容器； 　　- 为什么需要依赖：应用程序需要IoC容器来提供对象需要的外部资源； 　　- 谁注入谁：很明显是IoC容器注入应用程序某个对象，应用程序依赖的对象； 　　- 注入了什么：就是注入某个对象所需要的外部资源（包括对象、资源、常量数据）。 IoC和DI由什么关系呢？其实它们是同一个概念的不同角度描述，由于控制反转概念比较含糊（可能只是理解为容器控制对象这一个层面，很难让人想到谁来维护对象关系），所以2004年大师级人物Martin Fowler又给出了一个新的名字：“依赖注入”，相对IoC 而言，“依赖注入”明确描述了“被注入对象依赖IoC容器配置依赖对象”。 IOC vs Factory 简单来说，IOC 与 工厂模式 分别代表了 push 与 pull 的机制： Pull 机制：类间接依赖于 Factory Method ，而 Factory Method 又依赖于具体类。 Push 机制：容器可以在一个位置配置所有相关组件，从而促进高维护和松耦合。 使用 工厂模式 的责任仍然在于类（尽管间接地）来创建新对象，而 依赖注入 将责任外包。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"fromwork/spring/2-design-partten.html":{"url":"fromwork/spring/2-design-partten.html","title":"设计模式","keywords":"","body":"设计模式 代理模式：AOP 单例模式：默认 Bean 为单例 工厂模式：BeanFactory IOC：依赖倒置 or 依赖注入 MVC：spring web 模版方法模式：JdbcTemplate 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"fromwork/spring/3-aop.html":{"url":"fromwork/spring/3-aop.html","title":"AOP","keywords":"","body":"AOP AOP 的存在价值 在传统 OOP 编程里以对象为核心，整个软件系统由系列相互依赖的对象所组成，而这些对象将被抽象成一个一个的类，并允许使用类继承来管理类与类之间一般到特殊的关系。随着软件规模的增大，应用的逐渐升级，慢慢出现了一些 OOP 很难解决的问题。 我们可以通过分析、抽象出一系列具有一定属性与行为的对象，并通过这些对象之间的协作来形成一个完整的软件功能。由于对象可以继承，因此我们可以把具有相同功能或相同特性的属性抽象到一个层次分明的类结构体系中。随着软件规范的不断扩大，专业化分工越来越系列，以及 OOP 应用实践的不断增多，随之也暴露出了一些 OOP 无法很好解决的问题。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/":{"url":"architecture/","title":"系统架构","keywords":"","body":"系统架构 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/1-base.html":{"url":"architecture/1-base.html","title":"基本概念","keywords":"","body":"系统架构基础 分布式系统的最大难点，就是各个节点的状态如何同步。CAP 定理是这方面的基本定理，也是理解分布式系统的起点。 1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标。 Consistency Availability Partition tolerance 它们的第一个字母分别是 C、A、P。Eric Brewer 说，这三个指标不可能同时做到。这个结论就叫做 CAP 定理。 CAP 数据一致性模型 一些分布式系统通过复制数据来提高系统的可靠性和容错性，并且将数据的不同的副本存放在不同的机器，由于维护数据副本的一致性代价高，因此许多系统采用弱一致性来提高性能，一些不同的一致性模型也相继被提出。 强一致性： 要求无论更新操作实在哪一个副本执行，之后所有的读操作都要能获得最新的数据。 弱一致性：用户读到某一操作对系统特定数据的更新需要一段时间，我们称这段时间为“不一致性窗口”。 最终一致性：是弱一致性的一种特例，保证用户最终能够读取到某操作对系统特定数据的更新。 一致性解决方案 分布式事务：两段提交 分布式锁 MQ 消息持久化 重试 幂等 Paxos 算法 服务可用性 可用性，意思是只要收到用户的请求，服务器就必须给出回应。 高可用解决方案 负载均衡： 降级：当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。 熔断：对于目标服务的请求和调用大量超时或失败，这时应该熔断该服务的所有调用，并且对于后续调用应直接返回，从而快速释放资源，确保在目标服务不可用的这段时间内，所有对它的调用都是立即返回，不会阻塞的。再等到目标服务好转后进行接口恢复。 流量控制： 异地多活： 熔断是减少由于下游服务故障对自己的影响；而降级则是在整个系统的角度上，考虑业务整体流量，保护核心业务稳定。 分区容错性 大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。 般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/concurrent/":{"url":"architecture/concurrent/","title":"高并发","keywords":"","body":"高并发 高并发指的是：在同时或极短时间内，有大量的请求到达服务端，每个请求都需要服务端耗费资源进行处理，并做出相应的反馈。 服务端处理请求需要耗费服务端的资源，比如能同时开启的 进程数 、能同时运行的 线程数 、网络连接数、 cpu 、I/O、内存 等等，由于服务端资源是有限的，那么服务端能同时处理的请求也是有限的。 高并发问题的本质就是：资源的有限性 高并发带来的问题：服务端的处理和响应会越来越慢，甚至会丢弃部分请求不予处理，更严重的会导致服务端崩溃。 处理的思路 客户端 尽量减少请求数量，比如：依靠客户端自身的缓存或处理能力 尽量减少对服务端资源的不必要耗费，比如：重复使用某些资源，如连接池 基本原则就是：能不访问服务端就不要访问 服务端 增加资源供给，比如：更大的网络带宽，使用更高配置的服务器，使用高性能的Web服务器，使用高性能的数据库 请求分流，比如：使用集群,分布式的系统架构 应用优化，比如：使用更高效的编程语言,优化处理业务逻辑的算法,优化访问数据库的SQL 基本原则：分而治之，并提高单个请求的处理速度 处理的方法 处理高并发的三板斧: 缓存、降级和限流！ 应用层：扩容、动静分离、缓存、服务降级和限流 数据库：读写分离、分库分表 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/concurrent/1-flow_control.html":{"url":"architecture/concurrent/1-flow_control.html","title":"流量控制","keywords":"","body":"高并发下的流量控制 这个时候如果不做任何保护措施，服务器就会承受很大的处理压力，请求量很高，服务器负载也很高，并且当请求超过服务器承载极限的时候，系统就会崩溃，导致所有人都不能访问。 为了应用服务的高可用，一个常用的办法是对大流量的请求（秒杀/抢购）进行限流，拦截掉大部分请求，只允许一部分请求真正进入后端服务器，这样就可以防止大量请求造成系统压力过大导致的系统崩溃，从而保护服务正常可用。 令牌桶(Token Bucket)、漏桶(leaky bucket)和 计数器 算法是最常用的三种限流的算法。 限流算法 计数器 计数器限流算法也是比较常用的，主要用来限制总并发数。比如限流 qps 为 100 ，算法的实现思路就是从第一个请求进来开始计时，在接下去的 1s 内，每来一个请求，就把计数加 1 ，如果累加的数字达到了 100 ，那么后续的请求就会被全部拒绝。等到 1s 结束后，把计数恢复成 0 ，重新开始计数。 这种实现方式有一个弊端：如果我在单位时间 1s 内的前 10ms ，已经通过了 100 个请求，那后面的 990ms ，只能眼巴巴的把请求拒绝，这种现象称为 突刺现象。 漏桶 为了消除 突刺现象，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。 不管服务调用方多么不稳定，通过漏桶算法进行限流，每 10 毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。 在算法实现方面，可以 准备一个队列，用来保存请求，另外通过一个线程池定期从队列中获取请求并执行，可以一次性获取多个并发执行。 这种算法，在使用过后也存在弊端：无法应对短时间的突发流量，同时它的优点也是可以平滑网络上的突发流量，请求可以被整形成稳定的流量。 令牌桶 从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。 在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。 放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置 qps 为 100 ，那么限流器初始化完成一秒后，桶中就已经有 100 个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的 100 个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。 实现思路：可以 准备一个队列，用来保存令牌，另外通过一个线程池定期生成令牌放到队列中，每来一个请求，就从队列中获取一个令牌，并继续执行。 漏桶 VS 令牌桶：两者主要区别在于“漏桶算法”能够强行限制数据的传输速率，而“令牌桶算法”在能够限制数据的平均传输速率外，还允许某种程度的突发传输。在“令牌桶算法”中，只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，所以它适合于具有突发特性的流量。 集群限流 Redis 请求窗口 采用redis 的计时和计数方式,在规定的时间窗口期,允许通过的最大请求数量 比如为了限制某个资源被每个用户或者商户的访问次数，5s 只能访问 2 次，或者一天只能调用 1000 次，这种需求，单机限流是无法实现的，这时就需要通过集群限流进行实现。 如何实现？为了控制访问次数，肯定需要一个计数器，而且这个计数器只能保存在第三方服务，比如redis。 大概思路：每次有相关操作的时候，就向 redis 服务器发送一个 incr 命令，比如需要限制某个用户访问 /index 接口的次数，只需要拼接用户 id 和接口名生成 redis 的 key ，每次该用户访问此接口时，只需要对这个 key 执行 incr 命令，在这个 key 带上过期时间，就可以实现指定时间的访问频率。 Nginx 限流 Nginx按请求速率限速模块使用的是漏桶算法，即能够强行保证请求的实时处理速度不会超过设置的阈值。 Nginx官方版本限制IP的连接和并发分别有两个模块： limit_req_zone 用来限制单位时间内的请求数，即速率限制,采用的漏桶算法 \"leaky bucket\"。 limit_req_conn 用来限制同一时间连接数，即并发限制。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/design/":{"url":"architecture/design/","title":"系统设计","keywords":"","body":"系统设计 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/design/1-tinyURL.html":{"url":"architecture/design/1-tinyURL.html","title":"短链接系统","keywords":"","body":"短链接 使用场景(Scenario) 微博和Twitter都有140字数的限制，如果分享一个长网址，很容易就超出限制，发布出去。短网址服务可以把一个长网址变成短网址，方便在社交网络上传播。 需求(Needs) 很显然，要尽可能的短。长度设计为多少才合适呢？ 短网址的长度 当前互联网上的网页总数大概是 45亿(参考 短网址短网址资讯mrw.so)，45亿 超过了 2^{32}=4294967296232=4294967296，但远远小于64位整数的上限值，那么用一个64位整数足够了。微博的短网址服务用的是长度为 7 的字符串，这个字符串可以看做是62进制的数，那么最大能表示{62}^7=3521614606208627=3521614606208个网址，远远大于 45亿。所以长度为7就足够了。一个64位整数如何转化为字符串呢？，假设我们只是用大小写字母加数字，那么可以看做是62进制数，`log{62{(2^{64}-1)=10.7log62(264−1)=10.7`，即字符串最长11就足够了。实际生产中，还可以再短一点，比如新浪微博采用的长度就是7，因为 62^7=3521614606208627=3521614606208，这个量级远远超过互联网上的URL总数了，绝对够用了。现代的web服务器（例如Apache, Nginx）大部分都区分URL里的大小写了，所以用大小写字母来区分不同的URL是没问题的。因此，正确答案：长度不超过7的字符串，由大小写字母加数字共62个字母组成。 一对一还是一对多映射？ 一个长网址，对应一个短网址，还是可以对应多个短网址？ 这也是个重大选择问题。一般而言，一个长网址，在不同的地点，不同的用户等情况下，生成的短网址应该不一样，这样，在后端数据库中，可以更好的进行数据分析。如果一个长网址与一个短网址一一对应，那么在数据库中，仅有一行数据，无法区分不同的来源，就无法做数据分析了。 以这个7位长度的短网址作为唯一ID，这个ID下可以挂各种信息，比如生成该网址的用户名，所在网站，HTTP头部的 User Agent等信息，收集了这些信息，才有可能在后面做大数据分析，挖掘数据的价值。短网址服务商的一大盈利来源就是这些数据。 正确答案：一对多 如何计算短网址 现在我们设定了短网址是一个长度为7的字符串，如何计算得到这个短网址呢？ 最容易想到的办法是哈希，先hash得到一个64位整数，将它转化为62进制整，截取低7位即可。但是哈希算法会有冲突，如何处理冲突呢，又是一个麻烦。这个方法只是转移了矛盾，没有解决矛盾，抛弃。 正确答案：分布式发号器(Distributed ID Generator) 如何存储 如果存储短网址和长网址的对应关系？以短网址为 primary key, 长网址为value, 可以用传统的关系数据库存起来，例如MySQL,PostgreSQL，也可以用任意一个分布式 KV 数据库，例如Redis, LevelDB。 301还是302重定向 这也是一个有意思的问题。这个问题主要是考察你对301和302的理解，以及浏览器缓存机制的理解。 301是永久重定向，302是临时重定向。短地址一经生成就不会变化，所以用301是符合http语义的。但是如果用了301， Google，百度等搜索引擎，搜索的时候会直接展示真实地址，那我们就无法统计到短地址被点击的次数了，也无法收集用户的Cookie, User Agent 等信息，这些信息可以用来做很多有意思的大数据分析，也是短网址服务商的主要盈利来源。 所以，正确答案是302重定向。 可以抓包看看mrw.so的短网址是怎么做的，使用 Chrome 浏览器，访问这个URL http://mrw.so/4UD39p，是我事先发微博自动生成的短网址。来抓包看看返回的结果是啥，可见新浪微博用的就是302临时重定向。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/distributed/":{"url":"architecture/distributed/","title":"分布式","keywords":"","body":"分布式 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/distributed/1-session.html":{"url":"architecture/distributed/1-session.html","title":"分布式 Session","keywords":"","body":"分布式 Session 当一个带有会话表示的 Http 请求到 Web 服务器后，需求在请求中的处理过程中找到 session 数据。而问题就在于， session 是保存在单机上的。 假设我们有应用A和应用B，现在一位用户第一次访问网站， session 数据保存在 应用A 中。如果我们不做处理，怎么保障接下来的请求每次都请求到 应用A 呢? 如请求到了 应用B 中，就会发现没有这位用户的 session 数据，这绝对是不能容忍的。 解决方案有Session Stick，Session复制，Session集中管理，基于Cookie管理，下面一一说明。 Session Stick 在单机情况， session 保存在单机上，请求也是到这台单机上，不会有问题。变成多台后，如果能保障每次请求都到同一台服务，那就和单机一样了。 这需要在负载均衡设备上修改。这就是 Session Stick ，这种方式也会有问题： 如果某一台服务器宕机或重启，那么这台服务器上的 session 数据就丢失了。如果 session 数据中还有登录状态信息，那么用户需要重现登录。 负载均衡要处理具体的 session 到服务器的映射。 Session复制 Session 复制顾名思义，就是每台应用服务，都保存会话 session 数据，一般的应用容器都支持。与 Session Stick 相比， sessioon 复制对负载均衡 没有太多的要求。不过这个方案还是有缺点： 同步 session 数据带来都网络开销。只要 session 数据变化，就需要同步到所有机器上，机器越多，网络开销越大。 由于每台服务器都保存 session 数据，如果集群的 session 数据很多，比如 90万 人在访问网站，每台机器用于保存 session 数据的内容占用很严重。 这就是 Session 复制，这个方案是靠应用容器来完成，并不依赖应用，如果应用服务数量并不是很多，可以考虑。 Session集中管理 这个也很好理解，再加一台服务，专门来管理 session 数据，每台应用服务都从专门的 session 管理服务中取会话 session 数据。可以使用数据库，NOSQL数据库等。 和Session复制相比，减少了每台应用服务的内存使用，同步session带来的网络开销问题。但还是有缺点： 读写 session 引入了网络操作，相对于本机读写 session ，带来了延时和不稳定性。 如 Session 集中服务有问题，会影响应用。 基于Cookie管理 最后一个是基于 Cookie 管理，我们把 session 数据存放在 cookie 中，然后请求过来后，从 cookie 中获取 session 数据。与集中管理相比，这个方案并不依赖外部 的存储系统，读写 session 数据带来的网络操作延时和不稳定性。但依然有缺点： Cookie有长度限制，这会影响session数据的长度。 安全性：session数据本来存储在服务端的，而这个方案是让 session 数据转到外部网络或客户端中，所以会有安全性问题。不过可以对写入 Cookie 的 session 数据做加密。 带宽消耗：由于加了session数据，带宽当然也会增加一点。 性能消耗：每次Http请求和响应都带有Session数据，对于Web服务器来说，在同样的处理情况下，响应的结果输出越少，支持的并发请求越多。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/distributed/2-cache.html":{"url":"architecture/distributed/2-cache.html","title":"分布式缓存","keywords":"","body":"分布式缓存 高并发环境下，例如典型的淘宝双11秒杀，几分钟内上亿的用户涌入淘宝，这个时候如果访问不加拦截，让大量的读写请求涌向数据库，由于磁盘的处理速度与内存显然不在一个量级，服务器马上就要宕机。从减轻数据库的压力和提高系统响应速度两个角度来考虑，都会在数据库之前加一层缓存，访问压力越大的，在缓存之前就开始 CDN 拦截图片等访问请求。 并且由于最早的单台机器的内存资源以及承载能力有限，如果大量使用本地缓存，也会使相同的数据被不同的节点存储多份，对内存资源造成较大的浪费，因此，才催生出了分布式缓存。 应用场景 页面缓存：用来缓存Web 页面的内容片段,包括HTML、CSS 和图片等; 应用对象缓存：缓存系统作为ORM 框架的二级缓存对外提供服务,目的是减轻数据库的负载压力,加速应用访问;解决分布式Web部署的 session 同步问题，状态缓存.缓存包括Session 会话状态及应用横向扩展时的状态数据等,这类数据一般是难以恢复的,对可用性要求较高,多应用于高可用集群。 并行处理：通常涉及大量中间计算结果需要共享; 云计算领域提供分布式缓存服务 常见问题和挑战 缓存雪崩 缓存雪崩我们可以简单的理解为：由于原有缓存失效、新缓存未到之间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。 缓存穿透 缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。 缓存预热 缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！ 缓存更新 除了缓存服务器自带的缓存失效策略之外，我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种： 定时去清理过期的缓存； 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。 两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。 缓存降级 当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。 降级的最终目的是 保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。 在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案： 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级； 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警； 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级； 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。 缓存与数据库不一致问题 首先，缓存由于其高并发和高性能的特性，已经在项目中被广泛使用。在读取缓存方面，大家没啥疑问，都是按照下图的流程来进行业务操作。 但是在更新缓存方面，对于更新完数据库，是更新缓存呢，还是删除缓存。又或者是先删除缓存，再更新数据库，其实大家存在很大的争议。 从理论上来说，给 缓存设置过期时间，是保证最终一致性的解决方案。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。 先删除缓存，再更新数据库 该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形: 请求A进行写操作，删除缓存 请求B查询发现缓存不存在 请求B去数据库查询得到旧值 请求B将旧值写入缓存 请求A将新值写入数据库 上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。 可以通过： 更新操作数据库后，再次更新缓存来实现 缓存设置过期时间，等待过期时间后，数据恢复 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/distributed/3-lock.html":{"url":"architecture/distributed/3-lock.html","title":"分布式锁","keywords":"","body":"分布式锁 实现基于数据库的乐观锁 提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。 Connection conn = DriverManager.getConnection(url, user, password); conn.setAutoCommit(false); Statement stmt = conn.createStatement(); // step 1 int oldVersion = getOldVersion(stmt); // step 2 // 用这个数据库连接做其他的逻辑 // step 3 可用预编译语句 int i = stmt.executeUpdate( \"update optimistic_lock set version = \" + (oldVersion + 1) + \" where version = \" + oldVersion); // step 4 if (i > 0) { conn.commit(); // 更新成功表明数据没有被修改，提交事务。 } else { conn.rollback(); // 更新失败，数据被修改，回滚。 } 乐观锁的缺点： 会带来大数量的无效更新请求、事务回滚，给DB造成不必要的额外压力。 无法保证先到先得，后面的请求可能由于并发压力小了反而有可能处理成功。 基于 Redis 的分布式锁 Redis 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/distributed/4-transaction.html":{"url":"architecture/distributed/4-transaction.html","title":"分布式事务","keywords":"","body":"分布式事务 系统之间的通信可靠性从单一系统中的可靠变成了微服务架构之间的不可靠，分布式事务其实就是在不可靠的通信下实现事务的特性。无论是事务还是分布式事务实现原子性都无法避免对持久存储的依赖，事务使用磁盘上的日志记录执行的过程以及上下文，这样无论是需要回滚还是补偿都可以通过日志追溯，而分布式事务也会依赖 数据库、Zookeeper 或者 ETCD 等服务追踪事务的执行过程，总而言之，各种形式的日志是保证事务几大特性的 重要 手段。 2PC 与 3PC 2PC 两阶段提交的执行过程就跟它的名字一样分为两个阶段，投票阶段和提交阶段，在投票阶段中，协调者（Coordinator）会向事务的参与者（Cohort）询问是否可以执行操作的请求，并等待其他参与者的响应，参与者会执行相对应的事务操作并 记录重做和回滚日志，所有执行成功的参与者会向协调者发送 AGREEMENT 或者 ABORT 表示执行操作的结果。 当所有的参与者都返回了确定的结果（同意或者终止）时，两阶段提交就进入了提交阶段，协调者会根据投票阶段的返回情况向所有的参与者发送提交或者回滚的指令。 当事务的所有参与者都决定提交事务时，协调者会向参与者发送 COMMIT 请求，参与者在完成操作并释放资源之后向协调者返回完成消息，协调者在收到所有参与者的完成消息时会结束整个事务；与之相反，当有参与者决定 ABORT 当前事务时，协调者会向事务的参与者发送回滚请求，参与者会根据之前执行操作时的回滚日志对操作进行回滚并向协调者发送完成的消息，在提交阶段，无论当前事务被提交还是回滚，所有的资源都会被释放并且事务也一定会结束。 两阶段提交协议是一个阻塞协议，也就是说在两阶段提交的执行过程中，除此之外，如果事务的执行过程中协调者永久宕机，事务的一部分参与者将永远无法完成事务，它们会等待协调者发送 COMMIT 或者 ROLLBACK 消息，甚至会出现多个参与者状态不一致的问题。 3PC 为了解决两阶段提交在协议的一些问题，三阶段提交引入了超时机制和准备阶段，如果协调者或者参与者在规定的之间内没有接受到来自其他节点的响应，就会根据当前的状态选择提交或者终止整个事务，准备阶段的引入其实让事务的参与者有了除回滚之外的其他选择。 当参与者向协调者发送 ACK 后，如果长时间没有得到协调者的响应，在默认情况下，参与者会自动将超时的事务进行提交，不会像两阶段提交中被阻塞住；上述的图片非常清楚地说明了在不同阶段，协调者或者参与者的超时会造成什么样的行为。 消息服务 分布式事务带来复杂度的原因其实就是由于各个模块之间的通信不稳定，当我们发出一个网络请求时，可能的返回结果是成功、失败或者超时。 网络无论是返回成功还是失败其实都是一个确定的结果，当网络请求超时的时候其实非常不好处理，在这时调用方并不能确定这一次请求是否送达而且不会知道请求的结果，但是 消息服务 可以保证某条信息一定会送达到调用方；大多数消息服务都会提供两种不同的 QoS ，也就是服务的等级。 最常见的两种服务等级就是 At-Most-Once 和 At-Least-Once 。 At-Most-Once：能够保证发送方不对接收方是否能收到消息作保证，消息要么会被投递一次，要么不会被投递，这其实跟一次普通的网络请求没有太多的区别； At-Least-Once：能够解决消息投递失败的问题，它要求发送者检查投递的结果，并在失败或者超时时重新对消息进行投递，发送者会持续对消息进行推送，直到接受者确认消息已经被收到 相比于 At-Most-Once，At-Least-Once 因为能够确保消息的投递会被更多人使用。 除了这两种常见的服务等级之外，还有另一种服务等级，也就是 Exactly-Once，这种服务等级不仅对发送者提出了要求，还对消费者提出了要求，它需要接受者对接收到的所有消息进行去重，发送者和接受者一方对消息进行重试，另一方对消息进行去重，两者分别部署在不同的节点上，这样对于各个节点上的服务来说，它们之间的通信就是 Exactly-Once 的，但是需要注意的是，Exacly-Once 一定需要接收方的参与。 使用消息服务实现分布式事务在底层的原理上与其他的方法没有太多的差别，只是 消息服务能够帮助我们实现的消息的持久化以及重试等功能，能够为我们提供一个比较合理的 API 接口，方便开发者使用。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/distributed/5-mq.html":{"url":"architecture/distributed/5-mq.html","title":"消息队列","keywords":"","body":"MQ 消息队列技术(Message Queue) 是分布式应用间交换信息的一种技术。消息队列可驻留在内存或磁盘上, 队列存储消息直到它们被应用程序读走。通过消息队列，应用程序可独立地执行 ———— 它们不需要知道彼此的位置、或在继续执行前不需要等待接收程序接收此消息。在分布式计算环境中，为了集成分布式应用，开发者需要对异构网络环境下的分布式应用提供有效的通信手段。 MQ使用场景 异步通信：有些业务不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。 解耦：降低工程间的强依赖程度，针对异构系统进行适配。在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。通过消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口，当应用发生变化时，可以独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束 冗余：有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的\"插入-获取-删除\"范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。 扩展性：因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。便于分布式扩容 过载保护：在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量无法提取预知；如果以为了能处理这类瞬间峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃 可恢复性：系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。 顺序保证：在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。 缓冲：在任何重要的系统中，都会有需要不同的处理时间的元素。消息队列通过一个缓冲层来帮助任务最高效率的执行，该缓冲有助于控制和优化数据流经过系统的速度。以调节系统响应时间。 数据流处理：分布式系统产生的海量数据流，如：业务日志、监控数据、用户行为等，针对这些数据流进行实时或批量采集汇总，然后进行大数据分析是当前互联网的必备技术，通过消息队列完成此类数据收集是最好的选择 MQ缺点 系统可用性降低：系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了， ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用。 系统复杂度提高：硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。 一致性问题： A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里， BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。 MQ常用协议 AMQP协议 AMQP即Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。 优点：可靠、通用 MQTT协议 MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分。该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和致动器（比如通过Twitter让房屋联网）的通信协议。 优点：格式简洁、占用带宽小、移动端通信、PUSH、嵌入式系统 STOMP协议 STOMP（Streaming Text Orientated Message Protocol）是流文本定向消息协议，是一种为MOM(Message Oriented Middleware，面向消息的中间件)设计的简单文本协议。STOMP提供一个可互操作的连接格式，允许客户端与任意STOMP消息代理（Broker）进行交互。 优点：命令模式（非topic/queue模式） XMPP协议 XMPP（可扩展消息处理现场协议，Extensible Messaging and Presence Protocol）是基于可扩展标记语言（XML）的协议，多用于即时消息（IM）以及在线现场探测。适用于服务器之间的准即时操作。核心是基于XML流传输，这个协议可能最终允许因特网用户向因特网上的其他任何人发送即时消息，即使其操作系统和浏览器不同。 优点：通用公开、兼容性强、可扩展、安全性高，但XML编码格式占用带宽大 其他基于TCP/IP自定义的协议：有些特殊框架（如：redis、kafka、zeroMq等）根据自身需要未严格遵循MQ规范，而是基于TCP\\IP自行封装了一套协议，通过网络socket接口进行传输，实现了MQ的功能。 MQ的通讯模式 点对点通讯：点对点方式是最为传统和常见的通讯方式，它支持一对一、一对多、多对多、多对一等多种配置方式，支持树状、网状等多种拓扑结构。 多点广播：MQ适用于不同类型的应用。其中重要的，也是正在发展中的是\"多点广播\"应用，即能够将消息发送到多个目标站点(Destination List)。可以使用一条MQ指令将单一消息发送到多个目标站点，并确保为每一站点可靠地提供信息。MQ不仅提供了多点广播的功能，而且还拥有智能消息分发功能，在将一条消息发送到同一系统上的多个用户时，MQ将消息的一个复制版本和该系统上接收者的名单发送到目标MQ系统。目标MQ系统在本地复制这些消息，并将它们发送到名单上的队列，从而尽可能减少网络的传输量。 发布/订阅(Publish/Subscribe)模式：发布/订阅功能使消息的分发可以突破目的队列地理指向的限制，使消息按照特定的主题甚至内容进行分发，用户或应用程序可以根据主题或内容接收到所需要的消息。发布/订阅功能使得发送者和接收者之间的耦合关系变得更为松散，发送者不必关心接收者的目的地址，而接收者也不必关心消息的发送地址，而只是根据消息的主题进行消息的收发。在MQ家族产品中，MQ Event Broker是专门用于使用发布/订阅技术进行数据通讯的产品，它支持基于队列和直接基于TCP/IP两种方式的发布和订阅。 集群(Cluster)：为了简化点对点通讯模式中的系统配置，MQ提供 Cluster 的解决方案。集群类似于一个 域(Domain) ，集群内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用 Cluster 通道与其它成员通讯，从而大大简化了系统配置。此外，集群中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性 消息投递保证 At most once：消息可能会丢，但绝不会重复投递 At least one：消息绝不会丢，但可能会重复投递 Exactly once：每条消息肯定会被投递一次且仅投递一次，很多时候这是用户所想要的。 参考链接 消息队列面试场景 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/distributed/6-zk.html":{"url":"architecture/distributed/6-zk.html","title":"Zookeeper","keywords":"","body":"Zookeeper 集群 一个 ZooKeeper 集群通常由一组机器组成，一般 3 台以上就可以组成一个可用的 ZooKeeper 集群了。组成 ZooKeeper 集群的每台机器都会在内存中维护当前的服务器状态，并且每台机器之间都会互相保持通信。 ZooKeeper 本身就是一个 复制和分布式 应用程序，其目的作为服务运行，类似于我们运行DNS或任何其他集中式服务的方式。 ZK 集群 半数以上存活 即可用 ZooKeeper 的客户端程序会选择和集群中的任意一台服务器创建一个 TCP 连接，而且一旦客户端和服务器断开连接，客户端就会自动连接到集群中的其他服务器。 ZooKeeper 集群中包含以下角色： 领导者（leader）：负责进行投票的发起和决议，更新系统状态； 学习者（learner）：包括跟随者（follower）和观察者（observer）， follower 用于接受客户端请求并向客户端返回结果，在选主过程中参与投票； observer 可以接受客户端连接，将写请求转发给leader，但 observer 不参加投票过程，只同步 leader 的状态， observer 的目的是为了扩展系统，提高读取速度； 数据模型 到znode是一个标准的文件系统，层次结构很像一棵树。 需要注意的一些要点如下： 根节点有一个名为 /zoo 的子节点，它又有三个 znode 。 ZooKeeper 树中的每个 znode 都由一个路径标识，路径元素由/分隔。 这些节点被称为数据寄存器，因为它们可以存储数据。 因此，一个 znode 可以有子节点以及与之相关的数据。 这与文件系统可以把文件作为路径很类似。 znode 中的数据通常以字节格式存储，每个 znode 中的最大数据大小不超过1 MB。 ZooKeeper 是为协调而设计的，几乎所有形式的协调数据都比较小， 因此，对数据大小的限制是强制的。 与文件系统中的文件一样， znode 维护一个 stat 结构，其中包含数据更改的 版本号 以及随更改相关的时间戳而更改的 访问控制列表。 只要 znode 的数据发生变化，版本号就会增加。 ZooKeeper 使用版本号以及相关的时间戳来验证它的核心内缓存。 znode 版本号还允许客户端通过 ZooKeeper API 更新或删除特定的 znode。 如果指定的版本号与 znode 的当前版本不匹配，则操作失败。 但是，执行 znode 更新或删除操作时，可以通过指定0作为版本号来覆盖。 Znode 类型 persistent ephemeral sequential Watcher ZooKeeper 的设计是一种可伸缩的、健壮的集中式服务。在客户端访问此类服务时，常见的设计模式是通过轮询或拉式（pull）模型。当在大型和复杂的分布式系统中实现时，拉模型常常会受到可伸缩性问题的影响。为了解决这个问题，ZooKeeper设计了一种机制，客户端可以从 ZooKeeper 服务中获取通知。客户端接收到这个消息通知之后，需要主动到服务端获取最新的数据。 客户可以使用 ZooKeeper 服务注册与 znode 相关的任何更改。 这种注册被称为在 ZooKeeper 术语中的 znode 上设置 watch。 监视允许客户以任何方式更改 znode 时收到通知。 Watcher 是一次性操作，这意味着它只触发一个通知。 要继续接收通知，客户必须在收到每个事件通知后重新注册一个监视。 监视触发： 对 znode 数据的任何更改，例如使用 setData 操作将新数据写入 znode 的数据字段时。 对 znode 的子节点的任何更改。 例如，一个 znode 的子节点被删除。 正在创建或删除的 znode ，如果将新的 znode 添加到路径中或现有的 znode 被删除，则可能发生这种情况。 同样，ZooKeeper 针对监视和通知声明以下保证： ZooKeeper 确保监视始终以先进先出（FIFO）方式排序，并且通知总是按顺序发送 在对同一个 znode 进行任何其他更改之前，监视会将通知发送给客户端 监视事件的顺序是按照 ZooKeeper 服务的更新顺序排列的 应用场景 发布订阅 通过 Zookeeper 进行数据的发布与订阅其实可以说是它提供的最基本功能，它能够允许多个客户端同时订阅某一个节点的变更并在变更发生时执行我们预先设置好的回调函数，在运行时改变服务的配置和行为 命名服务 除了实现服务配置数据的发布与订阅功能，Zookeeper 还能帮助分布式系统实现命名服务，在每一个分布式系统中，客户端应用都有根据指定名字获取资源、服务器地址的需求，在这时就要求整个集群中的全部服务有着唯一的名字。 在大型分布式系统中，有两件事情非常常见，一是不同服务之间的可能拥有相同的名字，另一个是同一个服务可能会在集群中部署很多的节点，Zookeeper 就可以通过文件系统和顺序节点解决这两个问题。 协调分布式事务 Zookeeper 的另一个作用就是担任分布式事务中的协调者角色，在之前介绍 分布式事务 的文章中我们曾经介绍过分布式事务本质上都是通过 2PC 来实现的，在两阶段提交中就需要一个协调者负责协调分布式事务的执行。 所有的事务参与者会向当前节点中写入提交或者终止，一旦当前的节点改变了事务的状态，其他节点就会得到通知，如果出现一个写入终止的节点，所有的节点就会回滚对分布式事务进行回滚。 分布式锁 在数据库中，锁的概念其实是非常重要的，常见的关系型数据库就会对排他锁和共享锁进行支持，而 Zookeeper 提供的 API 也可以让我们非常简单的实现分布式锁。 作为分布式协调服务，Zookeeper 的应用场景非常广泛，不仅能够用于服务配置的下发、命名服务、协调分布式事务以及分布式锁，还能够用来实现微服务治理中的服务注册以及发现等功能，这些其实都源于 Zookeeper 能够提供高可用的分布式协调服务，能够为客户端提供分布式一致性的支持。 FAQ 这段时间来，也在和公司里的一些同学交流使用zk的心得，整理了一些常见的zookeeper问题。这个页面的目标是解答一些zk常见的使用问题，同时也让大家明确zk不能干什么。页面会一直更新。 1. 客户端对 ServerList 的轮询机制是什么 随机，客户端在初始化( new ZooKeeper(String connectString, int sessionTimeout, Watcher watcher) )的过程中，将所有 Server 保存在一个 List 中，然后随机打散，形成一个环。之后从 0 号位开始一个一个使用。两个注意点： Server地址能够重复配置，这样能够弥补客户端无法设置Server权重的缺陷，但是也会加大风险。（比如: 192.168.1.1:2181,192.168.1.1:2181,192.168.1.2:2181). 如果客户端在进行 Server 切换过程中耗时过长，那么将会收到 SESSION_EXPIRED . 这也是上面第1点中的加大风险之处。 2. 客户端如何正确处理 CONNECTIONLOSS (连接断开) 和 SESSIONEXPIRED (Session 过期)两类连接异常 在 ZooKeeper 中，服务器和客户端之间维持的是一个 长连接，在 SESSION_TIMEOUT 时间内，服务器会确定客户端是否正常连接(客户端会定时向服务器发送 heart_beat ),服务器重置下次 SESSION_TIMEOUT 时间。因此，在正常情况下， Session 一直有效，并且 zk 集群所有机器上都保存这个 Session 信息。在出现问题情况下，客户端与服务器之间连接断了（客户端所连接的那台zk机器挂了，或是其它原因的网络闪断），这个时候客户端会主动在地址列表（初始化的时候传入构造方法的那个参数 connectString ）中选择新的地址进行连接。 好了，上面基本就是服务器与客户端之间维持长连接的过程了。在这个过程中，用户可能会看到两类异常 CONNECTIONLOSS (连接断开) 和 SESSIONEXPIRED (Session 过期)。 CONNECTIONLOSS ：应用在进行操作A时，发生了 CONNECTIONLOSS ，此时用户不需要关心我的会话是否可用，应用所要做的就是等待客户端帮我们自动连接上新的 zk 机器，一旦成功连接上新的 zk 机器后，确认刚刚的操作A是否执行成功了。 SESSIONEXPIRED ：这个通常是zk客户端与服务器的连接断了，试图连接上新的 zk 机器，这个过程如果耗时过长，超过 SESSION_TIMEOUT 后还没有成功连接上服务器，那么服务器认为这个 session 已经结束了（服务器无法确认是因为其它异常原因还是客户端主动结束会话），开始清除和这个会话有关的信息，包括这个会话创建的临时节点和注册的 Watcher 。在这之后，客户端重新连接上了服务器在，但是很不幸，服务器会告诉客户端 SESSIONEXPIRED 。此时客户端要做的事情就看应用的复杂情况了，总之，要重新实例 zookeeper 对象，重新操作所有临时数据（包括临时节点和注册 Watcher ）。 3. 不同的客户端对同一个节点是否能获取相同的数据 4. 一个客户端修改了某个节点的数据，其它客户端能够马上获取到这个最新数据吗 ZooKeeper 不能确保任何客户端能够获取（即 Read Request ）到一样的数据，除非客户端自己要求：方法是客户端在获取数据之前调用org.apache.zookeeper.AsyncCallback.VoidCallback, java.lang.Object) sync. 通常情况下（这里所说的通常情况满足：1. 对获取的数据是否是最新版本不敏感，2. 一个客户端修改了数据，其它客户端需要不需要立即能够获取最新），可以不关心这点。 在其它情况下，最清晰的场景是这样：ZK 客户端 A 对 /my_test 的内容从 v1->v2, 但是 ZK 客户端 B 对 /my_test 的内容获取，依然得到的是 v1. 请注意，这个是实际存在的现象，当然延时很短。解决的方法是客户端B先调用 sync(), 再调用 getData(). 5. ZK为什么不提供一个永久性的Watcher注册机制 不支持用持久Watcher的原因很简单，ZK无法保证性能。 6. 使用watch需要注意的几点 Watches 通知是一次性的，必须重复注册. 发生 CONNECTIONLOSS 之后，只要在 session_timeout 之内再次连接上（即不发生 SESSIONEXPIRED ），那么这个连接注册的 watches 依然在。 节点数据的版本变化会触发 NodeDataChanged ，注意，这里特意说明了是版本变化。存在这样的情况，只要成功执行了 setData()方法，无论内容是否和之前一致，都会触发 NodeDataChanged 。 对某个节点注册了 watch ，但是节点被删除了，那么注册在这个节点上的 watches 都会被移除。 同一个 zk 客户端对某一个节点注册相同的 watch ，只会收到一次通知。 Watcher 对象只会保存在客户端，不会传递到服务端。 7. 我能否收到每次节点变化的通知 如果节点数据的更新频率很高的话，不能。 原因在于：当一次数据修改，通知客户端，客户端再次注册 watch ，在这个过程中，可能数据已经发生了许多次数据修改，因此，千万不要做这样的测试：\"数据被修改了n次，一定会收到n次通知\"来测试 server 是否正常工作。 8. 能为临时节点创建子节点吗 不能。 9. 是否可以拒绝单个IP对ZK的访问,操作 ZK 本身不提供这样的功能，它仅仅提供了对单个 IP 的连接数的限制。你可以通过修改 iptables 来实现对单个 ip 的限制。 10. 在[getChildren(String path, boolean watch)]注册对节点子节点的变化，那么子节点的子节点变化能通知吗 不能 11. 创建的临时节点什么时候会被删除，是连接一断就删除吗？延时是多少？ 连接断了之后，ZK 不会马上移除临时数据，只有当 SESSIONEXPIRED 之后，才会把这个会话建立的临时数据移除。因此，用户需要谨慎设置 Session_TimeOut 12. zookeeper是否支持动态进行机器扩容？如果目前不支持，那么要如何扩容呢？ 3.4.3版本的zookeeper，还不支持这个功能，在3.5.0版本开始，支持动态加机器了。 13. ZooKeeper集群中个服务器之间是怎样通信的？ Leader服务器会和每一个 Follower/Observer 服务器都建立TCP连接，同时为每个 F/O 都创建一个叫做 LearnerHandler 的实体。LearnerHandler 主要负责 Leader 和 F/O 之间的网络通讯，包括数据同步，请求转发和 Proposal 提议的投票等。Leader 服务器保存了所有 F/O 的 LearnerHandler 。 14.zookeeper是否会自动进行日志清理？如果进行日志清理？ zk自己不会进行日志清理，需要运维人员进行日志清理 参考文档 ZooKeeper FAQ Apache ZooKeeper数据模型 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/distributed/7-kafka.html":{"url":"architecture/distributed/7-kafka.html","title":"Kafka","keywords":"","body":"Kafka 术语 Broker：Kafka 集群包含一个或多个服务器，这种服务器被称为 broker 。 Topic：每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic。（物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或多个 broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处）。 Partition： Partition 是物理上的概念，每个 Topic 包含一个或多个 Partition 。 Producer：负责发布消息到 Kafka broker。 Consumer：消息消费者，向 Kafka broker 读取消息的客户端。 Consumer Group：每个 Consumer 属于一个特定的 Consumer Group（可为每个 Consumer 指定 group name，若不指定 group name 则属于默认的 group）。 拓扑结构 如上图所示，一个典型的 Kafka 集群中包含若干 Producer （可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干 broker （Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干 Consumer Group ，以及一个 Zookeeper 集群。 Kafka 通过 Zookeeper 管理集群配置，选举 leader ，以及在 Consumer Group 发生变化时进行 rebalance。 Producer 使用 push 模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。 Topic & Partition Topic 在逻辑上可以被认为是一个 queue ，每条消费都必须指定它的 Topic ，可以简单理解为必须指明把这条消息放进哪个 queue 里。为了使得 Kafka 的吞吐率可以线性提高，物理上把 Topic 分成一个或多个 Partition ，每个 Partition 在物理上对应一个文件夹，该文件夹下存储这个 Partition 的所有消息和索引文件。若创建 topic1 和 topic2 两个 topic ，且分别有 13 个和 19 个分区，则整个集群上会相应会生成共 32 个文件夹（本文所用集群共8个节点，此处 topic1 和 topic2 replication-factor 均为1）。 Partition 都是通过 顺序读写，所以效率很高 replication-factor 配置 partition 副本数。配置副本之后,每个 partition 都有一个唯一的 leader ，有 0 个或多个 follower 。所有的读写操作都在 leader 上完成，followers 从 leader 消费消息来复制 message，就跟普通的 consumer 消费消息一样。一般情况下 partition 的数量大于等于 broker 的数量，并且所有 partition 的 leader 均匀分布在 broker 上。 对于传统的 MQ 而言，一般会删除已经被消费的消息，而 Kafka 集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此 Kafka 提供两种策略删除旧数据。一是基于时间，二是基于 Partition 文件大小。 Producer 消息路由 Producer 发送消息到 broker 时，会根据 Paritition 机制选择将其存储到哪一个 Partition 。如果 Partition 机制设置合理，所有消息可以均匀分布到不同的 Partition 里，这样就实现了负载均衡。如果一个 Topic 对应一个文件，那这个文件所在的机器I/O将会成为这个 Topic 的性能瓶颈，而有了 Partition 后，不同的消息可以并行写入不同 broker 的不同 Partition 里，极大的提高了吞吐率。 可以在 $KAFKA_HOME/config/server.properties 中通过配置项 num.partitions 来指定新建 Topic 的默认 Partition 数量，也可在创建 Topic 时通过参数指定，同时也可以在 Topic 创建之后通过 Kafka 提供的工具修改。 在发送一条消息时，可以指定这条消息的 key ，Producer 根据这个 key 和 Partition 机制来判断应该将这条消息发送到哪个 Parition 。Paritition机制可以通过指定 Producer 的 paritition.class 这一参数来指定，该 class 必须实现 kafka.producer.Partitioner 接口。 Consumer Group 这是 Kafka 用来实现一个 Topic 消息的广播（发给所有的 Consumer ）和单播（发给某一个 Consumer ）的手段。一个 Topic 可以对应多个 Consumer Group 。如果需要实现广播，只要每个 Consumer 有一个独立的 Group 就可以了。要实现单播只要所有的 Consumer 在同一个 Group 里。用 Consumer Group 还可以将 Consumer 进行自由的分组而不需要多次发送消息到不同的 Topic 。 Consumer 个数与 Parition 数有什么关系？ topic 下的一个分区只能被同一个 consumer group 下的一个 consumer 线程来消费，但反之并不成立，即一个 consumer 线程可以消费多个分区的数据。比如 Kafka 提供的 ConsoleConsumer ，默认就只是一个线程来消费所有分区的数据。 即分区数决定了同组消费者个数的上限 所以，如果你的分区数是 N ，那么最好线程数也保持为 N ，这样通常能够达到最大的吞吐量。超过 N 的配置只是浪费系统资源，因为多出的线程不会被分配到任何分区。 Push vs. Pull　　 作为一个消息系统，Kafka 遵循了传统的方式，选择由 Producer 向 broker push 消息并由 Consumer 从 broker pull 消息。事实上，push 模式和 pull 模式各有优劣。 Push模式 很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成 Consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。 Pull模式 可以根据Consumer的消费能力以适当的速率消费消息。 对于 Kafka 而言，Pull模式 更合适。Pull模式 可简化 broker 的设计，Consumer 可自主控制消费消息的速率，同时 Consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。 高可用性 Kafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。 比如说，我们假设创建了一个 topic ，指定其 partition 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 的 1/3 的数据就丢了，因此这个是做不到高可用的。 Kafka 0.8 以后，提供了 HA 机制，就是 replica 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower 。写的时候， leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。 Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。 这么搞，就有所谓的高可用性了，因为如果某个 broker 宕机了，没事儿，那个 broker 上面的 partition 在其他机器上都有副本的，如果这上面有某个 partition 的 leader ，那么此时会从 follower 中 重新选举 一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。 写数据 的时候，生产者就写 leader ，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader ， leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为） 消费 的时候，只会从 leader 去读，但是 只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。 消息幂等性 Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset ，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。 但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset ，尴尬了。重启之后，少数消息会再次消费一次。 幂等性，通俗点说，一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性？其实还是得 结合业务来思考，这里给几个思路： 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。 比如你是写 Redis ，那没问题了，反正每次都是 set，天然幂等性。 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。 消息丢失 消费端弄丢了数据 唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边 自动提交了 offset ，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。 Kafka 会自动提交 offset ，那么只要关闭自动提交 offset ，在处理完之后自己手动提交 offset ，就可以保证数据不会丢。但是此时确实还是可能会有重复消费，比如你刚处理完，还没提交 offset ，结果自己挂了，此时肯定会重复消费一次，自己 保证幂等性 就好了。 Kafka 弄丢了数据 这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader 。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。 此时一般是要求起码设置如下 4 个参数： 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有 至少 2 个副本。 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是 要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。 在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求 一旦写入失败，就无限重试，卡在这里了。 这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。 生产者会不会弄丢数据？ 如果按照上述的思路设置了 acks=all，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者可以自动不断的重试，重试无限次。 消息的顺序性 比如说我们建了一个 topic ，有三个 partition 。生产者在写的时候，其实可以指定一个 key ，比如说我们指定了某个订单 id 作为 key ，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。 消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞 多个线程来并发处理消息。而多个线程并发跑的话，顺序可能就乱掉了。 解决方案： 一个 topic ，一个 partition ，一个 consumer ，内部单线程消费，单线程吞吐量太低，一般不会用这个。 写 N 个内存 queue ，具有相同 key 的数据都到同一个内存 queue ；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。 参考 Kafka设计解析 Kafka的高可用 Kafka幂等性 Kafka消息丢失 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/distributed/8-rpc.html":{"url":"architecture/distributed/8-rpc.html","title":"远程调用","keywords":"","body":"RPC 远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。 应用发展流程 单一应用架构 当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。 垂直应用架构 当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。 分布式服务架构 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。 流动计算架构 当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键。 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"architecture/distributed/9-dubbo.html":{"url":"architecture/distributed/9-dubbo.html","title":"Dubbo","keywords":"","body":"Dubbo 领域模型 在 Dubbo 的核心领域模型中： Protocol 是服务域，它是 Invoker 暴露和引用的主功能入口，它负责 Invoker 的生命周期管理。 Invoker 是实体域，它是 Dubbo 的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起 invoke 调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。 Invocation 是会话域，它持有调用过程中的变量，比如方法名，参数等。 基本设计原则 采用 Microkernel + Plugin 模式，Microkernel 只负责组装 Plugin，Dubbo 自身的功能也是通过扩展点实现的，也就是 Dubbo 的所有功能点都可被用户自定义扩展所替换。 采用 URL 作为配置信息的统一格式，所有扩展点都通过传递 URL 携带配置信息。 Dubbo 服务暴露过程 官方文档--服务导出 Dubbo 结构 第一层：service 层，接口层，给服务提供者和消费者来实现的 第二层：config 层，配置层，主要是对 dubbo 进行各种配置的 第三层：proxy 层，服务代理层，无论是 consumer 还是 provider，dubbo 都会给你生成代理，代理之间进行网络通信 第四层：registry 层，服务注册层，负责服务的注册与发现 第五层：cluster 层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务 第六层：monitor 层，监控层，对 rpc 接口的调用次数和调用时间进行监控 第七层：protocal 层，远程调用层，封装 rpc 调用 第八层：exchange 层，信息交换层，封装请求响应模式，同步转异步 第九层：transport 层，网络传输层，抽象 mina 和 netty 为统一接口 第十层：serialize 层，数据序列化层 工作流程 第一步：provider 向注册中心去注册 第二步：consumer 从注册中心订阅服务，注册中心会通知 consumer 注册好的服务 第三步：consumer 调用 provider 第四步：consumer 和 provider 都异步通知监控中心 注册中心挂了可以继续通信吗？ 可以，因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到 本地缓存，所以注册中心挂了可以继续通信。 Dubbo 支持哪些序列化协议？说一下 Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？ Dubbo 支持不同的通信协议 dubbo 协议：默认就是走 dubbo 协议，单一长连接，进行的是 NIO 异步通信，基于 hessian 作为序列化协议。使用的场景是：传输数据量小（每次请求在 100kb 以内），但是并发量很高。 rmi 协议：走 Java 二进制序列化，多个短连接，适合消费者和提供者数量差不多的情况，适用于文件的传输，一般较少用。 hessian 协议：走 hessian 序列化协议，多个短连接，适用于提供者数量比消费者数量还多的情况，适用于文件的传输，一般较少用。 http 协议：走 json 序列化 webservice：走 SOAP 文本序列化 Dubbo 支持的序列化协议 dubbo 支持 hession 、 Java 二进制序列化、json、SOAP 文本序列化多种序列化协议。但是 hessian 是其默认的序列化协议。 为什么 PB 的效率是最高的？ 其实 PB 之所以性能如此好，主要得益于两个： 它使用 proto 编译器，自动进行序列化和反序列化，速度非常快，应该比 XML 和 JSON 快上了 20~100 倍； 它的数据压缩效果好，就是说它序列化后的数据量体积小。因为体积小，传输起来带宽和速度上会有优化。 dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？ dubbo 负载均衡策略 random loadbalance 默认情况下，dubbo 是 random load balance ，即 随机 调用实现负载均衡，可以对 provider 不同实例 设置不同的权重，会按照权重来负载均衡，权重越大分配流量越高，一般就用这个默认的就可以了。 roundrobin loadbalance 这个的话默认就是均匀地将流量打到各个机器上去，但是如果各个机器的性能不一样，容易导致性能差的机器负载过高。所以此时需要调整权重，让性能差的机器承载权重小一些，流量少一些。 leastactive loadbalance 这个就是自动感知一下，如果某个机器性能越差，那么接收的请求越少，越不活跃，此时就会给 不活跃的性能差的机器更少的请求。 consistanthash loadbalance 一致性 Hash 算法，相同参数的请求一定分发到一个 provider 上去， provider 挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。如果你需要的不是随机负载均衡，是要一类请求都到一个节点，那就走这个一致性 Hash 策略。 dubbo 集群容错策略 failover cluster 模式 失败自动切换，自动重试其他机器，默认就是这个，常见于读操作。（失败重试其它机器） failfast cluster模式 一次调用失败就立即失败，常见于写操作。（调用失败就立即失败） failsafe cluster 模式 出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。 failback cluster 模式 失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种。 forking cluster 模式 并行调用 多个 provider ，只要一个成功就立即返回。 broadcacst cluster 逐个调用所有的 provider。 dubbo动态代理策略 默认使用 javassist 动态字节码生成，创建代理类。但是可以通过 spi 扩展机制配置自己的动态代理策略。 dubbo 的 spi 思想是什么？ spi ，简单来说，就是 service provider interface，说白了是什么意思呢，比如你有个接口，现在这个接口有 3 个实现类，那么在系统运行的时候对这个接口到底选择哪个实现类呢？这就需要 spi 了，需要根据指定的配置或者是默认的配置，去找到对应的实现类加载进来，然后用这个实现类的实例对象。 dubbo 也用了 spi 思想，不过没有用 jdk 的 spi 机制，是自己实现的一套 spi 机制。 Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); Protocol 接口，在系统运行的时候， dubbo 会判断一下应该选用这个 Protocol 接口的哪个实现类来实例化对象来使用。 它会去找一个你配置的 Protocol ，将你配置的 Protocol 实现类，加载到 jvm 中来，然后实例化对象，就用你的那个 Protocol 实现类就可以了。 如何基于 Dubbo 进行服务治理、服务降级、失败重试以及超时重试？ 服务治理 1. 调用链路自动生成 一个大型的分布式系统，或者说是用现在流行的微服务架构来说吧，分布式系统由大量的服务组成。那么这些服务之间互相是如何调用的？调用链路是啥？说实话，几乎到后面没人搞的清楚了，因为服务实在太多了，可能几百个甚至几千个服务。 那就需要基于 dubbo 做的分布式系统中，对各个服务之间的调用自动记录下来，然后自动将 各个服务之间的依赖关系和调用链路生成出来，做成一张图，显示出来，大家才可以看到对吧。 2. 服务访问压力以及时长统计 需要自动统计 各个接口和服务之间的调用次数以及访问延时，而且要分成两个级别。 一个级别是接口粒度，就是每个服务的每个接口每天被调用多少次，TP50/TP90/TP99，三个档次的请求延时分别是多少； 第二个级别是从源头入口开始，一个完整的请求链路经过几十个服务之后，完成一次请求，每天全链路走多少次，全链路请求延时的 TP50/TP90/TP99，分别是多少。 这些东西都搞定了之后，后面才可以来看当前系统的压力主要在哪里，如何来扩容和优化啊。 3. 其它 服务分层（避免循环依赖） 调用链路失败监控和报警 服务鉴权 每个服务的可用性的监控（接口调用成功率？几个 9？99.99%，99.9%，99%） 服务降级 比如说服务 A 调用服务 B，结果服务 B 挂掉了，服务 A 重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应。 举个栗子，我们有接口 HelloService。HelloServiceImpl 有该接口的具体实现。 public interface HelloService { void sayHello(); } public class HelloServiceImpl implements HelloService { public void sayHello() { System.out.println(\"hello world......\"); } } 我们调用接口失败的时候，可以通过 mock 统一返回 null 。 mock 的值也可以修改为 true，然后再跟接口同一个路径下实现一个 Mock 类，命名规则是 “接口名称+Mock” 后缀。然后在 Mock 类里实现自己的降级逻辑。 public class HelloServiceMock implements HelloService { public void sayHello() { // 降级逻辑 } } 失败重试和超时重试 所谓失败重试，就是 consumer 调用 provider 要是失败了，比如抛异常了，此时应该是可以重试的，或者调用超时了也可以重试。配置如下： 参考链接 advanced-java 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/":{"url":"offer/","title":"剑指offer","keywords":"","body":"剑指Offer 包含 剑指Offer 一直 60 道算法题目 常用技巧 异或运算 删除链表节点时，可通过复制下一个节点的方式减少遍历 保存计算结果来减少重复计算，优化时间效率 分治的思想 滑动窗口 数学建模 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/search-a-2d-matrix.html":{"url":"offer/search-a-2d-matrix.html","title":"搜索二维矩阵","keywords":"","body":"搜索二维矩阵 题目 Leetcode 编写一个高效的算法来搜索 m x n 矩阵 matrix 中的一个目标值 target。该矩阵具有以下特性： 每行的元素从左到右升序排列。 每列的元素从上到下升序排列。 示例: 现有矩阵 matrix 如下： [ [1, 4, 7, 11, 15], [2, 5, 8, 12, 19], [3, 6, 9, 16, 22], [10, 13, 14, 17, 24], [18, 21, 23, 26, 30] ] 给定 target = 5，返回 true。 给定 target = 20，返回 false。 解题思路 二维数组是有规律的：右上角的数字是一列中最小的、一行中最大的，通过这个数字和 target 进行对比，可以将一行或者一列作为候选区域排出，那么 target 可能存在的范围缩小，最终得出结果。 public boolean searchMatrix(int[][] matrix, int target) { if (matrix.length == 0) { return false; } for (int i = 0, j = matrix[0].length - 1; i = 0; ) { if (matrix[i][j] > target) { j--; } else if (matrix[i][j] 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/replay-space.html":{"url":"offer/replay-space.html","title":"替换空格","keywords":"","body":"替换空格 题目 牛客网 请实现一个函数，将一个字符串中的每个空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为 We%20Are%20Happy。 解题思路 通过字符串中空格的个数，计算新字符串长度 两个指针进行字符串拷贝，当遇到‘ ’时替换为 %20 public String replaceSpace(StringBuffer str) { char[] chars = str.toString().toCharArray(); int spaceCount = 0; for (char c : chars) { if (c == ' ') spaceCount++; } char[] res = new char[chars.length + spaceCount * 2]; for (int i = 0, j = 0; i 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/print-link-from-tail.html":{"url":"offer/print-link-from-tail.html","title":"从尾到头打印链表","keywords":"","body":"从尾到头打印链表 题目 牛客网 输入一个链表，按链表值从尾到头的顺序返回一个ArrayList。 解题思路 栈 public ArrayList printListFromTailToHead(ListNode listNode) { LinkedList stack = new LinkedList<>(); while (listNode != null) { stack.addLast(listNode.val); listNode = listNode.next; } ArrayList res = new ArrayList<>(); while (!stack.isEmpty()) { res.add(stack.pollLast()); } return res; } 递归：当链表过长时，会导致栈溢出 public ArrayList printListFromTailToHead(ListNode listNode) { ArrayList res = new ArrayList<>(); print(res,listNode); return res; } private void print(ArrayList res, ListNode listNode) { if (listNode == null) return; print(res, listNode.next); res.add(listNode.val); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/reConstructBinaryTree.html":{"url":"offer/reConstructBinaryTree.html","title":"重建二叉树","keywords":"","body":"重建二叉树 输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。 解题思路 通过前序遍历找到 root 节点 那么在 中序遍历中 root 节点的左侧则是左子树，右侧是右子树 依次类推，递归生成节点的左子树和右子树 构建过程由下往上 public TreeNode reConstructBinaryTree(int[] pre, int[] in) { Map preIndex = new HashMap<>(); for (int i = 0; i preIndex, int[] in, int start, int end) { Integer newRootValue = -1; Integer newRootValueIndexInPre = Integer.MAX_VALUE; for (int i = start; i 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/two-stack-fifo.html":{"url":"offer/two-stack-fifo.html","title":"用两个栈实现一个队列","keywords":"","body":"用两个栈实现一个队列 题目 https://www.nowcoder.com/practice/54275ddae22f475981afa2244dd448c6?tpId=13&tqId=11158&rp=1&ru=/ta/coding-interviews&qru=/ta/coding-interviews/question-ranking 用两个栈来实现一个队列，完成队列的 Push 和 Pop 操作。 队列中的元素为int类型。 解题思路 用 stack1 作为 push 队列，将元素 push 到 stack1 用 stack2 作为 pop 队列，当 stack2 为空时则将 stack1 的数据 push 到 stack2，否则直接 pop stack2 相当于将两个 stack 拼接：-> stack1 stack2 -> Stack stack1 = new Stack<>(); Stack stack2 = new Stack<>(); public void push(int node) { stack1.push(node); } public int pop() { if (stack2.isEmpty()) { while (!stack1.isEmpty()) { stack2.push(stack1.pop()); } } return stack2.pop(); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/find-minimum-in-rotated-sorted-array.html":{"url":"offer/find-minimum-in-rotated-sorted-array.html","title":"旋转数组的最小数字","keywords":"","body":"旋转数组的最小数字 题目 牛客网 把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非减排序的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。 解题思路 旋转之后的数组存在两个上升序列，最小元素在两个上升序列的中间 用两个指针在两个序列中找到最大和最小的值，这样 end 指向的数则为最小 public int minNumberInRotateArray(int[] array) { if (array.length == 0) { return 0; } int start = 0, end = array.length - 1; while (end - start != 1) { int mid = (start + end) / 2; if (array[mid] >= array[start]) { start = mid; } if (array[mid] 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/fibonacci.html":{"url":"offer/fibonacci.html","title":"斐波纳切数列","keywords":"","body":"斐波纳切数列 题目 牛客网 大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。n 解题思路 递归计算很慢，是最简单的算法 public int Fibonacci(int n) { if (n == 0) { return 0; } if (n == 1) { return 1; } int l = 1, ll = 0; for (int i = 2; i 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/number-of-one.html":{"url":"offer/number-of-one.html","title":"二进制中1的个数","keywords":"","body":"二进制中1的个数 题目 输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。 解题思路 负数是补码表示 >>> 为无符号右移，>>为有符号右移，当 n 为负数是会增加多余的1 public int NumberOf1(int n) { int mask = 0x01; int res = 0; int t = n; while (t != 0) { if ((t & mask) == 1) { res++; } t = t >>> 1; } return res; } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/power.html":{"url":"offer/power.html","title":"数值的整数次方","keywords":"","body":"题目 牛客网 给定一个 double 类型的浮点数 base 和 int 类型的整数 exponent 。求 base 的 exponent 次方。 解题思路 当 n 为偶数时，a^n = a^{n/2} * a^{n/2} 当 n 为奇数时，a^n = a^{n/2} * a^{n/2} * a 可以利用类似斐波纳切的方式，利用递归来进行求解 public double Power(double base, int exponent) { if (base == 0) { return 0; } if (base == 1) { return 1; } int t_exponent = Math.abs(exponent); double t = PositivePower(base, t_exponent); return exponent > 0 ? t : 1 / t; } private double PositivePower(double base, int exponent) { if (exponent == 0) { return 1; } if (exponent == 1) { return base; } double t = PositivePower(base, exponent >> 1); t *= t; if ((exponent & 0x01) == 1) { t *= base; } return t; } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/printn.html":{"url":"offer/printn.html","title":"打印最大的 n 位数","keywords":"","body":"打印最大的 n 位数 解题思路 n 可能很大，导致输出的数字超过 int 或者 long public void PrintN(int n) { if (n = 0; j--) { int a = chars[j]; if (flag) { a++; flag = false; } if (a > '9') { flag = true; a = a - '9' + '0' - 1; } res.append((char) a); } if (flag) { res.append('1'); } return res.reverse().toString(); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/O1DeleteNode.html":{"url":"offer/O1DeleteNode.html","title":"在O(1)的时间复杂度下删除节点","keywords":"","body":"在O(1)的时间复杂度下删除节点 题目 给定单向链表的头指针以及待删除的指针，定义一个函数在 O(1) 的时间复杂度下删除 解题思路 待删除节点非尾节点，将后一个节点的值复制到当前节点，然后删除后一个节点 待删除节点为尾节点，从头节点开始，找到待删除节点的前一个节点进行删除 public void O1DeleteNode(ListNode head, ListNode needDelete) { if (needDelete.next != null) { ListNode next = needDelete.next.next; needDelete.val = needDelete.next.val; needDelete.next = next; } else { ListNode cursor = head; while (cursor != null) { if (cursor.next == needDelete) break; cursor = cursor.next; } if (cursor == null) return; cursor.next = needDelete.next; } } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/reOrderArray.html":{"url":"offer/reOrderArray.html","title":"调整数组顺序使奇数位于偶数前面","keywords":"","body":"调整数组顺序使奇数位于偶数前面 题目 牛客网 输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。 解题思路 需要保证排序的稳定性 采用冒泡算法进行排序 public void reOrderArray(int[] array) { if (array.length = 0; i--) { for (int j = i; j 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/FindKthToTail.html":{"url":"offer/FindKthToTail.html","title":"链表中倒数第k个结点","keywords":"","body":"链表中倒数第k个结点 题目 牛客网 输入一个链表，输出该链表中倒数第k个结点。 解题思路 两个指针，快指针先走 k 步，然后慢指针在向前移动，当快指针遍历结束，慢指针指向倒数第 k 个节点 需要考虑倒数 k 个节点不存在的情况 public ListNode FindKthToTail(ListNode head, int k) { if (head == null) { return null; } ListNode cursor = head; ListNode cursorK = head; int i = 0; while (cursorK != null) { cursorK = cursorK.next; if (i >= k) { cursor = cursor.next; } i++; } if (i 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/revert-link.html":{"url":"offer/revert-link.html","title":"反转链表","keywords":"","body":"反转链表 题目 牛客网 输入一个链表，反转链表后，输出新链表的表头。 解题思路 三个指针 public ListNode ReverseList(ListNode head) { if (head == null || head.next == null) { return head; } ListNode pre = head, cur = head.next, next; pre.next = null; while (cur != null) { next = cur.next; cur.next = pre; pre = cur; cur = next; } return pre; } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/merge-sort-link.html":{"url":"offer/merge-sort-link.html","title":"合并两个排序的链表","keywords":"","body":"合并两个排序的链表 题目 牛客网 输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。 解题思路 双指针指向两个链表 循环选取最小值，加入结果集 public ListNode Merge(ListNode list1, ListNode list2) { ListNode head = new ListNode(-1); ListNode cursor = head; while (list1 != null || list2 != null) { if (list1 == null) { while (list2 != null) { cursor.next = list2; cursor = cursor.next; list2 = list2.next; } continue; } if (list2 == null) { while (list1 != null) { cursor.next = list1; cursor = cursor.next; list1 = list1.next; } continue; } if (list1.val 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/HasSubtree.html":{"url":"offer/HasSubtree.html","title":"树的子结构","keywords":"","body":"树的子结构 题目 牛客网 输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构） 解题思路 遍历查找相等根节点 通过递归查找当前根节点下是否包含子树 root2 public boolean HasSubtree(TreeNode root1, TreeNode root2) { if (root2 == null) { return false; } LinkedList pipeline = new LinkedList<>(); pipeline.addLast(root1); while (!pipeline.isEmpty()) { TreeNode node = pipeline.pop(); if (node == null) { continue; } pipeline.addLast(node.left); pipeline.addLast(node.right); if (node.val == root2.val && isSub(node, root2)) { return true; } } return false; } private boolean isSub(TreeNode root1, TreeNode root2) { if (root1 == null && root2 == null) { return true; } if (root1 == null) { return false; } if (root2 == null) { return true; } if (root1.val == root2.val) { return isSub(root1.left, root2.left) && isSub(root1.right, root2.right); } else { return false; } } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/mirror-tree.html":{"url":"offer/mirror-tree.html","title":"二叉树的镜像","keywords":"","body":"镜像二叉树 题目 镜像二叉树 操作给定的二叉树，将其变换为源二叉树的镜像。 输入描述: 二叉树的镜像定义：源二叉树 8 / \\ 6 10 / \\ / \\ 5 7 9 11 镜像二叉树 8 / \\ 10 6 / \\ / \\ 11 9 7 5 解题思路 从上到下进行左右节点交换 public void Mirror(TreeNode root) { if (root == null) return; TreeNode temp = root.left; root.left = root.right; root.right = temp; Mirror(root.left); Mirror(root.right); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/PrintMatrix.html":{"url":"offer/PrintMatrix.html","title":"顺时针打印矩阵","keywords":"","body":"顺时针打印矩阵 题目 输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下4 X 4矩阵： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10. 解题思路 通过4个指针，表示可打印区域，并对区域进行收缩 非 n*n 的矩阵，对于剩余非 4 边遍历的元素，要考虑边界 public ArrayList printMatrix(int[][] matrix) { ArrayList res = new ArrayList<>(); if (matrix.length == 0) { return res; } if (matrix.length == 1) { for (int i : matrix[0]) { res.add(i); } return res; } int top = 0, bottom = matrix.length - 1, left = 0, right = matrix[0].length - 1; for (; left = left; p--) { res.add(matrix[bottom][p]); } bottom--; for (int p = bottom; p >= top; p--) { res.add(matrix[p][left]); } left++; } return res; } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/MinStack.html":{"url":"offer/MinStack.html","title":"包含min函数的栈","keywords":"","body":"包含min函数的栈 题目 牛客网 定义栈的数据结构，请在该类型中实现一个能够得到栈中所含最小元素的 min 函数（时间复杂度应为O（1））。 解题思路 通过增加最小栈来记录当前最小节点 private LinkedList stack = new LinkedList<>(); private LinkedList min = new LinkedList<>(); public void push(int node) { stack.addLast(node); if (min.isEmpty()) { min.addLast(node); return; } if (node 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/IsPopOrder.html":{"url":"offer/IsPopOrder.html","title":"栈的压入、弹出序列","keywords":"","body":"栈的压入、弹出序列 题目 牛客网 输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否可能为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列1,2,3,4,5是某栈的压入顺序，序列4,5,3,2,1是该压栈序列对应的一个弹出序列，但4,3,5,1,2就不可能是该压栈序列的弹出序列。（注意：这两个序列的长度是相等的） 解题思路 通过 Stack 进行模拟 push，当 pop 的节点等于 Stack 的 top 节点时，pop Stack 最后如果 Stack 剩余数据，则判定为 false public boolean IsPopOrder(int[] pushA, int[] popA) { if (pushA.length != popA.length) { return false; } if (pushA.length == 0) { return false; } LinkedList stack = new LinkedList<>(); int j = 0; for (int value : pushA) { stack.addLast(value); while (stack.peekLast() != null && popA[j] == stack.getLast()) { j++; stack.removeLast(); } } return stack.isEmpty(); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/PrintFromTopToBottom.html":{"url":"offer/PrintFromTopToBottom.html","title":"从上往下打印二叉树","keywords":"","body":"从上往下打印二叉树 题目 牛客网 从上往下打印出二叉树的每个节点，同层节点从左至右打印。 解题思路 层次遍历，通过队列进行辅助遍历 public ArrayList PrintFromTopToBottom(TreeNode root) { ArrayList res = new ArrayList<>(); LinkedList nodeQueue = new LinkedList<>(); if (root == null) { return res; } nodeQueue.addLast(root); while (!nodeQueue.isEmpty()) { TreeNode node = nodeQueue.pollFirst(); if (node == null) { continue; } nodeQueue.addLast(node.left); nodeQueue.addLast(node.right); res.add(node.val); } return res; } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/VerifySquenceOfBST.html":{"url":"offer/VerifySquenceOfBST.html","title":"二叉搜索树的后序遍历序列","keywords":"","body":"二叉搜索树的后序遍历序列 题目 牛客网 输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历的结果。如果是则输出 Yes ,否则输出 No 。假设输入的数组的任意两个数字都互不相同。 解题思路 后序遍历中，最后一个节点为 root 节点 由于 BST 的左子树都小于 root，右子树都大于 root，那么可以判定该节点是否为 BST 依次类推，通过递归方式，再判定左右子树 public boolean VerifySquenceOfBST(int[] sequence) { if (sequence.length == 0) { return false; } if (sequence.length == 1) { return true; } return isBST(sequence, 0, sequence.length - 1); } private boolean isBST(int[] sequence, int start, int end) { if (start = end) { return true; } int rootV = sequence[end]; int rightIndex = -1, rightV = Integer.MIN_VALUE; for (int i = start; i rootV) { rightV = sequence[i]; rightIndex = i; continue; } if (rightV != Integer.MIN_VALUE && sequence[i] 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/FindPath.html":{"url":"offer/FindPath.html","title":"二叉树中和为某一值的路径","keywords":"","body":"二叉树中和为某一值的路径 题目 二叉树中和为某一值的路径 输入一颗二叉树的跟节点和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。(注意: 在返回值的 list 中，数组长度大的数组靠前) 解题思路 将走过的路径记录下来，当走过路径总和 = target 并且当前节点是叶子节点时，该路径符合要求 通过递归遍历所有可能的路径 public ArrayList> FindPath(TreeNode root, int target) { ArrayList> res = new ArrayList<>(); FindPath(res, new LinkedList<>(), root, 0, target); res.sort(Comparator.comparingInt(list -> -list.size())); return res; } private void FindPath(ArrayList> res, LinkedList path, TreeNode node, int pathSum, int target) { if (node == null) { return; } if (pathSum > target) { return; } if (pathSum + node.val == target && node.right == null && node.left == null) { ArrayList resPath = new ArrayList<>(path); resPath.add(node.val); res.add(resPath); return; } path.addLast(node.val); if (node.left != null) { FindPath(res, path, node.left, pathSum + node.val, target); } if (node.right != null) { FindPath(res, path, node.right, pathSum + node.val, target); } path.removeLast(); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/CloneLink.html":{"url":"offer/CloneLink.html","title":"复杂链表的复制","keywords":"","body":"复杂链表的复制 题目 牛客网 输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的 head 。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空） 解题思路 复制每个节点，如：复制节点 A 得到 A1 ，将 A1 插入节点 A 后面 遍历链表，并将 A1->random = A->random->next; 将链表拆分成原链表和复制后的链表 public RandomListNode Clone(RandomListNode pHead) { if (pHead == null) { return null; } RandomListNode cursor = pHead; while (cursor != null) { RandomListNode copyNode = new RandomListNode(cursor.label); RandomListNode nextNode = cursor.next; cursor.next = copyNode; copyNode.next = nextNode; cursor = nextNode; } cursor = pHead; while (cursor != null) { RandomListNode copyNode = cursor.next; if (cursor.random == null) { cursor = copyNode.next; continue; } copyNode.random = cursor.random.next; cursor = copyNode.next; } RandomListNode copyHead = pHead.next; cursor = pHead; while (cursor.next != null) { RandomListNode copyNode = cursor.next; cursor.next = copyNode.next; cursor = copyNode; } return copyHead; } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/BST-Link-Convert.html":{"url":"offer/BST-Link-Convert.html","title":"二叉搜索树与双向链表","keywords":"","body":"二叉搜索树与双向链表 题目 牛客网 输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。 解题思路 由于 BST 的特性，采用中序遍历正好符合排序 要考虑 root 节点要与 左节点的最大值连接，与右节点的最小值连接 增加一个已排序链表的指针，指向最后一个已排序节点 public TreeNode Convert(TreeNode pRootOfTree) { if (pRootOfTree == null) { return null; } TreeNode[] nodeList = {new TreeNode(-1)}; ConvertToLink(pRootOfTree, nodeList); TreeNode cursor = pRootOfTree; while (cursor.left != null) { cursor = cursor.left; } cursor.right.left = null; return cursor.right; } private void ConvertToLink(TreeNode root, TreeNode[] nodeList) { if (root == null) { return; } ConvertToLink(root.left, nodeList); root.left = nodeList[0]; nodeList[0].right = root; nodeList[0] = root; ConvertToLink(root.right, nodeList); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/Permutation.html":{"url":"offer/Permutation.html","title":"字符串的排列","keywords":"","body":"字符串的排列 题目 牛客网 输入一个字符串,按字典序打印出该字符串中字符的所有排列。例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。 输入描述:输入一个字符串,长度不超过9(可能有字符重复),字符只包括大小写字母。 解题思路 将字符串划分为两个部分，第一个字符以及后面的其他字符 将第一个字符和后面所有字符进行交换 对于 abc 这个字符串，计算出的排列顺序为： abc acb bac bca cba cab 代码： public ArrayList Permutation(String str) { Set res = new HashSet<>(); if (str == null || str.length() == 0) { return new ArrayList<>(); } Permutation(res, str.toCharArray(), 0); ArrayList list = new ArrayList<>(res); list.sort(String::compareTo); return list; } private void Permutation(Set res, char[] chars, int start) { if (start == chars.length) { res.add(new String(chars)); return; } for (int i = start; i 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/MoreThanHalfNum.html":{"url":"offer/MoreThanHalfNum.html","title":"数组中出现次数超过一半的数字","keywords":"","body":"数组中出现次数超过一半的数字 题目 牛客网 数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出 2 。如果不存在则输出 0 。 解题思路 由于数组的特性，在排序数组中，超过半数的数字一定包含中位数 通过 partition 方法，借用快排的思想，随机选取一个 key，将数组中小于 key 的移动到 key 的左侧，数组中大于 key 的移动到 key 的右侧 最终找到中位数的下标，还需要检查中位数是否超过半数 public int MoreThanHalfNum_Solution(int[] array) { int start = 0, end = array.length - 1; int mid = array.length / 2; int index = partition(array, start, end); if (index == mid) { return array[index]; } while (index != mid && start mid) { end = index - 1; index = partition(array, start, end); } else { start = index + 1; index = partition(array, start, end); } } if (checkIsHalf(array, index)) return array[index]; return 0; } private boolean checkIsHalf(int[] array, int index) { if (index array.length / 2; } private int partition(int[] array, int start, int end) { if (start >= array.length || start = array.length || end = key) { right--; } if (left 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/GetLeastNumbers.html":{"url":"offer/GetLeastNumbers.html","title":"最小的K个数","keywords":"","body":"最小的K个数 题目 牛客网 输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。 解题思路 Partition 该算法基于 Partition public ArrayList GetLeastNumbers_Solution_Partition(int[] input, int k) { ArrayList res = new ArrayList<>(); if (k > input.length || k k - 1) { end = index - 1; index = partition(input, start, end); } else { start = index + 1; index = partition(input, start, end); } } for (int i = 0; i key) { right--; } if (left 小根堆算法 该算法基于小根堆，适合海量数据，时间复杂度为：n*logk public ArrayList GetLeastNumbers_Solution(int[] input, int k) { ArrayList res = new ArrayList<>(); if (k > input.length||k==0) { return res; } for (int i = input.length - 1; i >= 0; i--) { minHeap(input, 0, i); swap(input, 0, i); res.add(input[i]); if (res.size() == k) break; } return res; } private void minHeap(int[] heap, int start, int end) { if (start == end) { return; } int childLeft = start * 2 + 1; int childRight = childLeft + 1; if (childLeft 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/FindGreatestSumOfSubArray.html":{"url":"offer/FindGreatestSumOfSubArray.html","title":"连续子数组的最大和","keywords":"","body":"连续子数组的最大和 题目 牛客网 例如:{6,-3,-2,7,-15,1,2,2},连续子向量的最大和为8(从第0个开始,到第3个为止)。给一个数组，返回它的最大连续子序列的和，你会不会被他忽悠住？(子向量的长度至少是1) 解题思路 通过动态规划计算最大和，f(i) 定义为以第 i 个数字结尾的子数组的最大和，那么 max(f(i)) 就有以下公式： max(f(i))=\\begin{cases} num[i] & i=0 or f(i)0 \\end{cases} public int FindGreatestSumOfSubArray(int[] array) { if (array == null || array.length == 0) { return 0; } int max = array[0]; int sum = 0; for (int a : array) { if (sum + a > a) { sum += a; } else { sum = a; } if (sum > max) { max = sum; } } return max; } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/NumberOfOneBetweenOneAndN.html":{"url":"offer/NumberOfOneBetweenOneAndN.html","title":"从1到n整数中1出现的次数","keywords":"","body":"整数中1出现的次数（从1到n整数中1出现的次数） 题目 牛客网 求出1~13的整数中 1 出现的次数,并算出 100~1300 的整数中1出现的次数？为此他特别数了一下 1~13 中包含1的数字有 1、10、11、12、13 因此共出现 6 次,但是对于后面问题他就没辙了。ACMer 希望你们帮帮他,并把问题更加普遍化,可以很快的求出任意非负整数区间中1出现的次数（从1 到 n 中1出现的次数）。 解题思路 假定 n=21345 将数字分为首位和非首位两个部分 对于首位为 1 的情况，如果首位 >1 那么sum=sum+10^{len(n)-1}，如果首位 =1 那么 sum=sum+1 对于非首位 1，指定其中一位为 1，根据排列组合有 10^{len(n)-2}\\times(len(n)-1) 个。那么非首位 1 总共有 2\\times10^{len(n)-2}\\times(len(n)-1) public int NumberOf1Between1AndN_Solution(int n) { int[] res = {0}; NumberOf1Between1AndN(res, n); return res[0]; } private void NumberOf1Between1AndN(int[] res, int n) { //假设 num=21345 String num = String.valueOf(n); int firstNum = num.charAt(0) - '0'; if (num.length() == 1) { if (firstNum > 0) res[0]++; return; } String nextNum = num.substring(1); int nextN = Integer.valueOf(nextNum); //数字 10000 ～ 19999 的第一位中的个数 if (firstNum > 1) { res[0] += Math.pow(10, num.length() - 1); } else if (firstNum == 1) { res[0] += nextN + 1; } //1346 ～ 21345 除第一位之外的数的个数 res[0] += firstNum * (num.length() - 1) * Math.pow(10, num.length() - 2); NumberOf1Between1AndN(res, nextN); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/PrintMinNumber.html":{"url":"offer/PrintMinNumber.html","title":"把数组排成最小的数","keywords":"","body":"把数组排成最小的数 题目 把数组排成最小的数 输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。 解题思路 最直接的办法就是，找到数组中数字的所有排列组合，找到最小的 对于 m, n，可以组成 mn , nm 这两个数，如果 mn 那么，m 应该在 n 之前 对于一组数，可以通过上述规则进行排序，依次打印出来就是最小的数 由于组合之后的数可能超出 int 的表示范围，注意使用字符串来处理大数问题 public String PrintMinNumber(int[] numbers) { List nums = new ArrayList<>(); for (int number : numbers) { nums.add(String.valueOf(number)); } nums.sort(Comparator.comparing(s -> s, (o1, o2) -> (o1 + o2).compareTo(o2 + o1))); StringJoiner joiner = new StringJoiner(\"\"); nums.forEach(joiner::add); return joiner.toString(); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/GetUglyNumber.html":{"url":"offer/GetUglyNumber.html","title":"丑数","keywords":"","body":"丑数 牛客网 把只包含质因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含质因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。 解题思路 通过保存已有丑数的方式，用空间换时间 对于已有丑数 M ，那么下一个丑数 M=\\min(M_{2}\\times2,M_{3}\\times3,M_{5}\\times5) M_{max} 是目前最大的丑数，那么 M_{2} 是已有丑数中 M_{2}\\times2 第一个大于 M_{max} 的丑数 public int GetUglyNumber_Solution(int index) { if (index == 0) { return 0; } if (index == 1) { return 1; } ArrayList list = new ArrayList<>(index); list.add(1); int preIndex2 = 0; int preIndex3 = 0; int preIndex5 = 0; for (int i = 0; i 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/FirstNotRepeatingChar.html":{"url":"offer/FirstNotRepeatingChar.html","title":"第一个只出现一次的字符","keywords":"","body":"第一个只出现一次的字符 题目 牛客网 在一个字符串(0，全部由字母组成)中找到第一个只出现一次的字符,并返回它的位置, 如果没有则返回 -1（需要区分大小写）. 解题思路 通过 LinkedHashMap 记录数组顺序，然后计算字符出现的次数 遍历找到第一个只出现 1次 的字符 public int FirstNotRepeatingChar(String str) { LinkedHashMap data = new LinkedHashMap<>(); char[] chars = str.toCharArray(); for (char c : chars) { Integer count = data.getOrDefault(c, 0); data.put(c, count + 1); } Character res = null; for (Character c : data.keySet()) { if (data.get(c) == 1) { res = c; break; } } if (res == null) { return -1; } for (int i = 0; i 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/InversePairs.html":{"url":"offer/InversePairs.html","title":"数组中的逆序对","keywords":"","body":"数组中的逆序对 题目 牛客网 在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007 输入描述: 题目保证输入的数组中没有的相同的数字 数据范围： 对于%50的数据,size解题思路 1. 使用归并排序的方式，划分子数组 2. 两个子数组进行对比，有两个分别指向两个数组末尾的指针 `f,s`，数组分割下标为 `mid`，如果 `array[f] > array[s]`那么，就有`s - mid`个 `array[f]` 的逆序 3. 依此类推，最终将数组排序，并且获得结果 public int InversePairs(int[] array) { long[] sum = {0}; if (array == null || array.length == 0) { return (int) sum[0]; } int[] temp = new int[array.length]; mergeSort(array, 0, array.length - 1, temp, sum); return (int) (sum[0] % 1000000007); } private void mergeSort(int[] array, int start, int end, int[] temp, long[] sum) { if (start == end) { return; } int mid = (start + end) / 2; mergeSort(array, start, mid, temp, sum); mergeSort(array, mid + 1, end, temp, sum); int f = mid, s = end; int t = end; while (f >= start && s >= mid + 1) { if (array[f] > array[s]) { temp[t--] = array[f--]; sum[0] += s - mid; } else { temp[t--] = array[s--]; } } while (f >= start) { temp[t--] = array[f--]; } while (s >= mid + 1) { temp[t--] = array[s--]; } for (int i = end, j = end; i >= start; ) { array[j--] = temp[i--]; } } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/FindFirstCommonNode.html":{"url":"offer/FindFirstCommonNode.html","title":"两个链表的第一个公共结点","keywords":"","body":"两个链表的第一个公共结点 题目 牛客网 输入两个链表，找出它们的第一个公共结点。 解决思路 空间复杂度 O(n) 的算法 使用辅助容器，保存第一个链表的所有元素 遍历第二个链表，并对比当前节点是否在辅助容器中 /** * 空间 O(n) * * @param pHead1 * @param pHead2 * @return */ public ListNode FindFirstCommonNode_1(ListNode pHead1, ListNode pHead2) { Set node1s = new HashSet<>(); while (pHead1 != null) { node1s.add(pHead1); pHead1 = pHead1.next; } while (pHead2 != null) { if (node1s.contains(pHead2)) { return pHead2; } pHead2 = pHead2.next; } return null; } 空间复杂度 O(1) 的算法 由于两个链表有可能不一样长，首先通过遍历找到他们的长度 移动较长的那个链表，使得两个链表长度一致 同步遍历两个链表 原理：如果两个链表相交，那么它们一定有相同的尾节点 /** * 空间 O(1) * * @param pHead1 * @param pHead2 * @return */ public ListNode FindFirstCommonNode_2(ListNode pHead1, ListNode pHead2) { int len1 = 0, len2 = 0; ListNode cursor1 = pHead1, cursor2 = pHead2; while (cursor1 != null) { cursor1 = cursor1.next; len1++; } while (cursor2 != null) { cursor2 = cursor2.next; len2++; } cursor1 = pHead1; cursor2 = pHead2; if (len1 > len2) { int i = len1; while (i != len2) { cursor1 = cursor1.next; i--; } } else if (len1 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/GetNumberOfK.html":{"url":"offer/GetNumberOfK.html","title":"数字在排序数组中出现的次数","keywords":"","body":"数字在排序数组中出现的次数 题目 牛客网 统计一个数字在排序数组中出现的次数。 解题思路 利用二分查找，找到任意一个 k 由于 k 有多个，并且当前找到的 k 可能在任意位置。所以，在当前 k 的前后进行遍历查找 public int GetNumberOfK(int[] array, int k) { if (array == null || array.length == 0) { return 0; } //二分查找 int start = 0, end = array.length - 1; int t = -1; while (start k) { end = mid - 1; } else { start = mid + 1; } } if (array[start] == k) { t = start; } if (t == -1) { return 0; } //左侧 int sum = 0; int a = t; while (a >= 0 && array[a] == k) { sum++; a--; } //右侧 a = t + 1; while (a 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/TreeDepth.html":{"url":"offer/TreeDepth.html","title":"二叉树的深度","keywords":"","body":"二叉树的深度 题目 牛客网 输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。 解题思路 深度优先遍历 public int TreeDepth(TreeNode root) { int[] max = {0}; depth(root, max, 1); return max[0]; } private void depth(TreeNode root, int[] max, int curDepth) { if (root == null) return; if (curDepth > max[0]) max[0] = curDepth; depth(root.left, max, curDepth + 1); depth(root.right, max, curDepth + 1); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/FindNumsAppearOnce.html":{"url":"offer/FindNumsAppearOnce.html","title":"数组中只出现一次的数字","keywords":"","body":"数组中只出现一次的数字 题目 牛客网 一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。 解题思路 两个相等的数字进行异或的结果为0 在这个特殊的数组中，重复出现的数字只能为2次，那么如果将所有数字异或 就等价与将两个不同的数字进行异或 异或的结果肯定有一位为1，那么这两个不同的数字，在这一位上不同。 找到第一个为1的位，并将第一位为1的位是否为1作为分组条件，相同的数字一定在同一个分组里，整个数组分组异或 得到两个结果，即为两个不同的数 /** * num1,num2分别为长度为1的数组。传出参数。将num1[0],num2[0]设置为返回结果 * @param array * @param num1 * @param num2 */ public void FindNumsAppearOnce(int[] array, int num1[], int num2[]) { if (array == null || array.length >>= 1; } int mask = 1; for (int i = 1; i 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/FindNumbersWithSum.html":{"url":"offer/FindNumbersWithSum.html","title":"和为S的两个数字","keywords":"","body":"和为S的两个数字 题目 牛客网 输入一个递增排序的数组和一个数字S，在数组中查找两个数，使得他们的和正好是S，如果有多对数字的和等于S，输出两个数的乘积最小的。 对应每个测试案例，输出两个数，小的先输出。 解题思路 利用二分查找的思想，由于是排序数组，通过两个指针来进行遍历 public ArrayList FindNumbersWithSum(int[] array, int sum) { ArrayList res = new ArrayList<>(); if (array == null || array.length == 1) { return res; } int start = 0, end = array.length - 1; int minMulti = Integer.MAX_VALUE; int a = -1, b = -1; while (start sum) end--; else start++; } if (a == -1 || b == -1) { return res; } res.add(a); res.add(b); return res; } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/FindContinuousSequence.html":{"url":"offer/FindContinuousSequence.html","title":"和为S的连续正数序列","keywords":"","body":"和为S的连续正数序列 题目 牛客网 输出所有和为S的连续正数序列。序列内按照从小至大的顺序，序列间按照开始数字从小到大的顺序 解题思路 与上一个题目类似，需要确定的是序列的最大值，不超过 sum 使用窗口模式，两个指针定义一个窗口，和为 t public ArrayList> FindContinuousSequence(int sum) { ArrayList> res = new ArrayList<>(); if (sum == 1) { return res; } int start = 1, end = 2; int t = start + end; while (start ints = new ArrayList<>(); for (int i = start; i sum) { t -= start; start++; } else { if (end >= sum) break; end++; t += end; } } return res; } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/ReverseSentence.html":{"url":"offer/ReverseSentence.html","title":"翻转单词顺序列","keywords":"","body":"翻转单词顺序列 题目 牛客网 牛客最近来了一个新员工 Fish ，每天早晨总是会拿着一本英文杂志，写些句子在本子上。同事Cat对Fish写的内容颇感兴趣，有一天他向Fish借来翻看，但却读不懂它的意思。例如，“student. a am I”。后来才意识到，这家伙原来把句子单词的顺序翻转了，正确的句子应该是“I am a student.”。Cat对一一的翻转这些单词顺序可不在行，你能帮助他么？ 解题思路 public String ReverseSentence(String str) { if(str == null || str.trim().equals(\"\")) return str; String[] split = str.split(\" \"); StringBuilder builder = new StringBuilder(); for (int i = split.length - 1; i >= 0; i--) { builder.append(split[i]); if (i != 0) builder.append(\" \"); } return builder.toString(); } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/LeftRotateString.html":{"url":"offer/LeftRotateString.html","title":"左旋转字符串","keywords":"","body":"左旋转字符串 题目 牛客网 汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！ 解题思路 对于 abcXYZdef 左移 3位，可以将字符串分为两个部分：abc & XYZdef 分别将两个部分进行反转得到：cba & fedZYX 将两部分和在一起再进行反转：XYZdefabc public String LeftRotateString(String str, int n) { if (str == null || str.trim().equals(\"\")) return str; String res = revert(str, 0, n - 1); res = revert(res, n, str.length() - 1); res = revert(res, 0, str.length() - 1); return res; } private String revert(String str, int start, int end) { char[] chars = str.toCharArray(); while (start 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/SumOfNDice.html":{"url":"offer/SumOfNDice.html","title":"n个骰子的点数","keywords":"","body":"n个骰子的点数 题目 把 n 个骰子扔在地上，所有骰子朝上一面的和为 s，输入 n，打印 s 所有可能值的概率 解题思路 首先考虑一个骰子的情况，那么有 1～6 出现的次数均为 1 再增加一个骰子时，由于各个点数出现的概率一致。用 f(n,s)=f(n-1,s-1)+f(n-1,s-2)+f(n-1,s-3)+f(n-1,s-4)+f(n-1,s-5)+f(n-1,s-6) 使用两个数组循环求解 public void SumOfNDice(int n) { if (n = 0); k++) { sum += nums[flag][j - k]; } nums[newFlag][j] = sum; } flag = newFlag; } //debug out System.out.println(Arrays.toString(nums[flag])); int sum = 0; for (int i : nums[flag]) { sum += i; } for (int i = 0; i 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/isContinuous.html":{"url":"offer/isContinuous.html","title":"扑克牌顺子","keywords":"","body":"扑克牌顺子 题目 牛客网 LL今天心情特别好,因为他去买了一副扑克牌,发现里面居然有 2 个大王, 2 个小王(一副牌原本是 54 张)...他随机从中抽出了 5 张牌,想测测自己的手气,看看能不能抽到顺子,如果抽到的话,他决定去买体育彩票,嘿嘿！！“红心A,黑桃3,小王,大王,方片5”,“Oh My God!”不是顺子.....LL不高兴了,他想了想,决定大\\小 王可以看成任何数字,并且A看作1,J为11,Q为12,K为13。上面的5张牌就可以变成“1,2,3,4,5”(大小王分别看作2和4),“So Lucky!”。LL决定去买体育彩票啦。 现在,要求你使用这幅牌模拟上面的过程,然后告诉我们 LL 的运气如何， 如果牌能组成顺子就输出 true，否则就输出 false。为了方便起见,你可以认为大小王是0。 解题思路 对数组进行排序 计算非0元素之间的间隔总和 如果有相同元素则直接认为失败 如果间隔大于0，那么间隔的总个数等于0的总个数，即为成功 public boolean isContinuous(int[] numbers) { if (numbers == null || numbers.length 0) { count += t; } else if (t 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/LastRemaining.html":{"url":"offer/LastRemaining.html","title":"圆圈中最后剩下的数","keywords":"","body":"圆圈中最后剩下的数 题目 牛客网 每年六一儿童节,牛客都会准备一些小礼物去看望孤儿院的小朋友,今年亦是如此。HF 作为牛客的资深元老,自然也准备了一些小游戏。其中,有个游戏是这样的:首先,让小朋友们围成一个大圈。然后,他随机指定一个数m,让编号为0的小朋友开始报数。每次喊到m-1的那个小朋友要出列唱首歌,然后可以在礼品箱中任意的挑选礼物,并且不再回到圈中,从他的下一个小朋友开始,继续0...m-1报数....这样下去....直到剩下最后一个小朋友,可以不用表演,并且拿到牛客名贵的“名侦探柯南”典藏版。请你试着想下,哪个小朋友会得到这份礼品呢？(注：小朋友的编号是从 0 到 n-1 ) 解题思路 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/sum.html":{"url":"offer/sum.html","title":"求1+2+3+...+n","keywords":"","body":"求1+2+3+...+n 题目 牛客网 求1+2+3+...+n，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。 解题思路 利用递归代替循环 public int Sum_Solution(int n) { int ans = n; boolean t = ((ans != 0) && ((ans += Sum_Solution(n - 1)) != 0)); return ans; } 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "},"offer/Add.html":{"url":"offer/Add.html","title":"不用加减乘除做加法","keywords":"","body":"不用加减乘除做加法 题目 牛客网 写一个函数，求两个整数之和，要求在函数体内不得使用+、-、*、/四则运算符号。 解题思路 将加法分解成两步 两个数不计算进位相加得到 sum，计算进位 carry 再将进位加上：sum = sum + carry 直到没有进位为止 public int Add(int num1, int num2) { int sum, carry; do { sum = num1 ^ num2; carry = (num1 & num2) 使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-05-06 11:44:46 "}}